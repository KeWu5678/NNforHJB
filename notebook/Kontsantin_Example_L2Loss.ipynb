{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeebd44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Add the src directory to Python path so model.py can find ssn and net modules\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "import torch\n",
    "from src.model import model\n",
    "from src.PDAP import retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dfa9fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-22 12:19:58.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mLoaded data with shape: (961,), dtype: [('x', '<f8', (2,)), ('dv', '<f8', (2,)), ('v', '<f8')]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "path = '../data_result/raw_data/gauss_cos_31x31.npy'# Initialize the weights\n",
    "data = np.load(path)\n",
    "logger.info(f\"Loaded data with shape: {data.shape}, dtype: {data.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4099fadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameter\n",
    "power = 2.1\n",
    "M = 50 # number greedy insertion selected\n",
    "num_iterations = 10\n",
    "loss_weights = (1.0, 0.0)\n",
    "pruning_threshold = 1e-15\n",
    "\n",
    "gamma = 5.0\n",
    "alpha = 1e-5\n",
    "lr_adam = 1e-5\n",
    "regularization = (gamma, alpha) \n",
    "th = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4273cea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-22 12:20:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_configure_logger\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mModel initialized\u001b[0m\n",
      "\u001b[32m2025-09-22 12:20:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_configure_logger\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mModel initialized\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Initialize the models\n",
    "model_1 = model(activation=torch.relu, power=power, regularization=regularization, optimizer='Adam', loss_weights=loss_weights, th = th)\n",
    "model_2 = model(activation=torch.relu, power=power, regularization=regularization, optimizer='SSN', loss_weights=loss_weights, th=th, train_outerweights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3470321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-22 12:20:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m150\u001b[0m - \u001b[1mTraining set: 864 samples, Validation set: 97 samples\u001b[0m\n",
      "\u001b[32m2025-09-22 12:20:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mData ranges - x: [-1.00, 1.00], v: [-0.72, 1.00], dv: [-5.86, 5.86]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# prepare the data\n",
    "data_train, data_valid = model_1._prepare_data(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bb86f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.greedy_insertion import _sample_uniform_sphere_points, insertion\n",
    "from src.PDAP import prune_small_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e2c1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-22 12:32:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mIteration 0 - Starting...\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m307\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m194\u001b[0m - \u001b[1mCreating network with 50 neurons\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m244\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m322\u001b[0m - \u001b[1mTraining hyperparameters: iterations=1000, batch_size=1620, display_every=100\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=0.0\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.151971, Val Loss = 2.131949\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.209801, Val Loss = 0.335750\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.154338, Val Loss = 0.885189\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.107728, Val Loss = 2.114578\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.097291, Val Loss = 1.982449\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.086606, Val Loss = 1.789326\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.081822, Val Loss = 1.769271\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.077470, Val Loss = 1.497500\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.069234, Val Loss = 1.726189\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.065469, Val Loss = 1.723983\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m376\u001b[0m - \u001b[1mBest validation loss: 0.335750. Restored best model from /Users/ruizhechao/Documents/NNforHJB/train_history/model_best.pt\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m307\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m227\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m322\u001b[0m - \u001b[1mTraining hyperparameters: iterations=1000, batch_size=1620, display_every=100\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=0.0\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.209294, Val Loss = 6.001241\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.091356, Val Loss = 1.039928\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.086061, Val Loss = 0.928614\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.079473, Val Loss = 0.805482\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.076679, Val Loss = 0.757861\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.075034, Val Loss = 0.716706\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.074232, Val Loss = 0.703301\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.073415, Val Loss = 0.686090\u001b[0m\n",
      "\u001b[32m2025-09-22 12:32:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.072772, Val Loss = 0.675030\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.072279, Val Loss = 0.667929\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m376\u001b[0m - \u001b[1mBest validation loss: 0.667929. Restored best model from /Users/ruizhechao/Documents/NNforHJB/train_history/model_best.pt\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m22\u001b[0m - \u001b[1mSmall weights count: 0, Pruning...\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.PDAP\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mprune_small_weights - weights: (50, 2), biases: (50,), outer_weights: (1, 50)\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.PDAP\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mAfter pruning - weights: (50, 2), biases: (50,), outer_weights: (1, 50)\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mRecording...\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mNew best model found at iteration 0 with validation loss: 0.667929\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mIteration 1 - Starting...\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m307\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m194\u001b[0m - \u001b[1mCreating network with 91 neurons\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m244\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m322\u001b[0m - \u001b[1mTraining hyperparameters: iterations=1000, batch_size=1620, display_every=100\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=0.0\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.893088, Val Loss = 0.363656\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.187163, Val Loss = 0.370505\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.119758, Val Loss = 0.256386\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.086795, Val Loss = 0.970581\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.079221, Val Loss = 1.362182\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.075460, Val Loss = 1.462138\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.072931, Val Loss = 1.358469\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.069046, Val Loss = 1.514539\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.067018, Val Loss = 1.498006\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.065443, Val Loss = 1.500695\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m376\u001b[0m - \u001b[1mBest validation loss: 0.256386. Restored best model from /Users/ruizhechao/Documents/NNforHJB/train_history/model_best.pt\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m307\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m227\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m322\u001b[0m - \u001b[1mTraining hyperparameters: iterations=1000, batch_size=1620, display_every=100\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=0.0\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.119109, Val Loss = 2.635381\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.029408, Val Loss = 167.949619\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.026476, Val Loss = 127.201410\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.023787, Val Loss = 124.164378\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.021217, Val Loss = 129.030489\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.020318, Val Loss = 114.434176\u001b[0m\n",
      "\u001b[32m2025-09-22 12:33:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.019982, Val Loss = 111.448857\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.019864, Val Loss = 114.945434\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.019531, Val Loss = 140.645811\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.019265, Val Loss = 119.784161\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m376\u001b[0m - \u001b[1mBest validation loss: 2.635381. Restored best model from /Users/ruizhechao/Documents/NNforHJB/train_history/model_best.pt\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m22\u001b[0m - \u001b[1mSmall weights count: 0, Pruning...\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.PDAP\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mprune_small_weights - weights: (91, 2), biases: (91,), outer_weights: (1, 91)\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.PDAP\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mAfter pruning - weights: (91, 2), biases: (91,), outer_weights: (1, 91)\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mRecording...\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mIteration 2 - Starting...\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m307\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m194\u001b[0m - \u001b[1mCreating network with 136 neurons\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m244\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m322\u001b[0m - \u001b[1mTraining hyperparameters: iterations=1000, batch_size=1620, display_every=100\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=0.0\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.082967, Val Loss = 0.182990\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.171795, Val Loss = 0.383966\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.111926, Val Loss = 1.286983\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.099883, Val Loss = 1.701258\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.094038, Val Loss = 1.633963\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.091057, Val Loss = 1.569724\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.087751, Val Loss = 1.531781\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.085150, Val Loss = 1.494503\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.084790, Val Loss = 1.458089\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.078815, Val Loss = 1.496260\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m376\u001b[0m - \u001b[1mBest validation loss: 0.182990. Restored best model from /Users/ruizhechao/Documents/NNforHJB/train_history/model_best.pt\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m307\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m227\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m322\u001b[0m - \u001b[1mTraining hyperparameters: iterations=1000, batch_size=1620, display_every=100\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=0.0\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.566144, Val Loss = 2.571721\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.456373, Val Loss = 14.233990\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.446594, Val Loss = 13.448091\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.437933, Val Loss = 13.438437\u001b[0m\n",
      "\u001b[32m2025-09-22 12:34:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.432479, Val Loss = 11.910221\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.414501, Val Loss = 9.920157\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.404031, Val Loss = 9.149181\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.394456, Val Loss = 8.148432\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.388065, Val Loss = 7.710830\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.380901, Val Loss = 7.353662\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m376\u001b[0m - \u001b[1mBest validation loss: 2.571721. Restored best model from /Users/ruizhechao/Documents/NNforHJB/train_history/model_best.pt\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m22\u001b[0m - \u001b[1mSmall weights count: 0, Pruning...\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.PDAP\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mprune_small_weights - weights: (136, 2), biases: (136,), outer_weights: (1, 136)\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.PDAP\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mAfter pruning - weights: (136, 2), biases: (136,), outer_weights: (1, 136)\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mRecording...\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mIteration 3 - Starting...\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m307\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m194\u001b[0m - \u001b[1mCreating network with 179 neurons\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m244\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m322\u001b[0m - \u001b[1mTraining hyperparameters: iterations=1000, batch_size=1620, display_every=100\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=0.0\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.607367, Val Loss = 1.039424\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.170505, Val Loss = 0.311703\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.107854, Val Loss = 1.491684\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.087119, Val Loss = 1.530513\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.078087, Val Loss = 1.626994\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.074832, Val Loss = 1.924752\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.071845, Val Loss = 1.726702\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.069478, Val Loss = 1.668476\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.067571, Val Loss = 1.692984\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.066026, Val Loss = 1.765866\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m376\u001b[0m - \u001b[1mBest validation loss: 0.311703. Restored best model from /Users/ruizhechao/Documents/NNforHJB/train_history/model_best.pt\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m307\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m227\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m322\u001b[0m - \u001b[1mTraining hyperparameters: iterations=1000, batch_size=1620, display_every=100\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=0.0\u001b[0m\n",
      "\u001b[32m2025-09-22 12:35:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.169611, Val Loss = 1.565919\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "alpha = model_1.alpha\n",
    "\n",
    "# Track best model across all iterations\n",
    "best_iteration = 0\n",
    "best_val_loss = float('inf')\n",
    "W_hidden, b_hidden = _sample_uniform_sphere_points(M)\n",
    "\n",
    "# Training loop\n",
    "for i in range(num_iterations):\n",
    "    logger.info(f\"Iteration {i} - Starting...\")\n",
    "    model_1.train(data_train, data_valid, inner_weights=W_hidden, inner_bias=b_hidden, iterations = 1000, display_every = 100)\n",
    "    state_1 = model_1.net.state_dict()\n",
    "    W_hidden, b_hidden, W_out = state_1['hidden.weight'].detach().cpu().numpy(), state_1['hidden.bias'].detach().cpu().numpy(), state_1['output.weight'].detach().cpu().numpy()\n",
    "    model_2.train(data_train, data_valid, inner_weights=W_hidden, inner_bias=b_hidden, outer_weights=W_out, iterations = 1000, display_every = 100)\n",
    "    \n",
    "    # Count and prune small weights\n",
    "    state_2 = model_2.net.state_dict()\n",
    "    # Use torch-native ops to count small weights, then convert to int for logging\n",
    "    small_mask = (state_2['output.weight'].abs().flatten() < pruning_threshold)\n",
    "    small_count = int(small_mask.sum().item())\n",
    "    logger.info(f\"Small weights count: {small_count}, Pruning...\")\n",
    "    # Prune neurons based on the trained outer weights from model_2\n",
    "    W_hidden, b_hidden, _ = prune_small_weights(\n",
    "        W_hidden, \n",
    "        b_hidden,\n",
    "        state_2['output.weight'].detach().cpu().numpy(),\n",
    "        pruning_threshold,\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Recording...\")\n",
    "    record = {'iteration': int(i), 'artifact': model_2.config, 'num_neurons': W_hidden.shape[0]}\n",
    "    history.append(record)\n",
    "    if model_2.config['best_val_loss'] < best_val_loss:\n",
    "        best_val_loss = model_2.config['best_val_loss']\n",
    "        best_iteration = i\n",
    "        logger.info(f\"New best model found at iteration {i} with validation loss: {best_val_loss:.6f}\")\n",
    "    \n",
    "    # Insert neurons and train\n",
    "    W_to_insert, b_to_insert = insertion(data_train, model_1, M, alpha)\n",
    "    W_hidden = np.concatenate((W_hidden, W_to_insert), axis=0)\n",
    "    b_hidden = np.concatenate((b_hidden, b_to_insert), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0db354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save(self):\n",
    "#     \"\"\"Save training history.\"\"\"\n",
    "#     timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "#     filename = f\"training_history_{timestamp}.pkl\"\n",
    "#     filepath = os.path.join(self.stats_dir, filename)\n",
    "    \n",
    "#     with open(filepath, 'wb') as f:\n",
    "#         pickle.dump(self.history, f)\n",
    "        \n",
    "#     logger.info(f\"Saved training history to {filepath}\")\n",
    "#     return filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cb5add",
   "metadata": {},
   "source": [
    "Reached 6.04e-3 at 179 neurones model is about 126 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adb6393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PLOT: Weight space visualization in polar coordinates\n",
    "# Shows the distribution of weights in 2D space for the BEST model (lowest validation loss)\n",
    "# =============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Extract weights from the current training run\n",
    "weights_run = KP_logger_L2_nc.history['weights']\n",
    "biases_run = KP_logger_L2_nc.history['biases']\n",
    "neurons_run = KP_logger_L2_nc.history['neuron_count']\n",
    "\n",
    "print(f\"Training run: {len(weights_run)} iterations, max neurons: {max(neurons_run)}\")\n",
    "\n",
    "# Use the BEST model (lowest validation loss) instead of the iteration with most neurons\n",
    "print(\"Using BEST model (lowest validation loss)\")\n",
    "weights_optimal = KP_logger_L2_nc.history['best_weights']\n",
    "b_optimal = KP_logger_L2_nc.history['best_biases'].reshape(1, -1)   # (1, n)\n",
    "best_loss = KP_logger_L2_nc.history['best_test_loss']\n",
    "print(f\"Best validation loss: {best_loss:.6f}\")\n",
    "\n",
    "a_optimal = weights_optimal.T                         # (2, n)\n",
    "Z = a_optimal / (1 + b_optimal) \n",
    "\n",
    "# Create polar coordinate visualization\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "# Compute angles and radii in weight space (2D)\n",
    "angles = np.arctan2(a_optimal[1], a_optimal[0])\n",
    "r_sphere = np.sqrt(np.sum(a_optimal**2, axis=0) + (b_optimal.flatten())**2)\n",
    "\n",
    "# Plot in polar coordinates\n",
    "radius = np.ones_like(angles)\n",
    "ax.scatter(angles, radius, c=b_optimal.flatten(), cmap='coolwarm', alpha=0.85, s=60)\n",
    "ax.set_title(f'Weight Space - BEST Model\\nNeurons: {weights_optimal.shape[0]}', fontsize=14)\n",
    "ax.grid(True, alpha=0.5)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('../data_result/plot/weights_polar_analysis_best.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"Polar coordinate analysis saved to ../data_result/plot/weights_polar_analysis_best.png\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b0f71",
   "metadata": {},
   "source": [
    "## Test with the L1 Penalty ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bceb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameter\n",
    "power = 2.1\n",
    "M = 50 # number greedy insertion selected\n",
    "num_iterations = 10\n",
    "loss_weights = (1.0, 0.0)\n",
    "pruning_threshold = 1e-13\n",
    "\n",
    "gamma = 1e-10\n",
    "alpha = 1e-5\n",
    "regularization = (gamma, alpha) \n",
    "th = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b7549f",
   "metadata": {},
   "source": [
    "The comparable model is about: 207 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac139d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model \n",
    "model_1 = model(torch.relu, power, regularization, optimizer='Adam', loss_weights = loss_weights)\n",
    "model_2 = model_outerweights(torch.relu, power, regularization, optimizer='SSN_TR', loss_weights = loss_weights, th = th)\n",
    "\n",
    "# Prepare data\n",
    "data_train, data_valid = model_1._prepare_data(0.8, data)\n",
    "\n",
    "# Set up the initializing weights and bias\n",
    "init_weights = np.random.randn(M, 2) * 0.1\n",
    "init_bias = np.random.randn(M)\n",
    "\n",
    "model_result, weight_raw, bias_raw, outerweight_raw = model_1.train(\n",
    "    data_train=data_train,\n",
    "    data_valid=data_valid,\n",
    "    inner_weights=init_weights, \n",
    "    inner_bias=init_bias,\n",
    "    iterations=1000,\n",
    "    display_every=200,\n",
    ")\n",
    "logger.info(\"Initialization done\"); logger.info(f\"Initial weights shape: {weight_raw.shape}, bias shape: {bias_raw.shape}\")\n",
    "\n",
    "# Training with improved logging\n",
    "KP_logger_L2_lasso, weight_raw_1, bias_raw_1, outerweight_raw_1 = retrain(\n",
    "    data_train, data_valid, model_1, model_2, model_result, weight_raw, bias_raw, outerweight_raw,\n",
    "    num_iterations, M, alpha, pruning_threshold, power, gamma\n",
    ")\n",
    "\n",
    "logger.info(\"Training completed with improved logging\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee82aba4",
   "metadata": {},
   "source": [
    "Reached 6e-3 at 157 neurones, 3.6e-3 at 231 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b6c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PLOT: Weight space visualization in polar coordinates\n",
    "# Shows the distribution of weights in 2D space for the BEST model (lowest validation loss)\n",
    "# =============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Extract weights from the current training run\n",
    "weights_run = KP_logger_L2_lasso.history['weights']\n",
    "biases_run = KP_logger_L2_lasso.history['biases']\n",
    "neurons_run = KP_logger_L2_lasso.history['neuron_count']\n",
    "\n",
    "print(f\"Training run: {len(weights_run)} iterations, max neurons: {max(neurons_run)}\")\n",
    "\n",
    "# Use the BEST model (lowest validation loss) instead of the iteration with most neurons\n",
    "if 'best_weights' in KP_logger_L2_lasso.history:\n",
    "    print(\"Using BEST model (lowest validation loss)\")\n",
    "weights_optimal = KP_logger_L2_lasso.history['best_weights']\n",
    "b_optimal = KP_logger_L2_lasso.history['best_biases'].reshape(1, -1)   # (1, n)\n",
    "best_loss = KP_logger_L2_lasso.history['best_test_loss']\n",
    "print(f\"Best validation loss: {best_loss:.6f}\")\n",
    "\n",
    "a_optimal = weights_optimal.T                         # (2, n)\n",
    "Z = a_optimal / (1 + b_optimal) \n",
    "\n",
    "# Create polar coordinate visualization\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "# Compute angles and radii in weight space (2D)\n",
    "angles = np.arctan2(a_optimal[1], a_optimal[0])\n",
    "r_sphere = np.sqrt(np.sum(a_optimal**2, axis=0) + (b_optimal.flatten())**2)\n",
    "\n",
    "# Plot in polar coordinates\n",
    "radius = np.ones_like(angles)\n",
    "ax.scatter(angles, radius, c=b_optimal.flatten(), cmap='coolwarm', alpha=0.85, s=60)\n",
    "ax.set_title(f'Weight Space - BEST Model (L1 Penalty)\\nNeurons: {weights_optimal.shape[0]}', fontsize=14)\n",
    "ax.grid(True, alpha=0.5)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('../data_result/plot/weights_polar_analysis_best_l1.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"Polar coordinate analysis saved to ../data_result/plot/weights_polar_analysis_best_l1.png\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Optional: Show weight evolution across iterations\n",
    "if len(weights_run) > 1:\n",
    "    print(f\"\\n=== Weight Evolution ===\")\n",
    "    print(\"Neuron counts across iterations:\")\n",
    "    for i, count in enumerate(neurons_run):\n",
    "        print(f\"Iteration {i}: {count} neurons\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
