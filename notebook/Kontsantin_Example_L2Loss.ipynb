{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeebd44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to Python path so model.py can find ssn and net modules\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from src.model import model\n",
    "from src.PDAP import retrain\n",
    "\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dfa9fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-21 19:15:50.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mLoaded data with shape: (961,), dtype: [('x', '<f8', (2,)), ('dv', '<f8', (2,)), ('v', '<f8')]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "path = '../data_result/raw_data/gauss_cos_31x31.npy'# Initialize the weights\n",
    "data = np.load(path)\n",
    "logger.info(f\"Loaded data with shape: {data.shape}, dtype: {data.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4099fadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameter\n",
    "power = 2.1\n",
    "M = 50 # number greedy insertion selected\n",
    "num_iterations = 10\n",
    "loss_weights = (1.0, 0.0)\n",
    "pruning_threshold = 1e-15\n",
    "\n",
    "gamma = 5.0\n",
    "alpha = 1e-5\n",
    "lr_adam = 1e-5\n",
    "regularization = (gamma, alpha) \n",
    "th = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4273cea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-21 19:15:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_configure_logger\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mModel initialized\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-21 19:15:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_configure_logger\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mModel initialized\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Initialize the models\n",
    "model_1 = model(activation=torch.relu, power=power, regularization=regularization, optimizer='Adam', loss_weights=loss_weights, th = th)\n",
    "model_2 = model(activation=torch.relu, power=power, regularization=regularization, optimizer='SSN_TR', loss_weights=loss_weights, th=th, train_outerweights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3470321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-21 19:15:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m150\u001b[0m - \u001b[1mTraining set: 864 samples, Validation set: 97 samples\u001b[0m\n",
      "\u001b[32m2025-09-21 19:15:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mData ranges - x: [-1.00, 1.00], v: [-0.72, 1.00], dv: [-5.86, 5.86]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# prepare the data\n",
    "data_train, data_valid = model_1._prepare_data(data)\n",
    "# Set up the initializing weights and bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e2c1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-21 19:15:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.PDAP\u001b[0m:\u001b[36mretrain\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mIteration 0 - Starting...\u001b[0m\n",
      "\u001b[32m2025-09-21 19:15:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m307\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-09-21 19:15:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m194\u001b[0m - \u001b[1mCreating network with 50 neurons\u001b[0m\n",
      "\u001b[32m2025-09-21 19:15:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m244\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-09-21 19:15:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m322\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-09-21 19:15:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=0.0\u001b[0m\n",
      "\u001b[32m2025-09-21 19:15:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.748650, Val Loss = 0.505255\u001b[0m\n",
      "\u001b[32m2025-09-21 19:16:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 0.060254, Val Loss = 1.833949\u001b[0m\n",
      "\u001b[32m2025-09-21 19:16:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 0.049605, Val Loss = 1.991746\u001b[0m\n",
      "\u001b[32m2025-09-21 19:16:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 0.044358, Val Loss = 1.825980\u001b[0m\n",
      "\u001b[32m2025-09-21 19:16:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 0.041023, Val Loss = 1.735556\u001b[0m\n",
      "\u001b[32m2025-09-21 19:16:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m376\u001b[0m - \u001b[1mBest validation loss: 0.505255. Restored best model from /Users/ruizhechao/Documents/NNforHJB/train_history/model_best.pt\u001b[0m\n",
      "\u001b[32m2025-09-21 19:16:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m307\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-09-21 19:16:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m227\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=1e-05, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-09-21 19:16:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m322\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-09-21 19:16:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=0.0\u001b[0m\n",
      "\u001b[32m2025-09-21 19:16:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.618906, Val Loss = 0.505196\u001b[0m\n",
      "\u001b[32m2025-09-21 19:16:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 0.618906, Val Loss = 0.505196\u001b[0m\n",
      "\u001b[32m2025-09-21 19:17:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 0.618906, Val Loss = 0.505196\u001b[0m\n",
      "\u001b[32m2025-09-21 19:17:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 0.618906, Val Loss = 0.505196\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_iteration, history \u001b[38;5;241m=\u001b[39m \u001b[43mretrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpruning_threshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/NNforHJB/src/PDAP.py:65\u001b[0m, in \u001b[0;36mretrain\u001b[0;34m(data_train, data_valid, model_1, model_2, num_iterations, M, threshold)\u001b[0m\n\u001b[1;32m     63\u001b[0m state_1 \u001b[38;5;241m=\u001b[39m model_1\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39mstate_dict()\n\u001b[1;32m     64\u001b[0m W_hidden, b_hidden, W_out \u001b[38;5;241m=\u001b[39m state_1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden.weight\u001b[39m\u001b[38;5;124m'\u001b[39m], state_1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden.bias\u001b[39m\u001b[38;5;124m'\u001b[39m], state_1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.weight\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 65\u001b[0m \u001b[43mmodel_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mouter_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Count and prune small weights\u001b[39;00m\n\u001b[1;32m     68\u001b[0m state_2 \u001b[38;5;241m=\u001b[39m model_2\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39mstate_dict()\n",
      "File \u001b[0;32m~/Documents/NNforHJB/src/model.py:349\u001b[0m, in \u001b[0;36mmodel.train\u001b[0;34m(self, data_train, data_valid, inner_weights, inner_bias, outer_weights, iterations, batch_size, display_every)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, (SSN, SSN_TR)):\n\u001b[0;32m--> 349\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    351\u001b[0m     total_loss, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_loss(train_x_tensor, train_v_tensor, train_dv_tensor)\n",
      "File \u001b[0;32m~/Documents/NNforHJB/.venv/lib/python3.9/site-packages/torch/optim/optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m             )\n\u001b[0;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_iteration, history = retrain(data_train, data_valid, model_1, model_2, num_iterations, M, pruning_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0db354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-21 17:31:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_configure_logger\u001b[0m:\u001b[36m104\u001b[0m - \u001b[1mModel initialized\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# def save(self):\n",
    "#     \"\"\"Save training history.\"\"\"\n",
    "#     timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "#     filename = f\"training_history_{timestamp}.pkl\"\n",
    "#     filepath = os.path.join(self.stats_dir, filename)\n",
    "    \n",
    "#     with open(filepath, 'wb') as f:\n",
    "#         pickle.dump(self.history, f)\n",
    "        \n",
    "#     logger.info(f\"Saved training history to {filepath}\")\n",
    "#     return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "256a18d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-21 17:32:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m306\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-09-21 17:32:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mCreating network with 50 neurons\u001b[0m\n",
      "\u001b[32m2025-09-21 17:32:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m243\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-09-21 17:32:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m321\u001b[0m - \u001b[1mTraining hyperparameters: iterations=1000, batch_size=1620, display_every=200\u001b[0m\n",
      "\u001b[32m2025-09-21 17:32:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m322\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=0.0\u001b[0m\n",
      "\u001b[32m2025-09-21 17:32:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m361\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.758605, Val Loss = 1.770856\u001b[0m\n",
      "\u001b[32m2025-09-21 17:32:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m361\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.138397, Val Loss = 0.556594\u001b[0m\n",
      "\u001b[32m2025-09-21 17:32:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m361\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.107812, Val Loss = 1.682160\u001b[0m\n",
      "\u001b[32m2025-09-21 17:32:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m361\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.098375, Val Loss = 1.937616\u001b[0m\n",
      "\u001b[32m2025-09-21 17:32:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m361\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.092920, Val Loss = 1.895901\u001b[0m\n",
      "\u001b[32m2025-09-21 17:32:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mBest validation loss: 0.556594. Restored best model from /Users/ruizhechao/Documents/NNforHJB/train_history/model_best.pt\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss_history': [0.7586048966332555,\n",
       "  0.13839654131324466,\n",
       "  0.10781152371223449,\n",
       "  0.09837455612629147,\n",
       "  0.09292016148593406],\n",
       " 'val_history': [1.7708560374591833,\n",
       "  0.5565938616000192,\n",
       "  1.6821601476086416,\n",
       "  1.9376158157305623,\n",
       "  1.8959011655118543],\n",
       " 'best_epoch': 200,\n",
       " 'config': {'optimizer': 'Adam',\n",
       "  'activation': 'relu',\n",
       "  'power': 2.1,\n",
       "  'regularization': {'gamma': 5.0, 'alpha': 1e-05, 'th': 0.5},\n",
       "  'loss_weights': {'value': 1.0, 'grad': 0.0},\n",
       "  'training_percentage': 0.9,\n",
       "  'train_outerweights': False,\n",
       "  'iterations': 1000,\n",
       "  'display_every': 200}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.train(\n",
    "    data_train=data_train,\n",
    "    data_valid=data_valid,\n",
    "    inner_weights=init_weights, \n",
    "    inner_bias=init_bias,\n",
    "    iterations=1000,\n",
    "    display_every=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b80147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with improved logging\n",
    "KP_logger_L2_nc, weight_raw, bias_raw, outerweight_raw = retrain(\n",
    "    data_train, data_valid, \n",
    "    model_1, model_2, model_result, weight_raw, bias_raw, outerweight_raw,\n",
    "    num_iterations, M, alpha, pruning_threshold, power, gamma\n",
    ")\n",
    "\n",
    "logger.info(\"Training completed with improved logging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cb5add",
   "metadata": {},
   "source": [
    "Reached 6.04e-3 at 179 neurones model is about 126 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adb6393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PLOT: Weight space visualization in polar coordinates\n",
    "# Shows the distribution of weights in 2D space for the BEST model (lowest validation loss)\n",
    "# =============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Extract weights from the current training run\n",
    "weights_run = KP_logger_L2_nc.history['weights']\n",
    "biases_run = KP_logger_L2_nc.history['biases']\n",
    "neurons_run = KP_logger_L2_nc.history['neuron_count']\n",
    "\n",
    "print(f\"Training run: {len(weights_run)} iterations, max neurons: {max(neurons_run)}\")\n",
    "\n",
    "# Use the BEST model (lowest validation loss) instead of the iteration with most neurons\n",
    "print(\"Using BEST model (lowest validation loss)\")\n",
    "weights_optimal = KP_logger_L2_nc.history['best_weights']\n",
    "b_optimal = KP_logger_L2_nc.history['best_biases'].reshape(1, -1)   # (1, n)\n",
    "best_loss = KP_logger_L2_nc.history['best_test_loss']\n",
    "print(f\"Best validation loss: {best_loss:.6f}\")\n",
    "\n",
    "a_optimal = weights_optimal.T                         # (2, n)\n",
    "Z = a_optimal / (1 + b_optimal) \n",
    "\n",
    "# Create polar coordinate visualization\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "# Compute angles and radii in weight space (2D)\n",
    "angles = np.arctan2(a_optimal[1], a_optimal[0])\n",
    "r_sphere = np.sqrt(np.sum(a_optimal**2, axis=0) + (b_optimal.flatten())**2)\n",
    "\n",
    "# Plot in polar coordinates\n",
    "radius = np.ones_like(angles)\n",
    "ax.scatter(angles, radius, c=b_optimal.flatten(), cmap='coolwarm', alpha=0.85, s=60)\n",
    "ax.set_title(f'Weight Space - BEST Model\\nNeurons: {weights_optimal.shape[0]}', fontsize=14)\n",
    "ax.grid(True, alpha=0.5)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('../data_result/plot/weights_polar_analysis_best.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"Polar coordinate analysis saved to ../data_result/plot/weights_polar_analysis_best.png\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b0f71",
   "metadata": {},
   "source": [
    "## Test with the L1 Penalty ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bceb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameter\n",
    "power = 2.1\n",
    "M = 50 # number greedy insertion selected\n",
    "num_iterations = 10\n",
    "loss_weights = (1.0, 0.0)\n",
    "pruning_threshold = 1e-13\n",
    "\n",
    "gamma = 1e-10\n",
    "alpha = 1e-5\n",
    "regularization = (gamma, alpha) \n",
    "th = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b7549f",
   "metadata": {},
   "source": [
    "The comparable model is about: 207 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac139d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model \n",
    "model_1 = model(torch.relu, power, regularization, optimizer='Adam', loss_weights = loss_weights)\n",
    "model_2 = model_outerweights(torch.relu, power, regularization, optimizer='SSN_TR', loss_weights = loss_weights, th = th)\n",
    "\n",
    "# Prepare data\n",
    "data_train, data_valid = model_1._prepare_data(0.8, data)\n",
    "\n",
    "# Set up the initializing weights and bias\n",
    "init_weights = np.random.randn(M, 2) * 0.1\n",
    "init_bias = np.random.randn(M)\n",
    "\n",
    "model_result, weight_raw, bias_raw, outerweight_raw = model_1.train(\n",
    "    data_train=data_train,\n",
    "    data_valid=data_valid,\n",
    "    inner_weights=init_weights, \n",
    "    inner_bias=init_bias,\n",
    "    iterations=1000,\n",
    "    display_every=200,\n",
    ")\n",
    "logger.info(\"Initialization done\"); logger.info(f\"Initial weights shape: {weight_raw.shape}, bias shape: {bias_raw.shape}\")\n",
    "\n",
    "# Training with improved logging\n",
    "KP_logger_L2_lasso, weight_raw_1, bias_raw_1, outerweight_raw_1 = retrain(\n",
    "    data_train, data_valid, model_1, model_2, model_result, weight_raw, bias_raw, outerweight_raw,\n",
    "    num_iterations, M, alpha, pruning_threshold, power, gamma\n",
    ")\n",
    "\n",
    "logger.info(\"Training completed with improved logging\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee82aba4",
   "metadata": {},
   "source": [
    "Reached 6e-3 at 157 neurones, 3.6e-3 at 231 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b6c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PLOT: Weight space visualization in polar coordinates\n",
    "# Shows the distribution of weights in 2D space for the BEST model (lowest validation loss)\n",
    "# =============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Extract weights from the current training run\n",
    "weights_run = KP_logger_L2_lasso.history['weights']\n",
    "biases_run = KP_logger_L2_lasso.history['biases']\n",
    "neurons_run = KP_logger_L2_lasso.history['neuron_count']\n",
    "\n",
    "print(f\"Training run: {len(weights_run)} iterations, max neurons: {max(neurons_run)}\")\n",
    "\n",
    "# Use the BEST model (lowest validation loss) instead of the iteration with most neurons\n",
    "if 'best_weights' in KP_logger_L2_lasso.history:\n",
    "    print(\"Using BEST model (lowest validation loss)\")\n",
    "weights_optimal = KP_logger_L2_lasso.history['best_weights']\n",
    "b_optimal = KP_logger_L2_lasso.history['best_biases'].reshape(1, -1)   # (1, n)\n",
    "best_loss = KP_logger_L2_lasso.history['best_test_loss']\n",
    "print(f\"Best validation loss: {best_loss:.6f}\")\n",
    "\n",
    "a_optimal = weights_optimal.T                         # (2, n)\n",
    "Z = a_optimal / (1 + b_optimal) \n",
    "\n",
    "# Create polar coordinate visualization\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "# Compute angles and radii in weight space (2D)\n",
    "angles = np.arctan2(a_optimal[1], a_optimal[0])\n",
    "r_sphere = np.sqrt(np.sum(a_optimal**2, axis=0) + (b_optimal.flatten())**2)\n",
    "\n",
    "# Plot in polar coordinates\n",
    "radius = np.ones_like(angles)\n",
    "ax.scatter(angles, radius, c=b_optimal.flatten(), cmap='coolwarm', alpha=0.85, s=60)\n",
    "ax.set_title(f'Weight Space - BEST Model (L1 Penalty)\\nNeurons: {weights_optimal.shape[0]}', fontsize=14)\n",
    "ax.grid(True, alpha=0.5)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('../data_result/plot/weights_polar_analysis_best_l1.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"Polar coordinate analysis saved to ../data_result/plot/weights_polar_analysis_best_l1.png\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Optional: Show weight evolution across iterations\n",
    "if len(weights_run) > 1:\n",
    "    print(f\"\\n=== Weight Evolution ===\")\n",
    "    print(\"Neuron counts across iterations:\")\n",
    "    for i, count in enumerate(neurons_run):\n",
    "        print(f\"Iteration {i}: {count} neurons\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
