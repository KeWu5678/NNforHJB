{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "00dd79be",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/ruizhechao/Documents/NNforHJB\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/ruizhechao/Documents/NNforHJB/.venv/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "%cd ..\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "# %load_ext nb_black\n",
        "# notebook setup\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0, Path().absolute().parent.as_posix())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4099fadd",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load the data\n",
        "import numpy as np\n",
        "\n",
        "path = 'rawdata/raw_data/data/gaussian_window_1000.npy'\n",
        "data = np.load(path)\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "73bfe79b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# prepare the data\n",
        "# data is a structured numpy array with fields: 'x', 'dv', 'v'\n",
        "# convert to the dict format expected by model._prepare_data\n",
        "\n",
        "data_dict = {\n",
        "    \"x\": np.asarray(data[\"x\"], dtype=np.float64),    # shape (N, 2)\n",
        "    \"v\": np.asarray(data[\"v\"], dtype=np.float64),    # shape (N,)\n",
        "    \"dv\": np.asarray(data[\"dv\"], dtype=np.float64),  # shape (N, 2)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1853ac4e",
      "metadata": {},
      "source": [
        "## Test effect of different gamma with increased neurons added"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "76b3c38d",
      "metadata": {},
      "outputs": [],
      "source": [
        "gammas = [10.0, 1.0, 1e-1, 1e-2, 0.0]\n",
        "alpha = 1e-5\n",
        "power = 1.0\n",
        "loss_weight_h1 = [1.0, 1.0]\n",
        "loss_weight_l2 = [1.0, 0.0]\n",
        "\n",
        "num_iterations = 15\n",
        "num_insertions = 50\n",
        "pruning_threshold = 1e-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "15961e8a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-01-25 10:22:22.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mModel initialized\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:22.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mModel initialized\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:22.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mTraining set: 900 samples, Validation set: 100 samples\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:22.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 50 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:23.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:23.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.630507, Val Loss = 0.657735\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:23.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.178618, Val Loss = 0.195876\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:23.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.128131, Val Loss = 0.147780\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:23.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.109960, Val Loss = 0.130392\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:23.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.100405, Val Loss = 0.120494\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:23.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.093513, Val Loss = 0.112821\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:23.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.087695, Val Loss = 0.106076\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:23.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.082502, Val Loss = 0.099930\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:23.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.077783, Val Loss = 0.094294\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:24.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.073475, Val Loss = 0.089116\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:24.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.084405 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:24.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:24.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:24.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.065663, Val Loss = 0.068360\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:24.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.048137, Val Loss = 0.050985\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:25.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.042138, Val Loss = 0.044470\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:25.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.038941, Val Loss = 0.041037\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:26.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.035491, Val Loss = 0.038085\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:26.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.033178, Val Loss = 0.035254\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:27.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.030991, Val Loss = 0.032923\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:28.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.028911, Val Loss = 0.030533\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:28.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.027477, Val Loss = 0.029054\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:29.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.025483, Val Loss = 0.027009\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:29.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.024925 at iteration 996\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:31.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 84 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:31.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:31.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 2.481225, Val Loss = 1.979440\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:31.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.073576, Val Loss = 0.089357\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:31.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.069565, Val Loss = 0.084297\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:31.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.066393, Val Loss = 0.080290\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:31.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.063597, Val Loss = 0.076788\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:31.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.061046, Val Loss = 0.073614\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:31.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.058693, Val Loss = 0.070699\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:31.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.056519, Val Loss = 0.068007\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:31.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.054506, Val Loss = 0.065514\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:31.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.052642, Val Loss = 0.063203\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:32.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.061080 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:32.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:32.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:32.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.049694, Val Loss = 0.049368\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:32.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.032813, Val Loss = 0.032612\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:33.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.025216, Val Loss = 0.024612\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:33.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.021413, Val Loss = 0.020847\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:34.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.018861, Val Loss = 0.018562\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:35.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.016923, Val Loss = 0.016625\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:35.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.015339, Val Loss = 0.014999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:36.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.013970, Val Loss = 0.013689\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:37.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.012184, Val Loss = 0.011912\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:37.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.010623, Val Loss = 0.010293\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:38.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.009174 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:39.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 124 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:39.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:39.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 3.992527, Val Loss = 2.655651\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:40.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.069683, Val Loss = 0.084218\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:40.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.066600, Val Loss = 0.080327\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:40.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.063760, Val Loss = 0.076764\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:40.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.061137, Val Loss = 0.073480\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:40.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.058710, Val Loss = 0.070445\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:40.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.056465, Val Loss = 0.067634\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:40.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.054386, Val Loss = 0.065028\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:40.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.052462, Val Loss = 0.062612\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:40.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.050678, Val Loss = 0.060370\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:41.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.058309 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:41.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:41.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:41.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.048082, Val Loss = 0.046239\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:41.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.029629, Val Loss = 0.030168\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:42.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.022333, Val Loss = 0.022089\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:43.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.019055, Val Loss = 0.018682\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:43.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.017635, Val Loss = 0.017208\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:44.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.016221, Val Loss = 0.015924\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:45.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.015012, Val Loss = 0.014698\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:46.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.013759, Val Loss = 0.013380\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:46.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.012448, Val Loss = 0.011955\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:47.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.011351, Val Loss = 0.010839\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:48.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.009495 at iteration 996\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:49.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 160 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:49.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:49.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.054494, Val Loss = 0.616314\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:50.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.075536, Val Loss = 0.086432\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:50.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.061150, Val Loss = 0.073269\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:50.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.055768, Val Loss = 0.068005\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:50.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.052703, Val Loss = 0.064640\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:50.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.050324, Val Loss = 0.061806\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:50.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.048229, Val Loss = 0.059205\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:50.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.046311, Val Loss = 0.056777\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:50.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.044537, Val Loss = 0.054506\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:50.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.042891, Val Loss = 0.052386\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:50.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.050427 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:50.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:50.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:50.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.040484, Val Loss = 0.036582\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:51.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.025891, Val Loss = 0.025658\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:52.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.020297, Val Loss = 0.019599\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:53.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.018256, Val Loss = 0.017722\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:53.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.017018, Val Loss = 0.016279\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:54.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.015728, Val Loss = 0.015114\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:55.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.014672, Val Loss = 0.014009\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:56.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.013803, Val Loss = 0.013161\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:56.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.012965, Val Loss = 0.012043\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:57.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.011888, Val Loss = 0.010967\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:58.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.010153 at iteration 986\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:59.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 197 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:59.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:59.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.987424, Val Loss = 1.010388\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:59.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.076886, Val Loss = 0.093464\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:59.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.068521, Val Loss = 0.083788\u001b[0m\n",
            "\u001b[32m2026-01-25 10:22:59.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.064350, Val Loss = 0.078619\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:00.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.061345, Val Loss = 0.074814\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:00.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.058762, Val Loss = 0.071553\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:00.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.056414, Val Loss = 0.068604\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:00.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.054246, Val Loss = 0.065887\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:00.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.052234, Val Loss = 0.063369\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:00.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.050366, Val Loss = 0.061030\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:01.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.058875 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:01.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:01.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:01.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.046241, Val Loss = 0.043641\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:02.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.026248, Val Loss = 0.025404\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:03.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.022553, Val Loss = 0.021446\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:04.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.020771, Val Loss = 0.019490\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:05.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.019472, Val Loss = 0.018397\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:06.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.018642, Val Loss = 0.017639\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:07.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.017656, Val Loss = 0.016641\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:08.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.016552, Val Loss = 0.015523\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:09.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.015413, Val Loss = 0.014407\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:10.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.014446, Val Loss = 0.013380\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:11.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.012566 at iteration 996\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:13.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 230 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:13.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:13.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.109642, Val Loss = 0.111090\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:13.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.078794, Val Loss = 0.098414\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:13.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.074508, Val Loss = 0.093210\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:13.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.070637, Val Loss = 0.088398\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:14.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.067073, Val Loss = 0.083917\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:14.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.063776, Val Loss = 0.079745\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:14.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.060720, Val Loss = 0.075862\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:14.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.057887, Val Loss = 0.072251\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:14.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.055261, Val Loss = 0.068894\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:14.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.052825, Val Loss = 0.065773\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:14.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.062899 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:14.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:14.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:14.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.047507, Val Loss = 0.047244\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:15.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.035818, Val Loss = 0.036713\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:17.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.029878, Val Loss = 0.030338\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:18.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.026951, Val Loss = 0.027045\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:19.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.025225, Val Loss = 0.024859\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:20.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.024099, Val Loss = 0.023669\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:22.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.022582, Val Loss = 0.022191\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:23.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.021274, Val Loss = 0.020806\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:24.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.020061, Val Loss = 0.019567\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:25.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.018769, Val Loss = 0.018199\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:26.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.017058 at iteration 996\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:28.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 269 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:28.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:28.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.197988, Val Loss = 0.120755\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:29.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.054669, Val Loss = 0.067018\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:29.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.051331, Val Loss = 0.062844\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:29.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.049141, Val Loss = 0.059994\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:29.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.047317, Val Loss = 0.057616\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:29.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.045672, Val Loss = 0.055481\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:29.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.044155, Val Loss = 0.053518\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:29.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.042747, Val Loss = 0.051698\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:30.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.041440, Val Loss = 0.050006\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:30.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.040225, Val Loss = 0.048431\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:30.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.046977 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:30.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:30.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:30.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.036045, Val Loss = 0.033599\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:31.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.019604, Val Loss = 0.018936\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:33.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.015445, Val Loss = 0.014351\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:34.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.013787, Val Loss = 0.012589\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:36.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.012725, Val Loss = 0.011625\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:37.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.011854, Val Loss = 0.010870\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:39.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.010983, Val Loss = 0.010069\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:40.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.009910, Val Loss = 0.008881\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:42.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.009104, Val Loss = 0.008164\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:43.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.008357, Val Loss = 0.007364\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:45.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.006771 at iteration 994\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:46.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 299 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:46.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:46.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.090457, Val Loss = 0.105647\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:47.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.081201, Val Loss = 0.099599\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:47.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.077102, Val Loss = 0.094389\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:47.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.073412, Val Loss = 0.089750\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:47.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.070018, Val Loss = 0.085510\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:47.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.066877, Val Loss = 0.081598\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:48.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.063967, Val Loss = 0.077975\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:48.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.061268, Val Loss = 0.074614\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:48.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.058765, Val Loss = 0.071493\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:48.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.056443, Val Loss = 0.068592\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:48.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.065922 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:48.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:48.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:48.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.051058, Val Loss = 0.048841\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:50.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.033670, Val Loss = 0.033802\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:51.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.028573, Val Loss = 0.027854\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:53.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.025858, Val Loss = 0.024997\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:55.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.024231, Val Loss = 0.023155\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:56.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.022757, Val Loss = 0.021429\u001b[0m\n",
            "\u001b[32m2026-01-25 10:23:58.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.021566, Val Loss = 0.020589\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:00.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.020401, Val Loss = 0.019654\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:01.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.019388, Val Loss = 0.018372\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:03.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.018303, Val Loss = 0.017176\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:05.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.015840 at iteration 996\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:07.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 343 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:07.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:07.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.461144, Val Loss = 0.327613\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:08.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.077943, Val Loss = 0.094059\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:08.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.072630, Val Loss = 0.088545\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:08.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.068887, Val Loss = 0.084263\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:08.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.065693, Val Loss = 0.080415\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:08.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.062796, Val Loss = 0.076838\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:08.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.060122, Val Loss = 0.073499\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:09.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.057646, Val Loss = 0.070385\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:09.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.055349, Val Loss = 0.067484\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:09.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.053217, Val Loss = 0.064784\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:09.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.062295 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:09.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:09.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:09.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.049341, Val Loss = 0.047932\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:11.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.035603, Val Loss = 0.037332\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:13.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.027132, Val Loss = 0.027309\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:15.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.024046, Val Loss = 0.024134\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:17.962\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.022391, Val Loss = 0.022653\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:20.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.020710, Val Loss = 0.020944\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:22.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.019399, Val Loss = 0.019582\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:24.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.018255, Val Loss = 0.018495\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:26.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.017105, Val Loss = 0.017480\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:28.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.016026, Val Loss = 0.015944\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:30.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.014976 at iteration 996\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:33.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 381 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:33.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:33.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 8.053192, Val Loss = 0.792561\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:33.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.058721, Val Loss = 0.071422\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:33.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.056257, Val Loss = 0.068224\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:33.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.054033, Val Loss = 0.065373\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:33.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.051983, Val Loss = 0.062763\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:34.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.050083, Val Loss = 0.060352\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:34.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.048321, Val Loss = 0.058115\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:34.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.046686, Val Loss = 0.056037\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:34.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.045167, Val Loss = 0.054104\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:34.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.043757, Val Loss = 0.052305\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:35.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.050647 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:35.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:35.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:35.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.040362, Val Loss = 0.038392\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:37.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.024132, Val Loss = 0.024001\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:39.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.018280, Val Loss = 0.017341\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:41.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.016220, Val Loss = 0.015356\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:44.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.015067, Val Loss = 0.014255\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:46.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.013589, Val Loss = 0.012779\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:48.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.012599, Val Loss = 0.011870\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:51.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.011494, Val Loss = 0.010697\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:53.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.010601, Val Loss = 0.009703\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:55.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.009869, Val Loss = 0.009041\u001b[0m\n",
            "\u001b[32m2026-01-25 10:24:58.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.008129 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:00.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 416 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:00.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:00.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.400366, Val Loss = 0.136892\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:00.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.072262, Val Loss = 0.088397\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:00.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.063906, Val Loss = 0.078457\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:01.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.059833, Val Loss = 0.073257\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:01.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.056909, Val Loss = 0.069475\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:01.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.054394, Val Loss = 0.066255\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:01.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.052104, Val Loss = 0.063352\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:01.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.049987, Val Loss = 0.060684\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:02.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.048024, Val Loss = 0.058214\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:02.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.046200, Val Loss = 0.055920\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:02.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.053807 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:02.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:02.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:02.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.040656, Val Loss = 0.039772\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:04.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.027001, Val Loss = 0.027489\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:06.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.021151, Val Loss = 0.020865\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:08.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.019392, Val Loss = 0.019298\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:10.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.018028, Val Loss = 0.018105\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:12.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.016923, Val Loss = 0.017090\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:14.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.015791, Val Loss = 0.016011\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:16.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.011367, Val Loss = 0.010160\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:18.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.009620, Val Loss = 0.008819\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:20.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.008829, Val Loss = 0.008084\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:22.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.007250 at iteration 996\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:23.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 453 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:23.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:23.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.446800, Val Loss = 0.084462\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:24.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.060683, Val Loss = 0.074089\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:24.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.057797, Val Loss = 0.070736\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:24.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.055309, Val Loss = 0.067700\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:24.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.053042, Val Loss = 0.064871\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:25.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.050947, Val Loss = 0.062227\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:25.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.049004, Val Loss = 0.059758\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:25.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.047199, Val Loss = 0.057455\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:25.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.045522, Val Loss = 0.055308\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:26.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.043965, Val Loss = 0.053307\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:26.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.051461 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:26.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:26.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:26.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.041526, Val Loss = 0.039627\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:29.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.023011, Val Loss = 0.023432\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:32.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.018787, Val Loss = 0.018921\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:35.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.016738, Val Loss = 0.016796\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:38.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.015347, Val Loss = 0.015538\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:41.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.014277, Val Loss = 0.014329\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:44.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.013221, Val Loss = 0.013099\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:47.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.012176, Val Loss = 0.012195\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:50.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.011247, Val Loss = 0.010957\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:53.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.010380, Val Loss = 0.010078\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:56.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.009386 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:58.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 492 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:58.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:58.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.122915, Val Loss = 0.097721\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:59.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.075778, Val Loss = 0.092692\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:59.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.072068, Val Loss = 0.087995\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:59.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.068674, Val Loss = 0.083737\u001b[0m\n",
            "\u001b[32m2026-01-25 10:25:59.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.065540, Val Loss = 0.079822\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:00.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.062636, Val Loss = 0.076202\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:00.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.059945, Val Loss = 0.072846\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:00.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.057450, Val Loss = 0.069732\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:01.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.055136, Val Loss = 0.066839\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:01.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.052989, Val Loss = 0.064152\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:01.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.061679 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:01.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:01.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:01.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.047948, Val Loss = 0.046724\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:04.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.030715, Val Loss = 0.030930\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:07.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.025296, Val Loss = 0.026157\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:10.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.023326, Val Loss = 0.023754\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:13.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.021797, Val Loss = 0.021994\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:16.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.020334, Val Loss = 0.020706\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:20.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.018720, Val Loss = 0.018679\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:23.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.017398, Val Loss = 0.017283\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:26.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.016125, Val Loss = 0.015998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:30.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.014869, Val Loss = 0.014667\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:33.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.012969 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:36.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 528 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:36.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:36.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.727085, Val Loss = 0.110376\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:36.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.074517, Val Loss = 0.091291\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:36.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.068355, Val Loss = 0.083691\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:36.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.064700, Val Loss = 0.078982\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:37.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.061770, Val Loss = 0.075217\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:37.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.059154, Val Loss = 0.071893\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:37.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.056751, Val Loss = 0.068859\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:37.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.054525, Val Loss = 0.066059\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:37.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.052461, Val Loss = 0.063463\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:38.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.050545, Val Loss = 0.061052\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:38.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.058833 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:38.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:38.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:38.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.044890, Val Loss = 0.043987\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:41.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.026920, Val Loss = 0.027155\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:43.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.022254, Val Loss = 0.022084\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:46.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.019839, Val Loss = 0.019921\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:49.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.018173, Val Loss = 0.018112\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:52.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.016764, Val Loss = 0.016707\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:54.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.015159, Val Loss = 0.014926\u001b[0m\n",
            "\u001b[32m2026-01-25 10:26:57.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.014069, Val Loss = 0.013926\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:00.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.013056, Val Loss = 0.012817\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:03.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.012025, Val Loss = 0.011816\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:06.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.010464 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:08.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 569 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:08.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:08.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 8.690909, Val Loss = 0.124506\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:08.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.059231, Val Loss = 0.072680\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:09.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.056741, Val Loss = 0.069601\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:09.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.054464, Val Loss = 0.066736\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:09.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.052359, Val Loss = 0.064065\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:09.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.050409, Val Loss = 0.061576\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:10.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.048600, Val Loss = 0.059258\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:10.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.046921, Val Loss = 0.057100\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:10.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.045364, Val Loss = 0.055093\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:11.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.043919, Val Loss = 0.053225\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:11.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.051502 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:11.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:11.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:11.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.033941, Val Loss = 0.035278\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:15.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.022348, Val Loss = 0.022964\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:19.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.017332, Val Loss = 0.017585\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:23.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.015043, Val Loss = 0.015309\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:27.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.013655, Val Loss = 0.013988\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:31.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.012549, Val Loss = 0.012648\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:35.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.011292, Val Loss = 0.011405\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:39.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.010316, Val Loss = 0.010314\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:43.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.009289, Val Loss = 0.009136\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:47.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.008421, Val Loss = 0.008218\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:51.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.007372 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:54.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mModel initialized\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:54.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mModel initialized\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:54.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mTraining set: 900 samples, Validation set: 100 samples\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:54.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 50 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:54.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:54.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.737420, Val Loss = 0.783029\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:54.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.241805, Val Loss = 0.292303\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:54.754\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.205402, Val Loss = 0.246997\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:54.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.184114, Val Loss = 0.220281\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:54.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.166830, Val Loss = 0.199049\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:55.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.151824, Val Loss = 0.180868\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:55.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.138608, Val Loss = 0.164938\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:55.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.126913, Val Loss = 0.150909\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:55.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.116553, Val Loss = 0.138482\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:55.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.107364, Val Loss = 0.127452\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:55.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.117743 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:55.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:55.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:55.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.097096, Val Loss = 0.104237\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:56.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.081820, Val Loss = 0.091582\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:56.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.074119, Val Loss = 0.082440\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:57.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.069458, Val Loss = 0.076951\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:57.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.066097, Val Loss = 0.073722\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:58.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.063499, Val Loss = 0.070770\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:58.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.061210, Val Loss = 0.068714\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:59.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.059448, Val Loss = 0.066717\u001b[0m\n",
            "\u001b[32m2026-01-25 10:27:59.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.057631, Val Loss = 0.064952\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:00.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.055656, Val Loss = 0.062468\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:01.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.059654 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:02.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 86 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:02.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:02.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.712709, Val Loss = 0.657452\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:02.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.144014, Val Loss = 0.174500\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:02.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.119217, Val Loss = 0.145453\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:02.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.106413, Val Loss = 0.129650\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:03.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.096542, Val Loss = 0.117498\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:03.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.088039, Val Loss = 0.107116\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:03.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.080549, Val Loss = 0.098001\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:03.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.073922, Val Loss = 0.089936\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:03.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.068050, Val Loss = 0.082782\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:03.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.062847, Val Loss = 0.076426\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:03.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.070829 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:03.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:03.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:03.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.055935, Val Loss = 0.061402\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:04.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.046359, Val Loss = 0.051101\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:04.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.041543, Val Loss = 0.045673\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:05.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.038278, Val Loss = 0.042049\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:06.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.035924, Val Loss = 0.039742\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:06.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.033888, Val Loss = 0.037542\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:07.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.031892, Val Loss = 0.035402\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:08.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.030004, Val Loss = 0.033424\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:08.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.028048, Val Loss = 0.031192\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:09.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.026188, Val Loss = 0.029150\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:10.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.027199 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:11.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 122 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:11.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:11.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.313806, Val Loss = 0.310213\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:11.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.096268, Val Loss = 0.111072\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:11.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.071968, Val Loss = 0.087531\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:11.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.064579, Val Loss = 0.079489\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:12.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.060241, Val Loss = 0.074240\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:12.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.056731, Val Loss = 0.069815\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:12.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.053657, Val Loss = 0.065883\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:12.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.050925, Val Loss = 0.062361\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:12.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.048488, Val Loss = 0.059203\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:12.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.046313, Val Loss = 0.056367\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:12.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.053842 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:12.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:12.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:12.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.042309, Val Loss = 0.046185\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:13.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.029689, Val Loss = 0.033602\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:14.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.023730, Val Loss = 0.026979\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:14.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.020120, Val Loss = 0.022745\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:15.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.017355, Val Loss = 0.019771\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:16.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.015068, Val Loss = 0.017176\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:17.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.013496, Val Loss = 0.015342\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:18.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.012514, Val Loss = 0.014399\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:18.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.011657, Val Loss = 0.013366\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:19.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.010857, Val Loss = 0.012156\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:20.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.011373 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:21.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 162 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:21.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:21.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 5.442808, Val Loss = 3.006525\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:21.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.078260, Val Loss = 0.091622\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:21.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.061818, Val Loss = 0.075394\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:22.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.056548, Val Loss = 0.069483\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:22.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.053292, Val Loss = 0.065465\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:22.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.050608, Val Loss = 0.062045\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:22.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.048245, Val Loss = 0.058999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:22.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.046138, Val Loss = 0.056266\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:22.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.044256, Val Loss = 0.053809\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:22.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.042572, Val Loss = 0.051598\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:22.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.049626 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:22.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:22.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:22.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.039252, Val Loss = 0.042820\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:23.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.025620, Val Loss = 0.029258\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:24.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.019923, Val Loss = 0.022707\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:25.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.016348, Val Loss = 0.018932\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:26.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.012979, Val Loss = 0.014759\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:27.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.011132, Val Loss = 0.012753\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:28.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.010137, Val Loss = 0.011388\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:29.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.009411, Val Loss = 0.010799\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:30.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.008756, Val Loss = 0.009592\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:31.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.008144, Val Loss = 0.008963\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:32.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.008196 at iteration 994\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:33.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 201 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:33.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:33.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 3.529147, Val Loss = 1.679182\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:33.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.067112, Val Loss = 0.083113\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:34.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.060773, Val Loss = 0.075250\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:34.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.056669, Val Loss = 0.069986\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:34.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.053234, Val Loss = 0.065593\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:34.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.050198, Val Loss = 0.061718\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:34.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.047487, Val Loss = 0.058254\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:34.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.045061, Val Loss = 0.055144\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:34.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.042890, Val Loss = 0.052347\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:35.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.040946, Val Loss = 0.049830\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:35.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.047585 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:35.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:35.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:35.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.037242, Val Loss = 0.040206\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:36.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.025213, Val Loss = 0.028574\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:37.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.020269, Val Loss = 0.022905\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:38.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.017105, Val Loss = 0.019059\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:40.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.014361, Val Loss = 0.016041\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:41.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.009366, Val Loss = 0.011783\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:42.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.008289, Val Loss = 0.009701\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:43.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.007674, Val Loss = 0.008816\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:44.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.007149, Val Loss = 0.008116\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:45.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.006678, Val Loss = 0.007410\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:47.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.006737 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:48.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 238 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:48.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:48.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 3.277773, Val Loss = 1.158602\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:48.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.051292, Val Loss = 0.062047\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:49.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.047493, Val Loss = 0.057774\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:49.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.044796, Val Loss = 0.054486\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:49.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.042487, Val Loss = 0.051591\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:49.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.040436, Val Loss = 0.048990\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:49.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.038602, Val Loss = 0.046647\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:49.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.036960, Val Loss = 0.044536\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:49.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.035489, Val Loss = 0.042635\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:50.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.034170, Val Loss = 0.040920\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:50.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.039389 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:50.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:50.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:50.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.031168, Val Loss = 0.032517\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:51.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.020073, Val Loss = 0.022276\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:52.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.015827, Val Loss = 0.017390\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:53.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.012107, Val Loss = 0.013262\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:55.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.009656, Val Loss = 0.010233\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:56.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.008315, Val Loss = 0.008761\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:57.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.006255, Val Loss = 0.006565\u001b[0m\n",
            "\u001b[32m2026-01-25 10:28:59.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.005528, Val Loss = 0.005941\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:00.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.005139, Val Loss = 0.005373\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:02.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.004504, Val Loss = 0.004720\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:03.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.004170 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:04.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 273 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:04.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:04.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.270225, Val Loss = 0.118657\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:04.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.052298, Val Loss = 0.063735\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:05.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.048464, Val Loss = 0.059396\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:05.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.045501, Val Loss = 0.055798\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:05.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.042918, Val Loss = 0.052581\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:05.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.040618, Val Loss = 0.049683\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:05.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.038561, Val Loss = 0.047073\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:05.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.036721, Val Loss = 0.044725\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:06.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.035075, Val Loss = 0.042612\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:06.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.033601, Val Loss = 0.040711\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:06.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.039015 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:06.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:06.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:06.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.030201, Val Loss = 0.032167\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:07.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.020626, Val Loss = 0.022685\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:09.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.015742, Val Loss = 0.017264\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:10.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.012737, Val Loss = 0.013636\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:12.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.010403, Val Loss = 0.011064\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:13.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.008827, Val Loss = 0.009366\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:15.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.007760, Val Loss = 0.008108\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:16.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.006843, Val Loss = 0.007180\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:18.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.006383, Val Loss = 0.006769\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:19.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.005874, Val Loss = 0.006154\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:21.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.005594 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:23.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 308 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:23.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:23.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 6.777391, Val Loss = 1.552558\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:23.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.097282, Val Loss = 0.118855\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:23.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.081647, Val Loss = 0.100763\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:23.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.074323, Val Loss = 0.091642\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:23.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.068730, Val Loss = 0.084641\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:24.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.063868, Val Loss = 0.078588\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:24.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.059543, Val Loss = 0.073208\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:24.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.055679, Val Loss = 0.068394\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:24.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.052225, Val Loss = 0.064078\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:24.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.049136, Val Loss = 0.060204\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:24.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.056758 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:24.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:24.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:24.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.044270, Val Loss = 0.048614\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:26.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.033072, Val Loss = 0.037073\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:27.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.028351, Val Loss = 0.031495\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:29.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.024590, Val Loss = 0.027186\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:31.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.021720, Val Loss = 0.023870\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:32.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.020083, Val Loss = 0.022138\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:34.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.018713, Val Loss = 0.020433\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:35.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.017451, Val Loss = 0.018934\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:37.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.016079, Val Loss = 0.017409\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:39.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.015127, Val Loss = 0.016312\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:40.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.015176 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:42.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 345 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:42.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:42.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.332294, Val Loss = 0.234733\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:42.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.044911, Val Loss = 0.053927\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:42.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.041580, Val Loss = 0.049903\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:43.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.039642, Val Loss = 0.047413\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:43.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.038056, Val Loss = 0.045362\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:43.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.036656, Val Loss = 0.043551\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:43.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.035404, Val Loss = 0.041925\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:43.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.034281, Val Loss = 0.040461\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:44.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.033273, Val Loss = 0.039140\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:44.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.032367, Val Loss = 0.037946\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:44.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.036876 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:44.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:44.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:44.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.029590, Val Loss = 0.030480\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:46.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.017262, Val Loss = 0.018253\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:48.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.012559, Val Loss = 0.013186\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:50.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.005131, Val Loss = 0.004754\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:52.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.004104, Val Loss = 0.003901\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:54.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.003376, Val Loss = 0.003329\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:56.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.002756, Val Loss = 0.002695\u001b[0m\n",
            "\u001b[32m2026-01-25 10:29:59.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.002278, Val Loss = 0.002156\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:01.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.001919, Val Loss = 0.001748\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:03.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.001609, Val Loss = 0.001430\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:05.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.001142 at iteration 996\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:08.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 381 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:08.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:08.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.094158, Val Loss = 0.099590\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:08.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.064356, Val Loss = 0.076055\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:08.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.057537, Val Loss = 0.069138\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:08.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.053838, Val Loss = 0.064879\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:09.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.050875, Val Loss = 0.061273\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:09.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.048276, Val Loss = 0.058044\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:09.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.045959, Val Loss = 0.055138\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:09.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.043888, Val Loss = 0.052524\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:10.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.042034, Val Loss = 0.050172\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:10.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.040375, Val Loss = 0.048057\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:10.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.046170 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:10.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:10.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:10.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.036943, Val Loss = 0.039472\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:12.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.024041, Val Loss = 0.026632\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:14.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.018869, Val Loss = 0.020354\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:17.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.015136, Val Loss = 0.016220\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:19.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.012113, Val Loss = 0.012525\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:21.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.010584, Val Loss = 0.011007\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:24.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.009825, Val Loss = 0.010157\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:26.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.009161, Val Loss = 0.009463\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:28.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.008467, Val Loss = 0.008816\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:31.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.007804, Val Loss = 0.008070\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:33.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.007381 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:36.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 414 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:36.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:36.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.149656, Val Loss = 0.106617\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:36.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.045888, Val Loss = 0.054932\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:36.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.043533, Val Loss = 0.052191\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:36.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.041730, Val Loss = 0.049954\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:37.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.040158, Val Loss = 0.047962\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:37.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.038754, Val Loss = 0.046167\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:37.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.037496, Val Loss = 0.044547\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:37.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.036367, Val Loss = 0.043085\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:37.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.035352, Val Loss = 0.041764\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:38.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.034441, Val Loss = 0.040571\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:38.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.039501 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:38.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:38.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:38.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.031760, Val Loss = 0.033548\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:40.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.018947, Val Loss = 0.020750\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:43.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.013789, Val Loss = 0.014921\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:45.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.010001, Val Loss = 0.010434\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:48.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.007000, Val Loss = 0.008227\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:50.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.005739, Val Loss = 0.006790\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:53.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.004478, Val Loss = 0.005328\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:56.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.002130, Val Loss = 0.001847\u001b[0m\n",
            "\u001b[32m2026-01-25 10:30:58.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.001491, Val Loss = 0.001184\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:01.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.001191, Val Loss = 0.000894\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:04.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.000697 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:06.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 447 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:06.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:06.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.183509, Val Loss = 0.124335\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:06.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.074128, Val Loss = 0.090706\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:06.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.068386, Val Loss = 0.084046\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:06.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.063620, Val Loss = 0.078245\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:07.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.059414, Val Loss = 0.073033\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:07.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.055664, Val Loss = 0.068343\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:07.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.052315, Val Loss = 0.064129\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:07.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.049322, Val Loss = 0.060344\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:07.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.046647, Val Loss = 0.056943\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:08.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.044255, Val Loss = 0.053888\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:08.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.051168 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:08.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:08.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:08.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.039977, Val Loss = 0.043202\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:11.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.028469, Val Loss = 0.032255\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:14.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.023179, Val Loss = 0.026068\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:17.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.019114, Val Loss = 0.021135\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:20.507\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.016532, Val Loss = 0.018295\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:23.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.015257, Val Loss = 0.016788\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:26.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.014141, Val Loss = 0.015343\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:29.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.013207, Val Loss = 0.014421\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:32.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.012118, Val Loss = 0.013271\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:35.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.011216, Val Loss = 0.012020\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:38.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.006971 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:41.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 488 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:41.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:41.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.156071, Val Loss = 0.142848\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:41.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.067039, Val Loss = 0.081026\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:41.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.056230, Val Loss = 0.068943\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:41.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.052044, Val Loss = 0.063738\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:42.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.049077, Val Loss = 0.059950\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:42.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.046533, Val Loss = 0.056700\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:42.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.044274, Val Loss = 0.053810\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:42.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.042254, Val Loss = 0.051218\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:42.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.040447, Val Loss = 0.048889\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:43.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.038830, Val Loss = 0.046793\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:43.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.044923 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:43.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:43.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:43.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.035224, Val Loss = 0.038398\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:45.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.023206, Val Loss = 0.026141\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:48.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.017911, Val Loss = 0.019672\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:51.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.014408, Val Loss = 0.015642\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:53.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.011643, Val Loss = 0.012260\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:56.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.010204, Val Loss = 0.010794\u001b[0m\n",
            "\u001b[32m2026-01-25 10:31:59.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.009338, Val Loss = 0.009991\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:02.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.006508, Val Loss = 0.006626\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:04.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.006056, Val Loss = 0.006135\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:07.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.005032, Val Loss = 0.005026\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:10.376\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.003778 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:12.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 523 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:12.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:12.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 3.591139, Val Loss = 0.092275\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:12.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.067765, Val Loss = 0.083598\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:12.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.062906, Val Loss = 0.077852\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:13.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.058975, Val Loss = 0.072964\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:13.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.055522, Val Loss = 0.068593\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:13.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.052446, Val Loss = 0.064662\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:14.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.049698, Val Loss = 0.061127\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:14.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.047241, Val Loss = 0.057949\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:14.537\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.045044, Val Loss = 0.055091\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:14.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.043079, Val Loss = 0.052519\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:15.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.050225 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:15.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:15.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:15.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.039350, Val Loss = 0.044071\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:18.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.026653, Val Loss = 0.030218\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:22.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.019970, Val Loss = 0.022209\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:25.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.015285, Val Loss = 0.016767\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:29.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.013129, Val Loss = 0.014427\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:32.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.012094, Val Loss = 0.013690\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:36.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.008843, Val Loss = 0.009419\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:40.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.008123, Val Loss = 0.008431\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:43.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.007591, Val Loss = 0.007926\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:47.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.007107, Val Loss = 0.007442\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:50.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.006855 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:53.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 559 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:53.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:53.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.107727, Val Loss = 0.099162\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:54.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.071971, Val Loss = 0.089392\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:54.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.066715, Val Loss = 0.082689\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:54.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.062228, Val Loss = 0.076990\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:54.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.058251, Val Loss = 0.071947\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:55.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.054704, Val Loss = 0.067440\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:55.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.051538, Val Loss = 0.063402\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:55.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.048710, Val Loss = 0.059778\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:56.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.046184, Val Loss = 0.056524\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:56.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.043926, Val Loss = 0.053600\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:56.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.050996 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:56.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:56.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:32:56.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.039857, Val Loss = 0.044871\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:00.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.027493, Val Loss = 0.031104\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:04.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.022578, Val Loss = 0.025300\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:08.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.018322, Val Loss = 0.020234\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:12.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.015530, Val Loss = 0.017125\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:16.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.014203, Val Loss = 0.015250\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:20.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.013144, Val Loss = 0.014190\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:24.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.012256, Val Loss = 0.013167\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:29.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.011313, Val Loss = 0.012111\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:33.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.010543, Val Loss = 0.011273\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:37.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.007431 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:40.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mModel initialized\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:40.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mModel initialized\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:40.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mTraining set: 900 samples, Validation set: 100 samples\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:40.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 50 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:40.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:40.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.172899, Val Loss = 0.192121\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:40.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.064133, Val Loss = 0.079252\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:40.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.058289, Val Loss = 0.071529\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:40.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.054530, Val Loss = 0.066720\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:40.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.051389, Val Loss = 0.062736\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:40.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.048595, Val Loss = 0.059207\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:40.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.046067, Val Loss = 0.056019\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:40.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.043768, Val Loss = 0.053118\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:40.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.041673, Val Loss = 0.050472\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:40.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.039765, Val Loss = 0.048056\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:41.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.045869 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:41.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:41.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:41.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.036831, Val Loss = 0.042386\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:41.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.025740, Val Loss = 0.030206\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:42.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.020713, Val Loss = 0.024057\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:42.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.018239, Val Loss = 0.021021\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:43.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.016625, Val Loss = 0.018915\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:43.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.015003, Val Loss = 0.017029\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:44.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.013674, Val Loss = 0.015514\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:45.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.012502, Val Loss = 0.014150\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:45.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.011453, Val Loss = 0.013217\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:46.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.010460, Val Loss = 0.011881\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:46.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.010882 at iteration 994\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:47.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 85 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:47.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:47.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 2.210806, Val Loss = 1.723403\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:47.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.068398, Val Loss = 0.075538\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:48.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.046218, Val Loss = 0.054268\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:48.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.040148, Val Loss = 0.048109\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:48.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.037802, Val Loss = 0.045436\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:48.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.036380, Val Loss = 0.043640\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:48.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.035241, Val Loss = 0.042133\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:48.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.034236, Val Loss = 0.040778\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:48.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.033324, Val Loss = 0.039538\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:48.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.032489, Val Loss = 0.038397\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:48.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.037357 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:48.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:48.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:48.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.030438, Val Loss = 0.032981\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:49.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.018189, Val Loss = 0.021187\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:50.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.011587, Val Loss = 0.013699\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:50.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.008000, Val Loss = 0.009492\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:51.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.005646, Val Loss = 0.006469\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:52.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.005007, Val Loss = 0.005735\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:52.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.004561, Val Loss = 0.005151\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:53.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.004035, Val Loss = 0.004567\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:54.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.003628, Val Loss = 0.004103\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:54.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.003191, Val Loss = 0.003633\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:55.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.003030 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:57.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 129 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:57.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:57.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.107912, Val Loss = 0.120516\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:57.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.072687, Val Loss = 0.086310\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:57.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.062680, Val Loss = 0.076337\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:57.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.058099, Val Loss = 0.071219\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:57.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.054903, Val Loss = 0.067340\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:57.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.052205, Val Loss = 0.063945\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:57.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.049799, Val Loss = 0.060868\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:58.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.047621, Val Loss = 0.058056\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:58.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.045642, Val Loss = 0.055488\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:58.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.043843, Val Loss = 0.053142\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:58.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.051017 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:58.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:58.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:58.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.041019, Val Loss = 0.047544\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:59.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.024576, Val Loss = 0.029974\u001b[0m\n",
            "\u001b[32m2026-01-25 10:33:59.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.019085, Val Loss = 0.023257\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:00.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.015951, Val Loss = 0.019261\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:01.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.013822, Val Loss = 0.016354\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:02.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.012575, Val Loss = 0.014748\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:03.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.011543, Val Loss = 0.013589\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:04.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.007185, Val Loss = 0.007946\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:04.901\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.006449, Val Loss = 0.007336\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:05.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.005834, Val Loss = 0.006656\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:06.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.006126 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:08.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 167 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:08.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:08.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.252753, Val Loss = 0.240332\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:08.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.093450, Val Loss = 0.102537\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:08.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.067242, Val Loss = 0.078620\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:08.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.058995, Val Loss = 0.070700\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:08.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.054908, Val Loss = 0.066305\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:08.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.051935, Val Loss = 0.062814\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:09.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.049386, Val Loss = 0.059693\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:09.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.047095, Val Loss = 0.056832\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:09.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.045011, Val Loss = 0.054202\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:09.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.043109, Val Loss = 0.051786\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:09.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.049590 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:09.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:09.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:09.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.040043, Val Loss = 0.045197\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:10.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.027555, Val Loss = 0.032795\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:11.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.021192, Val Loss = 0.024998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:12.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.018033, Val Loss = 0.020881\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:13.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.015766, Val Loss = 0.018025\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:13.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.014396, Val Loss = 0.016379\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:14.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.013308, Val Loss = 0.015290\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:15.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.012328, Val Loss = 0.014350\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:16.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.011352, Val Loss = 0.013131\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:17.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.010473, Val Loss = 0.012103\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:18.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.011202 at iteration 983\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:20.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 204 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:20.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:20.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.161562, Val Loss = 0.138775\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:20.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.066329, Val Loss = 0.078716\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:20.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.060505, Val Loss = 0.072661\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:20.493\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.057019, Val Loss = 0.068669\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:20.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.054226, Val Loss = 0.065306\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:20.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.051758, Val Loss = 0.062272\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:20.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.049522, Val Loss = 0.059495\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:20.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.047481, Val Loss = 0.056949\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:21.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.045616, Val Loss = 0.054612\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:21.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.043911, Val Loss = 0.052469\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:21.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.050520 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:21.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:21.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:21.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.041078, Val Loss = 0.046536\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:22.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.025410, Val Loss = 0.030017\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:23.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.018941, Val Loss = 0.022296\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:24.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.015339, Val Loss = 0.017645\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:25.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.013584, Val Loss = 0.015621\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:26.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.012462, Val Loss = 0.014276\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:27.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.011382, Val Loss = 0.013252\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:28.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.010548, Val Loss = 0.012390\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:29.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.009689, Val Loss = 0.011319\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:30.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.008668, Val Loss = 0.010132\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:32.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.009213 at iteration 996\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:33.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 242 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:33.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:33.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.595162, Val Loss = 0.294533\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:34.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.068481, Val Loss = 0.081973\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:34.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.056557, Val Loss = 0.069238\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:34.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.051988, Val Loss = 0.063863\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:34.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.049154, Val Loss = 0.060320\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:34.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.046850, Val Loss = 0.057388\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:34.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.044806, Val Loss = 0.054775\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:34.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.042952, Val Loss = 0.052399\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:35.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.041262, Val Loss = 0.050227\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:35.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.039718, Val Loss = 0.048236\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:35.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.046429 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:35.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:35.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:35.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.036781, Val Loss = 0.042495\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:36.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.022762, Val Loss = 0.027860\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:37.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.016922, Val Loss = 0.020662\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:39.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.007340, Val Loss = 0.008601\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:40.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.006753, Val Loss = 0.007943\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:41.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.006153, Val Loss = 0.007288\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:43.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.005383, Val Loss = 0.006337\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:44.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.004901, Val Loss = 0.005750\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:45.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.004509, Val Loss = 0.005404\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:47.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.004054, Val Loss = 0.004734\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:48.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.004248 at iteration 995\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:50.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 277 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:50.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:50.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.337224, Val Loss = 0.181894\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:50.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.082837, Val Loss = 0.101918\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:50.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.077611, Val Loss = 0.095241\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:51.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.073149, Val Loss = 0.089570\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:51.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.069146, Val Loss = 0.084508\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:51.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.065512, Val Loss = 0.079920\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:51.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.062202, Val Loss = 0.075741\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:51.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.059184, Val Loss = 0.071923\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:51.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.056432, Val Loss = 0.068433\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:52.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.053920, Val Loss = 0.065240\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:52.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.062344 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:52.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:52.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:52.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.050183, Val Loss = 0.057737\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:53.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.034794, Val Loss = 0.041748\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:55.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.026460, Val Loss = 0.031775\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:56.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.022534, Val Loss = 0.026312\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:58.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.020880, Val Loss = 0.024151\u001b[0m\n",
            "\u001b[32m2026-01-25 10:34:59.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.019362, Val Loss = 0.022270\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:01.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.017813, Val Loss = 0.020570\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:03.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.016513, Val Loss = 0.019068\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:04.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.015536, Val Loss = 0.018088\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:06.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.014419, Val Loss = 0.016731\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:07.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.015574 at iteration 994\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:10.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 316 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:10.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:10.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 2.327028, Val Loss = 0.454836\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:10.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.062732, Val Loss = 0.076508\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:10.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.059560, Val Loss = 0.072595\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:10.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.056670, Val Loss = 0.069004\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:10.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.054032, Val Loss = 0.065712\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:10.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.051623, Val Loss = 0.062693\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:10.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.049421, Val Loss = 0.059926\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:11.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.047409, Val Loss = 0.057388\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:11.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.045569, Val Loss = 0.055062\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:11.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.043887, Val Loss = 0.052927\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:11.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.050987 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:11.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:11.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:11.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.040524, Val Loss = 0.046665\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:13.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.026812, Val Loss = 0.032382\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:14.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.019432, Val Loss = 0.023207\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:16.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.016705, Val Loss = 0.019591\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:17.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.014555, Val Loss = 0.017169\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:19.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.009263, Val Loss = 0.010388\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:21.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.008266, Val Loss = 0.009497\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:22.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.007459, Val Loss = 0.008795\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:24.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.006738, Val Loss = 0.007903\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:26.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.006126, Val Loss = 0.007259\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:27.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.006400 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:28.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 350 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:28.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:28.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.611755, Val Loss = 0.313585\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:29.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.079839, Val Loss = 0.098260\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:29.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.074129, Val Loss = 0.091012\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:29.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.069582, Val Loss = 0.085234\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:29.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.065572, Val Loss = 0.080175\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:29.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.061941, Val Loss = 0.075612\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:30.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.058632, Val Loss = 0.071459\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:30.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.055612, Val Loss = 0.067664\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:30.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.052854, Val Loss = 0.064192\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:30.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.050335, Val Loss = 0.061012\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:30.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.058127 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:30.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:30.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:30.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.046324, Val Loss = 0.053273\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:32.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.032489, Val Loss = 0.040594\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:34.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.026580, Val Loss = 0.032966\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:36.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.024040, Val Loss = 0.029587\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:38.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.021382, Val Loss = 0.025926\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:40.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.019584, Val Loss = 0.023428\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:42.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.018260, Val Loss = 0.022149\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:44.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.016640, Val Loss = 0.020089\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:46.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.015485, Val Loss = 0.018706\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:48.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.014200, Val Loss = 0.017350\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:50.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.014915 at iteration 989\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:52.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 390 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:52.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:52.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.330115, Val Loss = 0.135129\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:52.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.084673, Val Loss = 0.101334\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:53.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.075814, Val Loss = 0.092337\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:53.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.070769, Val Loss = 0.086633\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:53.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.066798, Val Loss = 0.081862\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:53.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.063307, Val Loss = 0.077558\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:53.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.060148, Val Loss = 0.073616\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:54.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.057269, Val Loss = 0.070001\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:54.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.054642, Val Loss = 0.066686\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:54.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.052242, Val Loss = 0.063646\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:54.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.060885 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:54.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:54.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:54.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.048324, Val Loss = 0.058077\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:56.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.033032, Val Loss = 0.040101\u001b[0m\n",
            "\u001b[32m2026-01-25 10:35:59.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.025437, Val Loss = 0.030785\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:01.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.022854, Val Loss = 0.027363\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:03.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.020487, Val Loss = 0.024024\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:06.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.018722, Val Loss = 0.021945\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:08.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.017288, Val Loss = 0.020557\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:10.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.015751, Val Loss = 0.018582\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:13.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.014459, Val Loss = 0.017392\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:15.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.013365, Val Loss = 0.016201\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:17.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.014007 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:19.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 426 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:19.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:19.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.613341, Val Loss = 0.145824\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:20.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.084795, Val Loss = 0.098737\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:20.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.073384, Val Loss = 0.087871\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:20.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.068042, Val Loss = 0.082179\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:20.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.064217, Val Loss = 0.077723\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:21.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.060944, Val Loss = 0.073746\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:21.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.058001, Val Loss = 0.070103\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:21.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.055323, Val Loss = 0.066756\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:21.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.052879, Val Loss = 0.063683\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:21.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.050646, Val Loss = 0.060864\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:22.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.058303 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:22.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:22.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:22.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.046916, Val Loss = 0.053296\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:24.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.033240, Val Loss = 0.040737\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:27.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.023883, Val Loss = 0.027962\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:30.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.021541, Val Loss = 0.025010\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:33.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.020129, Val Loss = 0.022976\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:35.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.018922, Val Loss = 0.021783\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:38.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.016823, Val Loss = 0.019735\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:41.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.014876, Val Loss = 0.017256\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:44.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.013663, Val Loss = 0.015794\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:46.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.012584, Val Loss = 0.014441\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:49.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.013563 at iteration 986\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:51.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 460 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:51.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:51.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 3.930207, Val Loss = 0.150609\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:51.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.073897, Val Loss = 0.089823\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:52.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.069665, Val Loss = 0.084757\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:52.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.065897, Val Loss = 0.080145\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:52.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.062477, Val Loss = 0.075915\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:52.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.059358, Val Loss = 0.072032\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:52.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.056509, Val Loss = 0.068472\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:53.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.053906, Val Loss = 0.065208\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:53.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.051528, Val Loss = 0.062215\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:53.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.049353, Val Loss = 0.059471\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:53.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.056978 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:53.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:53.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:53.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.045629, Val Loss = 0.052475\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:56.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.031284, Val Loss = 0.038193\u001b[0m\n",
            "\u001b[32m2026-01-25 10:36:59.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.023889, Val Loss = 0.029111\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:02.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.020728, Val Loss = 0.025169\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:05.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.018100, Val Loss = 0.021972\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:07.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.016537, Val Loss = 0.019997\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:10.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.015417, Val Loss = 0.018788\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:13.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.014150, Val Loss = 0.017391\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:16.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.012901, Val Loss = 0.016029\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:19.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.011565, Val Loss = 0.014333\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:22.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.012304 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:24.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 498 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:24.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:24.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.096035, Val Loss = 0.099239\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:24.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.074787, Val Loss = 0.090908\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:24.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.069782, Val Loss = 0.085256\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:25.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.065779, Val Loss = 0.080466\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:25.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.062243, Val Loss = 0.076129\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:25.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.059038, Val Loss = 0.072152\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:25.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.056116, Val Loss = 0.068502\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:26.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.053446, Val Loss = 0.065153\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:26.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.051007, Val Loss = 0.062080\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:26.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.048777, Val Loss = 0.059262\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:26.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.056702 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:26.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:26.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:26.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.044966, Val Loss = 0.053317\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:30.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.029989, Val Loss = 0.037076\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:33.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.023491, Val Loss = 0.029311\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:36.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.020835, Val Loss = 0.025408\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:40.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.018583, Val Loss = 0.022448\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:43.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.017074, Val Loss = 0.020397\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:47.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.015759, Val Loss = 0.019062\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:50.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.014318, Val Loss = 0.017729\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:53.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.013135, Val Loss = 0.016032\u001b[0m\n",
            "\u001b[32m2026-01-25 10:37:57.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.012027, Val Loss = 0.014791\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:01.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.012661 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:03.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 529 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:03.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:03.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.314306, Val Loss = 0.100152\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:03.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.076092, Val Loss = 0.093614\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:03.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.071510, Val Loss = 0.088156\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:03.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.067533, Val Loss = 0.083266\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:04.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.063944, Val Loss = 0.078792\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:04.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.060674, Val Loss = 0.074685\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:04.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.057690, Val Loss = 0.070917\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:05.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.054963, Val Loss = 0.067461\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:05.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.052472, Val Loss = 0.064292\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:05.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.050194, Val Loss = 0.061385\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:05.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.058743 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:05.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:05.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:06.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.046111, Val Loss = 0.054248\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:09.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.033938, Val Loss = 0.042292\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:12.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.026164, Val Loss = 0.032622\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:16.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.022771, Val Loss = 0.028320\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:19.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.019407, Val Loss = 0.023451\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:23.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.017668, Val Loss = 0.021451\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:26.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.016345, Val Loss = 0.019697\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:30.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.014899, Val Loss = 0.018066\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:34.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.012608, Val Loss = 0.015381\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:37.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.011595, Val Loss = 0.014564\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:41.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.011891 at iteration 997\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:44.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 568 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:44.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:44.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 8.017443, Val Loss = 0.155268\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:44.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.067045, Val Loss = 0.082358\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:44.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.062817, Val Loss = 0.077010\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:44.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.059331, Val Loss = 0.072595\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:45.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.056226, Val Loss = 0.068679\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:45.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.053408, Val Loss = 0.065131\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:45.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.050839, Val Loss = 0.061894\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:45.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.048493, Val Loss = 0.058934\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:45.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.046352, Val Loss = 0.056224\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:46.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.044397, Val Loss = 0.053741\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:46.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.051489 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:46.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:46.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:46.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.040807, Val Loss = 0.048338\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:49.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.026387, Val Loss = 0.032789\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:52.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.020891, Val Loss = 0.026360\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:55.749\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.017525, Val Loss = 0.021392\u001b[0m\n",
            "\u001b[32m2026-01-25 10:38:58.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.015494, Val Loss = 0.018812\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:02.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.013943, Val Loss = 0.016944\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:06.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.012472, Val Loss = 0.015327\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:09.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.008199, Val Loss = 0.010395\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:12.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.005538, Val Loss = 0.007198\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:15.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.004716, Val Loss = 0.006194\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:18.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.003416 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:20.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mModel initialized\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:20.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mModel initialized\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:20.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mTraining set: 900 samples, Validation set: 100 samples\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:20.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 50 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:20.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:20.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.247702, Val Loss = 0.259868\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:20.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.124484, Val Loss = 0.152329\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:20.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.115789, Val Loss = 0.141878\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:20.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.107994, Val Loss = 0.132320\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:21.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.100894, Val Loss = 0.123628\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:21.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.094417, Val Loss = 0.115684\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:21.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.088500, Val Loss = 0.108412\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:21.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.083089, Val Loss = 0.101756\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:21.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.078136, Val Loss = 0.095660\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:21.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.073602, Val Loss = 0.090075\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:21.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.084999 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:21.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:21.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:21.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.068970, Val Loss = 0.078294\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:22.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.057092, Val Loss = 0.065619\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:22.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.049473, Val Loss = 0.057024\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:23.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.044724, Val Loss = 0.051238\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:23.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.041628, Val Loss = 0.047344\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:24.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.039410, Val Loss = 0.044590\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:24.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.037247, Val Loss = 0.041789\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:25.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.035929, Val Loss = 0.040080\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:25.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.034573, Val Loss = 0.038422\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:26.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.033306, Val Loss = 0.036744\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:27.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.035736 at iteration 990\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:28.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 87 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:28.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:28.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 10.197719, Val Loss = 8.075731\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:28.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.088991, Val Loss = 0.107096\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:28.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.071676, Val Loss = 0.087978\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:28.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.065674, Val Loss = 0.080591\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:28.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.061947, Val Loss = 0.075821\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:28.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.058836, Val Loss = 0.071865\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:28.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.056025, Val Loss = 0.068320\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:28.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.053440, Val Loss = 0.065072\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:28.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.051054, Val Loss = 0.062081\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:29.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.048851, Val Loss = 0.059316\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:29.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.056782 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:29.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:29.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:29.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.046025, Val Loss = 0.050754\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:29.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.034435, Val Loss = 0.039830\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:30.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.027838, Val Loss = 0.032253\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:31.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.022017, Val Loss = 0.024760\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:31.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.019753, Val Loss = 0.021552\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:32.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.014346, Val Loss = 0.014903\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:33.029\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.012285, Val Loss = 0.013195\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:33.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.011308, Val Loss = 0.012214\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:34.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.010427, Val Loss = 0.011300\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:35.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.009703, Val Loss = 0.010460\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:35.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.009719 at iteration 996\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:37.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 124 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:37.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:37.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.573498, Val Loss = 0.377240\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:37.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.047363, Val Loss = 0.057125\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:37.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.045047, Val Loss = 0.054457\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:37.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.043435, Val Loss = 0.052462\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:37.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.042039, Val Loss = 0.050693\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:37.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.040763, Val Loss = 0.049064\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:37.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.039585, Val Loss = 0.047552\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:37.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.038493, Val Loss = 0.046147\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:37.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.037480, Val Loss = 0.044840\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:38.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.036540, Val Loss = 0.043622\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:38.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.042500 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:38.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:38.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:38.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.034843, Val Loss = 0.038613\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:38.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.023789, Val Loss = 0.026791\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:39.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.015830, Val Loss = 0.017850\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:40.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.011402, Val Loss = 0.012917\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:40.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.008691, Val Loss = 0.009286\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:41.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.007600, Val Loss = 0.007952\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:42.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.006873, Val Loss = 0.007135\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:43.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.006202, Val Loss = 0.006484\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:43.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.005636, Val Loss = 0.005755\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:44.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.005046, Val Loss = 0.005130\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:45.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.004601 at iteration 988\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:46.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 158 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:46.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:46.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 3.739658, Val Loss = 2.055677\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:47.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.086753, Val Loss = 0.101340\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:47.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.077734, Val Loss = 0.093043\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:47.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.073004, Val Loss = 0.088059\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:47.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.069253, Val Loss = 0.083747\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:47.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.065891, Val Loss = 0.079738\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:47.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.062798, Val Loss = 0.075993\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:47.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.059937, Val Loss = 0.072504\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:47.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.057289, Val Loss = 0.069259\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:48.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.054836, Val Loss = 0.066245\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:48.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.063472 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:48.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:48.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:48.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.052174, Val Loss = 0.058419\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:49.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.029693, Val Loss = 0.033457\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:50.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.010803, Val Loss = 0.011925\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:51.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.009953, Val Loss = 0.010782\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:51.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.009061, Val Loss = 0.009737\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:52.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.008233, Val Loss = 0.008735\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:53.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.007577, Val Loss = 0.008022\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:54.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.006864, Val Loss = 0.007252\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:55.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.006182, Val Loss = 0.006487\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:56.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.005652, Val Loss = 0.005921\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:57.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.004159 at iteration 996\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:59.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 199 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:59.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:59.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.417081, Val Loss = 0.234235\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:59.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.063569, Val Loss = 0.077303\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:59.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.057674, Val Loss = 0.070463\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:59.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.054631, Val Loss = 0.066674\u001b[0m\n",
            "\u001b[32m2026-01-25 10:39:59.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.052231, Val Loss = 0.063658\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:00.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.050078, Val Loss = 0.060963\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:00.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.048094, Val Loss = 0.058485\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:00.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.046254, Val Loss = 0.056186\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:00.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.044546, Val Loss = 0.054050\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:00.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.042961, Val Loss = 0.052062\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:00.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.050229 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:00.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:00.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:00.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.040606, Val Loss = 0.046211\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:02.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.028223, Val Loss = 0.032347\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:03.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.022684, Val Loss = 0.025858\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:04.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.018913, Val Loss = 0.021516\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:05.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.016109, Val Loss = 0.017958\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:06.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.014529, Val Loss = 0.015699\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:07.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.013209, Val Loss = 0.014348\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:08.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.012014, Val Loss = 0.013018\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:10.017\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.010035, Val Loss = 0.010703\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:11.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.009326, Val Loss = 0.009949\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:12.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.007601 at iteration 996\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:13.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 231 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:13.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:13.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.411579, Val Loss = 0.175315\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:13.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.053823, Val Loss = 0.064300\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:14.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.051670, Val Loss = 0.061770\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:14.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.049719, Val Loss = 0.059418\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:14.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.047914, Val Loss = 0.057221\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:14.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.046239, Val Loss = 0.055170\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:14.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.044681, Val Loss = 0.053256\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:14.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.043233, Val Loss = 0.051472\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:14.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.041886, Val Loss = 0.049809\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:15.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.040632, Val Loss = 0.048258\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:15.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.046825 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:15.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:15.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:15.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.039022, Val Loss = 0.043636\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:16.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.025342, Val Loss = 0.027982\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:18.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.016359, Val Loss = 0.018314\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:19.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.013161, Val Loss = 0.014622\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:20.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.011370, Val Loss = 0.012349\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:22.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.010158, Val Loss = 0.010951\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:23.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.009176, Val Loss = 0.009956\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:24.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.008345, Val Loss = 0.009074\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:26.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.007521, Val Loss = 0.008166\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:27.538\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.006835, Val Loss = 0.007392\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:28.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.006546 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:31.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 267 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:31.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:31.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.561303, Val Loss = 0.459978\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:31.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.061548, Val Loss = 0.074672\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:31.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.058668, Val Loss = 0.071030\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:31.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.056068, Val Loss = 0.067786\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:31.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.053666, Val Loss = 0.064809\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:31.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.051439, Val Loss = 0.062052\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:32.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.049371, Val Loss = 0.059490\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:32.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.047451, Val Loss = 0.057107\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:32.377\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.045667, Val Loss = 0.054890\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:32.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.044010, Val Loss = 0.052825\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:32.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.050920 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:32.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:32.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:32.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.041694, Val Loss = 0.048373\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:34.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.030145, Val Loss = 0.035006\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:35.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.024697, Val Loss = 0.029080\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:37.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.020158, Val Loss = 0.023637\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:39.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.017608, Val Loss = 0.020276\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:40.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.015458, Val Loss = 0.017415\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:42.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.014015, Val Loss = 0.015799\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:43.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.012732, Val Loss = 0.014335\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:45.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.011533, Val Loss = 0.013110\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:46.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.010435, Val Loss = 0.011864\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:48.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.010517 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:50.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 299 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:50.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:50.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 3.858888, Val Loss = 0.887432\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:50.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.077642, Val Loss = 0.090044\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:50.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.062703, Val Loss = 0.076086\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:50.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.057861, Val Loss = 0.071061\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:50.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.054851, Val Loss = 0.067568\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:51.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.052301, Val Loss = 0.064464\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:51.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.049974, Val Loss = 0.061582\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:51.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.047820, Val Loss = 0.058893\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:51.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.045822, Val Loss = 0.056386\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:51.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.043966, Val Loss = 0.054051\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:51.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.051896 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:51.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:51.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:51.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.041296, Val Loss = 0.047967\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:53.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.028885, Val Loss = 0.033944\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:55.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.021724, Val Loss = 0.025414\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:56.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.019027, Val Loss = 0.021608\u001b[0m\n",
            "\u001b[32m2026-01-25 10:40:58.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.017329, Val Loss = 0.019544\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:00.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.015693, Val Loss = 0.017308\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:02.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.014455, Val Loss = 0.015938\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:04.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.013521, Val Loss = 0.014924\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:06.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.012434, Val Loss = 0.013735\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:07.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.011402, Val Loss = 0.012603\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:09.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.011496 at iteration 996\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:11.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 331 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:11.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:11.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.572119, Val Loss = 0.196340\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:11.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.076349, Val Loss = 0.093752\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:11.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.067849, Val Loss = 0.083936\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:11.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.063940, Val Loss = 0.079015\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:11.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.060966, Val Loss = 0.075222\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:11.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.058317, Val Loss = 0.071860\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:12.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.055879, Val Loss = 0.068774\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:12.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.053622, Val Loss = 0.065916\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:12.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.051530, Val Loss = 0.063263\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:12.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.049590, Val Loss = 0.060796\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:12.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.058524 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:12.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:12.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:12.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.047113, Val Loss = 0.055164\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:14.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.034015, Val Loss = 0.039169\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:16.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.027832, Val Loss = 0.032403\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:18.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.023319, Val Loss = 0.027009\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:20.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.020267, Val Loss = 0.023136\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:22.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.018379, Val Loss = 0.020280\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:24.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.017057, Val Loss = 0.018874\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:26.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.015809, Val Loss = 0.017408\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:27.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.014524, Val Loss = 0.016159\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:29.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.013077, Val Loss = 0.014381\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:31.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.011618 at iteration 994\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:33.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 365 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:33.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:33.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.742611, Val Loss = 0.263801\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:33.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.077426, Val Loss = 0.095138\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:34.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.073243, Val Loss = 0.089917\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:34.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.069540, Val Loss = 0.085328\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:34.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.066137, Val Loss = 0.081129\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:34.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.062986, Val Loss = 0.077247\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:34.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.060067, Val Loss = 0.073646\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:35.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.057360, Val Loss = 0.070302\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:35.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.054849, Val Loss = 0.067194\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:35.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.052520, Val Loss = 0.064304\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:35.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.061643 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:35.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:35.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:35.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.049602, Val Loss = 0.058072\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:37.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.031662, Val Loss = 0.037711\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:39.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.027210, Val Loss = 0.031998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:41.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.024226, Val Loss = 0.028307\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:44.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.021471, Val Loss = 0.023751\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:46.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.019514, Val Loss = 0.021758\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:48.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.017766, Val Loss = 0.019970\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:50.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.015999, Val Loss = 0.017953\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:52.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.014587, Val Loss = 0.016344\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:54.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.013213, Val Loss = 0.014763\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:57.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.013409 at iteration 996\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:59.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 403 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:59.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:59.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 8.797508, Val Loss = 0.593332\u001b[0m\n",
            "\u001b[32m2026-01-25 10:41:59.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.062472, Val Loss = 0.076579\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:00.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.059799, Val Loss = 0.073187\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:00.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.057385, Val Loss = 0.070132\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:00.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.055157, Val Loss = 0.067314\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:01.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.053093, Val Loss = 0.064701\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:01.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.051178, Val Loss = 0.062273\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:01.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.049402, Val Loss = 0.060013\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:01.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.047754, Val Loss = 0.057909\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:01.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.046223, Val Loss = 0.055950\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:02.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.054143 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:02.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:02.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:02.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.044438, Val Loss = 0.052264\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:04.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.030602, Val Loss = 0.035719\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:06.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.023944, Val Loss = 0.028380\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:09.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.019136, Val Loss = 0.022513\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:11.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.016216, Val Loss = 0.018587\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:14.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.014570, Val Loss = 0.016364\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:16.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.013302, Val Loss = 0.014887\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:19.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.012089, Val Loss = 0.013415\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:21.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.010967, Val Loss = 0.012204\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:24.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.009798, Val Loss = 0.010868\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:26.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.009829 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:28.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 438 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:28.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:28.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.197855, Val Loss = 0.147444\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:29.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.085072, Val Loss = 0.103842\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:29.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.075701, Val Loss = 0.092680\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:29.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.071174, Val Loss = 0.086913\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:29.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.067650, Val Loss = 0.082443\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:30.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.064492, Val Loss = 0.078487\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:30.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.061581, Val Loss = 0.074864\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:30.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.058883, Val Loss = 0.071511\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:30.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.056381, Val Loss = 0.068399\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:31.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.054059, Val Loss = 0.065506\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:31.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.062840 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:31.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:31.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:31.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.051470, Val Loss = 0.061004\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:33.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.038109, Val Loss = 0.044349\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:36.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.029929, Val Loss = 0.035093\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:39.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.025158, Val Loss = 0.029188\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:41.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.020949, Val Loss = 0.023491\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:44.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.017894, Val Loss = 0.020170\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:47.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.016249, Val Loss = 0.018303\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:50.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.014497, Val Loss = 0.016359\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:52.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.012907, Val Loss = 0.014566\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:55.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.011909, Val Loss = 0.013335\u001b[0m\n",
            "\u001b[32m2026-01-25 10:42:58.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.012399 at iteration 994\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:00.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 478 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:00.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:00.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.476058, Val Loss = 0.134933\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:01.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.080722, Val Loss = 0.098254\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:01.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.072800, Val Loss = 0.088693\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:01.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.068564, Val Loss = 0.083320\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:02.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.065142, Val Loss = 0.079023\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:02.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.062054, Val Loss = 0.075194\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:02.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.059207, Val Loss = 0.071683\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:02.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.056571, Val Loss = 0.068436\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:03.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.054128, Val Loss = 0.065426\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:03.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.051864, Val Loss = 0.062631\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:03.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.060060 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:03.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:03.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:03.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.049055, Val Loss = 0.058604\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:06.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.036118, Val Loss = 0.041636\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:09.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.030836, Val Loss = 0.035388\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:12.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.025090, Val Loss = 0.028774\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:15.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.022780, Val Loss = 0.026069\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:18.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.021271, Val Loss = 0.023946\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:21.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.020160, Val Loss = 0.022640\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:24.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.019247, Val Loss = 0.021599\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:27.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.017110, Val Loss = 0.019145\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:30.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.015325, Val Loss = 0.017030\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:34.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.015648 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:36.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 512 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:36.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:36.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.068268, Val Loss = 0.078872\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:36.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.061040, Val Loss = 0.073530\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:36.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.058086, Val Loss = 0.070209\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:36.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.055667, Val Loss = 0.067302\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:37.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.053475, Val Loss = 0.064601\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:37.357\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.051449, Val Loss = 0.062080\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:37.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.049572, Val Loss = 0.059729\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:37.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.047829, Val Loss = 0.057540\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:37.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.046212, Val Loss = 0.055501\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:38.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.044710, Val Loss = 0.053602\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:38.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.051850 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:38.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:38.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:38.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.042518, Val Loss = 0.048459\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:41.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.029241, Val Loss = 0.033259\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:44.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.023637, Val Loss = 0.026943\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:46.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.019623, Val Loss = 0.022407\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:49.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.015657, Val Loss = 0.017518\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:52.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.010071, Val Loss = 0.010953\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:55.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.009128, Val Loss = 0.010005\u001b[0m\n",
            "\u001b[32m2026-01-25 10:43:58.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.008263, Val Loss = 0.009169\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:01.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.007548, Val Loss = 0.008313\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:04.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.006962, Val Loss = 0.007667\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:07.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.006974 at iteration 984\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:10.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 552 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:10.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:10.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.228926, Val Loss = 0.077148\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:10.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.058692, Val Loss = 0.071927\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:10.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.056105, Val Loss = 0.068654\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:10.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.053755, Val Loss = 0.065695\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:11.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.051584, Val Loss = 0.062965\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:11.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.049573, Val Loss = 0.060432\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:11.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.047708, Val Loss = 0.058078\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:11.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.045977, Val Loss = 0.055889\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:12.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.044372, Val Loss = 0.053853\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:12.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.042883, Val Loss = 0.051957\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:12.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.050210 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:12.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:12.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:12.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.040421, Val Loss = 0.045789\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:15.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.024961, Val Loss = 0.027999\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:18.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.017925, Val Loss = 0.020606\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:21.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.015223, Val Loss = 0.016872\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:24.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.013853, Val Loss = 0.015278\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:27.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.012652, Val Loss = 0.013826\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:30.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.011586, Val Loss = 0.012671\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:33.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.010387, Val Loss = 0.011254\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:36.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.009413, Val Loss = 0.010207\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:39.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.008365, Val Loss = 0.009119\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:42.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.008306 at iteration 996\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:44.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mModel initialized\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:44.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mModel initialized\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:44.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mTraining set: 900 samples, Validation set: 100 samples\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:44.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 50 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:44.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:44.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:44.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:44.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:44.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:44.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:44.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:44.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:44.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:44.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:44.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:44.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: inf at iteration -1\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:44.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:44.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:44.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 4.086137, Val Loss = 3.950677\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:45.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 4.058235, Val Loss = 3.941218\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:45.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 4.027899, Val Loss = 3.902428\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:46.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 3.996764, Val Loss = 3.867914\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:46.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 3.966100, Val Loss = 3.823459\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:47.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 3.935443, Val Loss = 3.785385\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:47.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 3.904808, Val Loss = 3.748946\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:48.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 3.870437, Val Loss = 3.689602\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:48.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 3.831497, Val Loss = 3.611730\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:49.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 3.789601, Val Loss = 3.558392\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:49.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 3.506081 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:51.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 87 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:51.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:51.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:51.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:51.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:52.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:52.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:52.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:52.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:52.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:52.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:52.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:52.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: inf at iteration -1\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:52.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:52.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:52.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.258151, Val Loss = 0.271985\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:53.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.236445, Val Loss = 0.250690\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:53.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.219556, Val Loss = 0.232732\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:54.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.189662, Val Loss = 0.203860\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:55.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.168557, Val Loss = 0.185274\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:55.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.153531, Val Loss = 0.172941\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:56.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.144655, Val Loss = 0.165459\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:56.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.134635, Val Loss = 0.153638\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:57.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.125665, Val Loss = 0.143915\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:58.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.119467, Val Loss = 0.136541\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:58.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.131420 at iteration 990\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:59.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 116 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:59.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:44:59.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:00.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:00.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:00.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:00.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:00.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:00.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:00.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:00.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:01.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:01.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: inf at iteration -1\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:01.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:01.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:01.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.455245, Val Loss = 0.464276\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:01.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.351519, Val Loss = 0.356396\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:02.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.269871, Val Loss = 0.269298\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:03.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.212046, Val Loss = 0.208452\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:03.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.177422, Val Loss = 0.173907\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:04.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.159707, Val Loss = 0.158423\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:04.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.150668, Val Loss = 0.156232\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:05.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.144017, Val Loss = 0.155577\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:06.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.130615, Val Loss = 0.147263\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:06.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.115070, Val Loss = 0.138431\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:07.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.132729 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:09.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 160 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:09.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:09.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:09.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:10.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:10.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:10.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:10.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:10.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:10.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:10.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:10.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:10.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: inf at iteration -1\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:10.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:10.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:10.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.205532, Val Loss = 0.203020\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:11.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.177500, Val Loss = 0.177856\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:12.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.157638, Val Loss = 0.156559\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:12.754\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.141464, Val Loss = 0.139268\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:13.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.117226, Val Loss = 0.114650\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:14.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.097928, Val Loss = 0.097945\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:14.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.083992, Val Loss = 0.085846\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:15.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.074613, Val Loss = 0.078290\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:16.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.069391, Val Loss = 0.074396\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:16.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.058836, Val Loss = 0.065407\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:17.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.059596 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:19.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 200 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:19.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:19.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:19.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:19.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:19.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:19.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:19.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:19.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:19.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:20.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:20.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:20.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: inf at iteration -1\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:20.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:20.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:20.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.083359, Val Loss = 1.031822\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:21.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.885716, Val Loss = 0.848142\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:21.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.723946, Val Loss = 0.689982\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:22.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.588241, Val Loss = 0.555551\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:23.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.484565, Val Loss = 0.458582\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:24.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.406856, Val Loss = 0.379330\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:24.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.344268, Val Loss = 0.314653\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:25.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.299834, Val Loss = 0.269583\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:26.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.274439, Val Loss = 0.244968\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:27.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.213482, Val Loss = 0.192613\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:27.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.132983 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:30.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 239 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:30.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:30.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:30.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:30.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:30.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:30.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:30.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:30.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:31.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:31.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:31.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:31.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: inf at iteration -1\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:31.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:31.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:31.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.821007, Val Loss = 0.750527\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:32.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.712260, Val Loss = 0.641678\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:33.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.612630, Val Loss = 0.547129\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:34.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.524850, Val Loss = 0.466095\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:35.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.449934, Val Loss = 0.399445\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:36.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.387638, Val Loss = 0.346818\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:37.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.337668, Val Loss = 0.307805\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:38.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.299829, Val Loss = 0.282115\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:39.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.274012, Val Loss = 0.269569\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:40.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.260168, Val Loss = 0.270075\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:41.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.236325 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:44.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 277 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:44.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:44.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:44.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:44.377\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:44.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:44.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:44.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:44.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:45.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:45.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:45.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:45.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: inf at iteration -1\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:45.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:45.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:45.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.270646, Val Loss = 0.253551\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:47.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.234950, Val Loss = 0.224439\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:48.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.164414, Val Loss = 0.157092\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:49.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.120795, Val Loss = 0.119891\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:51.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.097496, Val Loss = 0.101831\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:52.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.076683, Val Loss = 0.081120\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:53.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.068442, Val Loss = 0.072548\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:55.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.057597, Val Loss = 0.062439\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:56.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.050642, Val Loss = 0.054485\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:58.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.046353, Val Loss = 0.049373\u001b[0m\n",
            "\u001b[32m2026-01-25 10:45:59.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.045503 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:02.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 317 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:02.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:02.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:02.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:02.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:03.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:03.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:03.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:03.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:03.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:03.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:04.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:04.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: inf at iteration -1\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:04.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:04.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:04.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.078065, Val Loss = 0.093086\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:05.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.059246, Val Loss = 0.068747\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:07.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.051824, Val Loss = 0.057680\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:09.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.044901, Val Loss = 0.049469\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:11.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.037080, Val Loss = 0.041385\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:12.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.033004, Val Loss = 0.037219\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:14.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.030373, Val Loss = 0.034620\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:16.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.028547, Val Loss = 0.032468\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:18.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.027047, Val Loss = 0.031346\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:19.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.025663, Val Loss = 0.029137\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:21.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.027186 at iteration 992\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:23.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 352 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:23.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:23.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:23.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:23.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:24.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:24.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:24.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:24.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:24.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:24.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:25.029\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:25.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: inf at iteration -1\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:25.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:25.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:25.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.202327, Val Loss = 0.231224\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:26.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.172450, Val Loss = 0.192115\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:27.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.145623, Val Loss = 0.161363\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:29.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.123297, Val Loss = 0.135119\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:30.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.105267, Val Loss = 0.113319\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:31.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.091521, Val Loss = 0.095912\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:33.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.081881, Val Loss = 0.083143\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:34.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.061716, Val Loss = 0.061111\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:36.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.054670, Val Loss = 0.055440\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:37.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.051719, Val Loss = 0.052616\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:39.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.048988 at iteration 994\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:41.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 394 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:41.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:41.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:41.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:41.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:41.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:41.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:42.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:42.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:42.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:42.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:42.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:43.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: inf at iteration -1\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:43.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:43.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:43.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.307074, Val Loss = 1.234537\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:45.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 1.243651, Val Loss = 1.165685\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:47.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 1.176987, Val Loss = 1.101764\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:49.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 1.109275, Val Loss = 1.037757\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:51.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 1.042970, Val Loss = 0.976115\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:53.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.978825, Val Loss = 0.917772\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:55.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.916892, Val Loss = 0.861865\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:57.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.857595, Val Loss = 0.808923\u001b[0m\n",
            "\u001b[32m2026-01-25 10:46:59.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.800842, Val Loss = 0.758236\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:01.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.746968, Val Loss = 0.710323\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:03.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.665572 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:05.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 430 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:05.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:05.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:06.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:06.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:06.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:06.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:06.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:07.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:07.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:07.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:07.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:08.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: inf at iteration -1\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:08.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:08.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:08.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.375385, Val Loss = 1.268476\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:10.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 1.342157, Val Loss = 1.239412\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:12.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 1.322112, Val Loss = 1.214705\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:14.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 1.299865, Val Loss = 1.186798\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:17.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 1.276060, Val Loss = 1.160131\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:19.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 1.250698, Val Loss = 1.131952\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:22.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 1.224405, Val Loss = 1.103048\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:24.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 1.197432, Val Loss = 1.074609\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:26.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 1.169954, Val Loss = 1.045232\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:28.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 1.142608, Val Loss = 1.016975\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:31.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.989178 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:33.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 467 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:33.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:33.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:33.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:33.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:34.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:34.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:34.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:34.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:35.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:35.401\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:35.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:35.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: inf at iteration -1\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:35.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:35.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:35.901\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 2.697419, Val Loss = 2.655500\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:38.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 2.565430, Val Loss = 2.466254\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:41.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 2.411845, Val Loss = 2.321608\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:43.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 2.264457, Val Loss = 2.176567\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:46.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 2.122445, Val Loss = 2.034612\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:48.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 1.985674, Val Loss = 1.896882\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:51.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 1.854230, Val Loss = 1.764047\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:53.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 1.728230, Val Loss = 1.636547\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:56.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 1.607768, Val Loss = 1.514660\u001b[0m\n",
            "\u001b[32m2026-01-25 10:47:58.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 1.492902, Val Loss = 1.398558\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:01.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 1.290484 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:04.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 506 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:04.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:04.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:04.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:05.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:05.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:05.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:05.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:06.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:06.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:06.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:07.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:07.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: inf at iteration -1\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:07.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:07.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:07.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.975249, Val Loss = 0.952643\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:10.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.936231, Val Loss = 0.922881\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:14.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.923794, Val Loss = 0.934593\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:17.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.917354, Val Loss = 0.949842\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:21.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.914088, Val Loss = 0.951893\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:24.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.910441, Val Loss = 0.949201\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:28.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.904287, Val Loss = 0.945395\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:31.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.893621, Val Loss = 0.932853\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:35.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.887237, Val Loss = 0.920857\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:39.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.882054, Val Loss = 0.909618\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:42.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.891744 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:45.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 549 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:45.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:45.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:46.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:46.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:46.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:47.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:47.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:47.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:47.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:48.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:48.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:48.756\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: inf at iteration -1\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:48.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:48.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:48.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 4.217367, Val Loss = 4.125936\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:51.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 4.034388, Val Loss = 3.967509\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:54.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 3.858536, Val Loss = 3.791796\u001b[0m\n",
            "\u001b[32m2026-01-25 10:48:57.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 3.686708, Val Loss = 3.623235\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:01.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 3.520609, Val Loss = 3.460830\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:04.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 3.360062, Val Loss = 3.304060\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:07.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 3.204702, Val Loss = 3.152479\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:10.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 3.054215, Val Loss = 3.005717\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:13.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 2.908361, Val Loss = 2.863487\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:16.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 2.766960, Val Loss = 2.725580\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:19.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 2.594487 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:22.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 582 neurons\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:22.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:22.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:22.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:23.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:23.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:23.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:24.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:24.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:24.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:24.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:25.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = nan, Val Loss = nan\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:25.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: inf at iteration -1\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:25.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:25.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:25.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 7.625997, Val Loss = 7.572786\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:29.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 7.602986, Val Loss = 7.594360\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:33.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 7.585880, Val Loss = 7.692849\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:37.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 7.572803, Val Loss = 7.703731\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:40.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 7.558156, Val Loss = 7.683816\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:44.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 7.546704, Val Loss = 7.675707\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:48.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 7.532330, Val Loss = 7.655379\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:51.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 7.520795, Val Loss = 7.651292\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:55.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 7.505476, Val Loss = 7.620783\u001b[0m\n",
            "\u001b[32m2026-01-25 10:49:59.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 7.474298, Val Loss = 7.588791\u001b[0m\n",
            "\u001b[32m2026-01-25 10:50:02.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 7.536801 at iteration 982\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from scr.PDPA import PDPA\n",
        "\n",
        "pdpa_list_l2 = []\n",
        "best_iteration_l2 = []\n",
        "best_neurons_l2 = []\n",
        "for gamma in gammas:\n",
        "    pdpa = PDPA(\n",
        "        data=data_dict,\n",
        "        alpha=alpha,\n",
        "        gamma=gamma,\n",
        "        power=power,\n",
        "        activation=torch.relu,\n",
        "        loss_weights=loss_weight_l2,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "    best_iteration, best_neurons = pdpa.retrain(\n",
        "    num_iterations = num_iterations, \n",
        "    num_insertion= num_insertions, \n",
        "    threshold = pruning_threshold,\n",
        "    verbose=False\n",
        "    )\n",
        "\n",
        "    pdpa_list_l2.append(pdpa)\n",
        "    best_iteration_l2.append(best_iteration)\n",
        "    best_neurons_l2.append(best_neurons)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "747843f1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[84, 413, 85, 158, 317]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_neurons_l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8cb5bb44",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 10, 1, 3, 7]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_iteration_l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a37177b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# pdpa_list_h1 = []\n",
        "# best_iteration_h1 = []\n",
        "\n",
        "# for gamma in gammas:\n",
        "#     pdpa = PDPA(\n",
        "#         data=data_dict,\n",
        "#         alpha=alpha,\n",
        "#         gamma=gamma,\n",
        "#         power=power,\n",
        "#         activation=torch.relu,\n",
        "#         loss_weights=loss_weight_h1,\n",
        "#         verbose=False,\n",
        "#     )\n",
        "\n",
        "#     best_iteration = pdpa.retrain(\n",
        "#     num_iterations = num_iterations, \n",
        "#     num_insertion= num_insertions, \n",
        "#     threshold = pruning_threshold,\n",
        "#     verbose=False\n",
        "#     )\n",
        "\n",
        "#     pdpa_list_h1.append(pdpa)\n",
        "#     best_iteration_h1.append(best_iteration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a3deb9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "model_l2 = {\n",
        "    \"gammas\": gammas,\n",
        "    \"pdpa_list_l2\": pdpa_list_l2,\n",
        "    \"alpha\": alpha,\n",
        "    \"power\": power,\n",
        "    \"num_iteration\": num_iterations,\n",
        "    \"num_insertion\": num_insertions,\n",
        "    \"pruning_threshold\": pruning_threshold,\n",
        "    \"best_iteration_l2\": best_iteration_l2,\n",
        "    \"best_neurons_l2\": best_neurons_l2\n",
        "}\n",
        "\n",
        "# model_h1 = {\n",
        "#     \"gammas\": gammas,\n",
        "#     \"pdpa_list_h1\": pdpa_list_h1,\n",
        "#     \"alpha\": alpha,\n",
        "#     \"power\": power,\n",
        "#     \"num_iteration\": num_insertions,\n",
        "#     \"num_insertion\": num_insertions,\n",
        "#     \"pruning_threshold\": pruning_threshold,\n",
        "#     \"best_iteration_h1\": best_iteration_h1\n",
        "# }\n",
        "\n",
        "\n",
        "with open(\"models/experiment_5/pdpa_gausswindow_model_l2_5.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model_l2, f)\n",
        "\n",
        "# with open(\"models/experiment_2/pdpa_gauscos_model_h1_0.pkl\", \"wb\") as f:\n",
        "#     pickle.dump(model_h1, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8591213b",
      "metadata": {},
      "source": [
        "In each iteration we tried to add 5 neurons. The following plots indicates the relation of loss & number of neurons. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cf79243f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<Figure size 1000x600 with 1 Axes>,\n",
              " <Axes: title={'center': 'PDPA best loss vs best neuron count (best-so-far by iteration)'}, xlabel='Best iteration neuron count', ylabel='Best iteration validation loss'>)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from scr.metric import plot_pdpa_best_loss_vs_neurons_by_iteration\n",
        "\n",
        "# Plot raw (iteration-by-iteration) (neurons[t], val_loss[t]) pairs; exclude NaN/Inf points\n",
        "plot_pdpa_best_loss_vs_neurons_by_iteration(\n",
        "    model_l2,\n",
        "    pdpa_key=\"pdpa_list_l2\",\n",
        "    best_so_far=True,\n",
        "    marker=\"o\",\n",
        ")\n",
        "# from scr.metric import plot_pdpa_best_neurons_by_iteration\n",
        "\n",
        "# plot_pdpa_best_neurons_by_iteration(model_l2, pdpa_key=\"pdpa_list_l2\")\n",
        "# plot_pdpa_val_loss_histories_by_gamma(model_h1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
