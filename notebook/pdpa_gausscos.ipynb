{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "00dd79be",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/ruizhechao/Documents/NNforHJB\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/ruizhechao/Documents/NNforHJB/.venv/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "%cd ..\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "# %load_ext nb_black\n",
        "# notebook setup\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0, Path().absolute().parent.as_posix())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4099fadd",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "961"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load the data\n",
        "import numpy as np\n",
        "\n",
        "path = 'rawdata/raw_data/data/gauss_cos_31x31.npy'\n",
        "data = np.load(path)\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "73bfe79b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# prepare the data\n",
        "# data is a structured numpy array with fields: 'x', 'dv', 'v'\n",
        "# convert to the dict format expected by model._prepare_data\n",
        "\n",
        "data_dict = {\n",
        "    \"x\": np.asarray(data[\"x\"], dtype=np.float64),    # shape (N, 2)\n",
        "    \"v\": np.asarray(data[\"v\"], dtype=np.float64),    # shape (N,)\n",
        "    \"dv\": np.asarray(data[\"dv\"], dtype=np.float64),  # shape (N, 2)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1853ac4e",
      "metadata": {},
      "source": [
        "## Test effect of different gamma with increased neurons added"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "76b3c38d",
      "metadata": {},
      "outputs": [],
      "source": [
        "gammas = [10.0, 5.0, 1.0, 1e-1, 1e-2]\n",
        "# gammas = [0.0]\n",
        "alpha = 1e-5\n",
        "power = 1.0\n",
        "loss_weight_h1 = [1.0, 1.0]\n",
        "loss_weight_l2 = [1.0, 0.0]\n",
        "\n",
        "num_iterations = 10\n",
        "num_insertions = 50\n",
        "pruning_threshold = 1e-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "15961e8a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-01-24 16:00:05.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mModel initialized\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:05.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mModel initialized\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:05.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mTraining set: 864 samples, Validation set: 97 samples\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:05.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 50 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:06.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:06.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.914729, Val Loss = 0.875890\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:06.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.485314, Val Loss = 0.469482\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:06.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.435679, Val Loss = 0.423389\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:06.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.412913, Val Loss = 0.402830\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:06.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.397865, Val Loss = 0.389461\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:06.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.385682, Val Loss = 0.378611\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:07.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.374882, Val Loss = 0.368940\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:07.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.364967, Val Loss = 0.360027\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:07.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.355729, Val Loss = 0.351665\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:07.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.347109, Val Loss = 0.343862\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:07.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.336647 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:07.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:07.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:07.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.277330, Val Loss = 0.294162\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:08.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.257235, Val Loss = 0.274018\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:08.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.230764, Val Loss = 0.227635\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:09.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.218157, Val Loss = 0.213405\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:10.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.209839, Val Loss = 0.202913\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:11.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.203968, Val Loss = 0.196811\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:11.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.197702, Val Loss = 0.190674\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:12.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.191929, Val Loss = 0.185388\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:13.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.186562, Val Loss = 0.180480\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:14.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.181562, Val Loss = 0.175894\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:14.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.164233 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:16.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 92 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:16.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:16.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.590688, Val Loss = 0.494096\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:16.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.291847, Val Loss = 0.292743\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:17.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.275740, Val Loss = 0.280154\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:17.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.269358, Val Loss = 0.275784\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:17.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.265794, Val Loss = 0.273420\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:17.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.263126, Val Loss = 0.271527\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:17.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.260806, Val Loss = 0.269756\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:17.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.258673, Val Loss = 0.268053\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:17.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.256675, Val Loss = 0.266416\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:18.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.254794, Val Loss = 0.264857\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:18.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.263397 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:18.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:18.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:18.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.211428, Val Loss = 0.272259\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:18.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.165849, Val Loss = 0.186945\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:19.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.155838, Val Loss = 0.173154\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:20.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.150336, Val Loss = 0.166106\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:21.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.147169, Val Loss = 0.162187\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:22.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.145395, Val Loss = 0.160044\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:23.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.144525, Val Loss = 0.159008\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:23.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.125807, Val Loss = 0.134223\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:24.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.119890, Val Loss = 0.127398\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:25.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.116808, Val Loss = 0.122986\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:26.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.109352 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:28.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 138 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:28.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:28.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 4.726091, Val Loss = 3.291416\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:28.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.314105, Val Loss = 0.334805\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:29.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.289765, Val Loss = 0.306846\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:29.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.280091, Val Loss = 0.295910\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:29.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.274683, Val Loss = 0.290069\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:29.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.270668, Val Loss = 0.285943\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:29.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.267227, Val Loss = 0.282531\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:30.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.264116, Val Loss = 0.279506\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:30.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.261247, Val Loss = 0.276750\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:30.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.258585, Val Loss = 0.274208\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:30.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.271873 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:30.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:30.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:30.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.199775, Val Loss = 0.209595\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:31.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.166198, Val Loss = 0.167623\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:33.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.131785, Val Loss = 0.128502\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:34.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.127890, Val Loss = 0.126623\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:35.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.122109, Val Loss = 0.120294\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:36.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.120353, Val Loss = 0.117914\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:38.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.117835, Val Loss = 0.115361\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:39.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.114338, Val Loss = 0.111980\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:40.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.111642, Val Loss = 0.109302\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:41.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.109346, Val Loss = 0.107308\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:42.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.103366 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:45.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 184 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:45.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:45.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.853058, Val Loss = 0.551959\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:45.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.277678, Val Loss = 0.280580\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:45.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.273014, Val Loss = 0.276381\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:45.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.269412, Val Loss = 0.273355\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:46.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.266224, Val Loss = 0.270775\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:46.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.263273, Val Loss = 0.268436\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:46.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.260508, Val Loss = 0.266274\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:46.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.257905, Val Loss = 0.264261\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:46.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.255452, Val Loss = 0.262383\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:47.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.253140, Val Loss = 0.260631\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:47.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.259012 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:47.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:47.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:47.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.214562, Val Loss = 0.242755\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:48.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.176094, Val Loss = 0.193595\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:49.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.138993, Val Loss = 0.148821\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:50.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.125271, Val Loss = 0.132684\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:52.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.120114, Val Loss = 0.128614\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:53.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.118773, Val Loss = 0.127427\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:55.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.118019, Val Loss = 0.126851\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:56.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.117442, Val Loss = 0.126407\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:57.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.116081, Val Loss = 0.126361\u001b[0m\n",
            "\u001b[32m2026-01-24 16:00:59.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.114468, Val Loss = 0.125117\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:00.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.102929 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:02.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 225 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:02.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:02.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.533743, Val Loss = 0.413555\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:02.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.326187, Val Loss = 0.323892\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:02.962\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.315916, Val Loss = 0.313554\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:03.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.309156, Val Loss = 0.307286\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:03.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.303561, Val Loss = 0.302366\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:03.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.298503, Val Loss = 0.298042\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:03.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.293805, Val Loss = 0.294091\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:04.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.289406, Val Loss = 0.290432\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:04.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.285276, Val Loss = 0.287029\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:04.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.281394, Val Loss = 0.283855\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:04.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.280921 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:04.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:04.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:04.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.230576, Val Loss = 0.265026\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:06.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.196364, Val Loss = 0.231067\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:08.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.162747, Val Loss = 0.184570\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:10.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.151600, Val Loss = 0.170783\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:12.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.146602, Val Loss = 0.165147\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:14.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.142444, Val Loss = 0.159467\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:15.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.139501, Val Loss = 0.156086\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:17.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.137534, Val Loss = 0.153807\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:19.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.136153, Val Loss = 0.152095\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:21.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.134845, Val Loss = 0.150539\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:23.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.120645 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:27.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 272 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:27.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:27.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.520396, Val Loss = 0.349945\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:27.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.299748, Val Loss = 0.300509\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:27.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.291315, Val Loss = 0.294248\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:27.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.285699, Val Loss = 0.289956\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:27.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.281117, Val Loss = 0.286297\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:28.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.277023, Val Loss = 0.282924\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:28.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.273245, Val Loss = 0.279756\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:28.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.269716, Val Loss = 0.276773\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:28.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.266409, Val Loss = 0.273968\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:29.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.263305, Val Loss = 0.271337\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:29.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.268895 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:29.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:29.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:29.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.215447, Val Loss = 0.229727\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:31.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.169879, Val Loss = 0.172418\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:33.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.140185, Val Loss = 0.146380\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:34.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.135162, Val Loss = 0.142092\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:36.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.133116, Val Loss = 0.139281\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:38.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.131107, Val Loss = 0.136689\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:40.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.129716, Val Loss = 0.135411\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:41.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.127408, Val Loss = 0.133397\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:43.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.126115, Val Loss = 0.131849\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:45.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.124889, Val Loss = 0.130631\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:47.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.116984 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:50.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 317 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:50.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:50.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.297855, Val Loss = 0.299711\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:50.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.264685, Val Loss = 0.273794\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:50.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.257544, Val Loss = 0.266867\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:51.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.254057, Val Loss = 0.263817\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:51.376\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.251587, Val Loss = 0.261798\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:51.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.249462, Val Loss = 0.260103\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:51.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.247509, Val Loss = 0.258558\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:52.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.245679, Val Loss = 0.257117\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:52.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.243954, Val Loss = 0.255766\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:52.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.242325, Val Loss = 0.254498\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:52.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.253320 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:52.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:52.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:53.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.187131, Val Loss = 0.201912\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:55.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.133699, Val Loss = 0.140078\u001b[0m\n",
            "\u001b[32m2026-01-24 16:01:57.901\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.116453, Val Loss = 0.128478\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:00.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.112927, Val Loss = 0.121884\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:02.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.111761, Val Loss = 0.120342\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:05.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.110161, Val Loss = 0.118386\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:08.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.109574, Val Loss = 0.117663\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:10.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.109024, Val Loss = 0.117077\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:13.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.108509, Val Loss = 0.116532\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:15.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.108060, Val Loss = 0.115954\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:17.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.105074 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:21.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 360 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:21.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:21.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.375707, Val Loss = 0.502524\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:21.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.281138, Val Loss = 0.286688\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:22.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.266853, Val Loss = 0.276466\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:22.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.260699, Val Loss = 0.272306\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:22.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.257108, Val Loss = 0.269848\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:23.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.254393, Val Loss = 0.267872\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:23.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.252037, Val Loss = 0.266062\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:23.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.249879, Val Loss = 0.264347\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:24.028\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.247863, Val Loss = 0.262718\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:24.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.245970, Val Loss = 0.261177\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:24.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.259736 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:24.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:24.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:24.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.196908, Val Loss = 0.220228\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:26.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.138330, Val Loss = 0.146863\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:28.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.127370, Val Loss = 0.136553\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:30.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.116896, Val Loss = 0.128361\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:31.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.112105, Val Loss = 0.121892\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:33.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.110918, Val Loss = 0.120268\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:35.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.110060, Val Loss = 0.119301\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:36.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.109275, Val Loss = 0.118433\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:38.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.108540, Val Loss = 0.117649\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:40.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.107725, Val Loss = 0.116718\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:41.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.106278 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:43.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 404 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:43.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:43.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.330642, Val Loss = 0.294057\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:43.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.268168, Val Loss = 0.275772\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:44.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.262821, Val Loss = 0.271392\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:44.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.259542, Val Loss = 0.268852\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:44.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.256895, Val Loss = 0.266783\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:44.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.254512, Val Loss = 0.264881\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:44.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.252295, Val Loss = 0.263086\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:45.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.250210, Val Loss = 0.261388\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:45.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.248246, Val Loss = 0.259788\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:45.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.246392, Val Loss = 0.258282\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:45.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.256881 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:45.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:45.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:45.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.191781, Val Loss = 0.214736\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:47.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.137379, Val Loss = 0.146344\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:49.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.123769, Val Loss = 0.135594\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:52.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.119465, Val Loss = 0.131061\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:54.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.116421, Val Loss = 0.127728\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:56.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.113449, Val Loss = 0.124379\u001b[0m\n",
            "\u001b[32m2026-01-24 16:02:58.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.111685, Val Loss = 0.122151\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:01.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.109970, Val Loss = 0.119876\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:03.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.108456, Val Loss = 0.118061\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:05.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.107105, Val Loss = 0.116443\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:07.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.103215 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:10.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 447 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:10.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:10.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.494472, Val Loss = 0.324110\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:10.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.290811, Val Loss = 0.294211\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:10.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.281805, Val Loss = 0.287303\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:10.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.276523, Val Loss = 0.283224\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:11.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.272524, Val Loss = 0.280039\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:11.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.269060, Val Loss = 0.277202\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:11.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.265894, Val Loss = 0.274564\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:11.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.262946, Val Loss = 0.272086\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:12.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.260182, Val Loss = 0.269755\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:12.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.257584, Val Loss = 0.267567\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:12.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.265533 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:12.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=10.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:12.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:12.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.215838, Val Loss = 0.248321\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:15.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.160146, Val Loss = 0.168874\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:17.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.132055, Val Loss = 0.146564\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:20.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.128137, Val Loss = 0.142204\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:23.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.125948, Val Loss = 0.139161\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:26.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.124252, Val Loss = 0.137194\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:29.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.122764, Val Loss = 0.135325\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:32.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.121239, Val Loss = 0.133546\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:34.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.120281, Val Loss = 0.132478\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:37.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.119553, Val Loss = 0.131733\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:40.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.109696 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:43.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mModel initialized\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:43.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mModel initialized\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:43.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mTraining set: 864 samples, Validation set: 97 samples\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:43.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 50 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:43.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:43.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.561645, Val Loss = 0.493148\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:43.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.329690, Val Loss = 0.324816\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:43.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.316290, Val Loss = 0.317224\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:43.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.309114, Val Loss = 0.311759\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:43.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.303326, Val Loss = 0.306946\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:44.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.298237, Val Loss = 0.302534\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:44.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.293597, Val Loss = 0.298381\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:44.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.289292, Val Loss = 0.294451\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:44.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.285278, Val Loss = 0.290762\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:44.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.281524, Val Loss = 0.287290\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:44.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.284052 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:44.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=5.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:44.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:44.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.223511, Val Loss = 0.193123\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:45.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.153808, Val Loss = 0.138103\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:45.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.144878, Val Loss = 0.131461\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:46.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.140034, Val Loss = 0.127468\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:46.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.135637, Val Loss = 0.123333\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:47.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.132289, Val Loss = 0.121464\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:47.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.129226, Val Loss = 0.119659\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:48.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.125903, Val Loss = 0.116595\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:48.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.122668, Val Loss = 0.114258\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:49.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.120825, Val Loss = 0.113723\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:49.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.110340 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:51.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 95 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:51.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:51.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.287103, Val Loss = 1.155724\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:51.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.327193, Val Loss = 0.361901\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:51.749\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.291842, Val Loss = 0.319698\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:51.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.275631, Val Loss = 0.299737\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:51.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.267528, Val Loss = 0.289493\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:52.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.262929, Val Loss = 0.283616\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:52.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.259890, Val Loss = 0.279772\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:52.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.257575, Val Loss = 0.276925\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:52.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.255626, Val Loss = 0.274607\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:52.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.253878, Val Loss = 0.272596\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:52.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.270802 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:52.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=5.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:52.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:52.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.198808, Val Loss = 0.163924\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:53.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.134951, Val Loss = 0.114458\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:53.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.126850, Val Loss = 0.111055\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:54.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.120961, Val Loss = 0.107692\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:55.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.117506, Val Loss = 0.105173\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:55.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.114618, Val Loss = 0.103190\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:56.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.112590, Val Loss = 0.101937\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:57.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.110809, Val Loss = 0.100699\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:57.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.109267, Val Loss = 0.099573\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:58.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.107779, Val Loss = 0.098801\u001b[0m\n",
            "\u001b[32m2026-01-24 16:03:59.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.097823 at iteration 996\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:01.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 140 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:01.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:01.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.832575, Val Loss = 0.683729\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:01.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.282487, Val Loss = 0.286420\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:01.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.273357, Val Loss = 0.279016\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:01.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.268135, Val Loss = 0.274842\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:01.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.264551, Val Loss = 0.271904\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:01.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.261717, Val Loss = 0.269479\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:01.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.259276, Val Loss = 0.267302\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:02.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.257076, Val Loss = 0.265276\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:02.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.255047, Val Loss = 0.263369\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:02.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.253155, Val Loss = 0.261567\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:02.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.259879 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:02.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=5.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:02.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:02.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.244336, Val Loss = 0.222099\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:03.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.164065, Val Loss = 0.140481\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:03.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.131837, Val Loss = 0.122549\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:04.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.127859, Val Loss = 0.120591\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:05.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.123269, Val Loss = 0.118156\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:06.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.120840, Val Loss = 0.116548\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:07.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.118612, Val Loss = 0.114115\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:07.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.116141, Val Loss = 0.109965\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:08.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.114294, Val Loss = 0.108103\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:09.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.112624, Val Loss = 0.106448\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:10.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.104976 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:11.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 184 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:11.749\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:11.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.946742, Val Loss = 0.639745\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:11.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.296372, Val Loss = 0.304745\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:11.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.289996, Val Loss = 0.298868\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:12.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.284448, Val Loss = 0.293731\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:12.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.279494, Val Loss = 0.289118\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:12.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.275015, Val Loss = 0.284917\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:12.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.270943, Val Loss = 0.281064\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:12.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.267226, Val Loss = 0.277525\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:12.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.263826, Val Loss = 0.274267\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:12.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.260711, Val Loss = 0.271267\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:12.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.268525 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:12.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=5.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:12.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:12.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.210005, Val Loss = 0.184188\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:13.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.151684, Val Loss = 0.143497\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:14.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.132994, Val Loss = 0.125789\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:15.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.130899, Val Loss = 0.122912\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:16.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.127964, Val Loss = 0.118446\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:17.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.126137, Val Loss = 0.116317\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:17.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.125653, Val Loss = 0.115532\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:18.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.125249, Val Loss = 0.114720\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:19.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.124902, Val Loss = 0.114092\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:20.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.124593, Val Loss = 0.113602\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:20.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.113211 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:22.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 230 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:22.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:22.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 3.958738, Val Loss = 1.542494\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:22.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.363935, Val Loss = 0.359053\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:23.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.314430, Val Loss = 0.317154\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:23.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.295500, Val Loss = 0.301281\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:23.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.286874, Val Loss = 0.293992\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:23.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.281907, Val Loss = 0.289653\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:23.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.278347, Val Loss = 0.286410\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:23.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.275402, Val Loss = 0.283638\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:23.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.272779, Val Loss = 0.281121\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:24.017\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.270363, Val Loss = 0.278779\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:24.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.276601 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:24.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=5.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:24.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:24.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.215392, Val Loss = 0.189084\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:25.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.149196, Val Loss = 0.141232\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:26.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.140408, Val Loss = 0.137096\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:27.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.135968, Val Loss = 0.132385\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:28.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.134059, Val Loss = 0.129417\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:29.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.132722, Val Loss = 0.127363\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:30.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.131497, Val Loss = 0.125920\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:32.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.128948, Val Loss = 0.123018\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:33.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.124695, Val Loss = 0.118963\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:34.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.121473, Val Loss = 0.115809\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:35.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.113908 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:38.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 272 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:38.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:38.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 3.454635, Val Loss = 1.114758\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:38.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.279961, Val Loss = 0.282367\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:38.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.276663, Val Loss = 0.279603\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:38.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.273705, Val Loss = 0.277022\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:38.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.270969, Val Loss = 0.274575\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:38.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.268410, Val Loss = 0.272253\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:38.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.266003, Val Loss = 0.270052\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:39.028\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.263734, Val Loss = 0.267969\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:39.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.261592, Val Loss = 0.265999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:39.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.259567, Val Loss = 0.264137\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:39.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.262394 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:39.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=5.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:39.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:39.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.204843, Val Loss = 0.168860\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:40.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.147682, Val Loss = 0.130908\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:41.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.132854, Val Loss = 0.120273\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:42.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.128332, Val Loss = 0.116027\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:43.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.124455, Val Loss = 0.112807\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:44.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.121192, Val Loss = 0.110757\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:46.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.119206, Val Loss = 0.109362\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:47.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.117452, Val Loss = 0.108143\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:48.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.115836, Val Loss = 0.106961\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:49.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.114326, Val Loss = 0.105799\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:50.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.104684 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:52.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 316 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:52.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:52.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.350451, Val Loss = 0.315197\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:52.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.292274, Val Loss = 0.295248\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:52.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.287304, Val Loss = 0.290875\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:53.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.283050, Val Loss = 0.287065\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:53.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.279246, Val Loss = 0.283606\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:53.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.275775, Val Loss = 0.280414\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:53.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.272576, Val Loss = 0.277448\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:53.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.269612, Val Loss = 0.274686\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:53.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.266860, Val Loss = 0.272110\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:53.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.264297, Val Loss = 0.269706\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:54.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.267484 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:54.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=5.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:54.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:54.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.209705, Val Loss = 0.188190\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:55.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.148411, Val Loss = 0.140602\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:57.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.133444, Val Loss = 0.130889\u001b[0m\n",
            "\u001b[32m2026-01-24 16:04:58.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.126076, Val Loss = 0.118960\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:00.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.122395, Val Loss = 0.115750\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:01.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.121687, Val Loss = 0.115083\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:03.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.121011, Val Loss = 0.114581\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:04.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.120344, Val Loss = 0.114246\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:06.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.119695, Val Loss = 0.113975\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:08.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.119065, Val Loss = 0.113722\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:09.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.111910 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:12.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 358 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:12.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:12.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 8.257029, Val Loss = 1.537613\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:12.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.337863, Val Loss = 0.343395\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:12.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.312636, Val Loss = 0.318209\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:12.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.301474, Val Loss = 0.306564\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:13.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.294833, Val Loss = 0.299601\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:13.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.289813, Val Loss = 0.294472\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:13.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.285509, Val Loss = 0.290209\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:13.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.281625, Val Loss = 0.286450\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:13.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.278052, Val Loss = 0.283043\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:14.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.274740, Val Loss = 0.279912\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:14.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.277040 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:14.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=5.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:14.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:14.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.224299, Val Loss = 0.192402\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:16.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.156830, Val Loss = 0.141159\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:17.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.148134, Val Loss = 0.134849\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:19.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.143110, Val Loss = 0.131752\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:21.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.140476, Val Loss = 0.129770\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:23.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.138696, Val Loss = 0.128193\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:25.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.136880, Val Loss = 0.124672\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:27.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.135815, Val Loss = 0.123028\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:29.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.134594, Val Loss = 0.121396\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:31.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.132585, Val Loss = 0.119881\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:33.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.118181 at iteration 990\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:35.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 404 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:35.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:35.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.779058, Val Loss = 0.366635\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:36.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.314407, Val Loss = 0.316582\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:36.377\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.308069, Val Loss = 0.311151\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:36.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.302529, Val Loss = 0.306255\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:36.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.297515, Val Loss = 0.301730\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:36.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.292918, Val Loss = 0.297523\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:37.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.288680, Val Loss = 0.293606\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:37.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.284761, Val Loss = 0.289959\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:37.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.281129, Val Loss = 0.286563\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:37.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.277759, Val Loss = 0.283399\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:37.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.280479 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:37.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=5.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:37.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:37.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.228643, Val Loss = 0.194240\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:40.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.153548, Val Loss = 0.137277\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:41.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.146217, Val Loss = 0.132381\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:43.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.141835, Val Loss = 0.129066\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:46.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.139290, Val Loss = 0.126441\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:48.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.137761, Val Loss = 0.124801\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:50.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.136605, Val Loss = 0.123594\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:52.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.135628, Val Loss = 0.122616\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:54.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.134755, Val Loss = 0.121770\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:56.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.133950, Val Loss = 0.121003\u001b[0m\n",
            "\u001b[32m2026-01-24 16:05:58.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.120302 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:01.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 448 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:01.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:01.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.712499, Val Loss = 0.349033\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:01.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.288702, Val Loss = 0.300939\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:01.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.277300, Val Loss = 0.288717\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:02.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.271317, Val Loss = 0.282106\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:02.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.267193, Val Loss = 0.277607\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:02.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.263829, Val Loss = 0.274045\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:02.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.260869, Val Loss = 0.270991\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:02.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.258184, Val Loss = 0.268267\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:03.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.255720, Val Loss = 0.265793\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:03.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.253447, Val Loss = 0.263521\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:03.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.261443 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:03.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=5.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:03.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:03.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.202288, Val Loss = 0.168323\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:05.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.137084, Val Loss = 0.124886\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:07.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.124798, Val Loss = 0.117257\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:09.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.121486, Val Loss = 0.111654\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:11.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.118093, Val Loss = 0.107606\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:13.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.116976, Val Loss = 0.106825\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:15.958\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.115521, Val Loss = 0.106155\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:18.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.114365, Val Loss = 0.105530\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:20.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.113335, Val Loss = 0.104969\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:22.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.112380, Val Loss = 0.104170\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:24.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.102196 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:26.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mModel initialized\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:26.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mModel initialized\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:26.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mTraining set: 864 samples, Validation set: 97 samples\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:26.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 50 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:26.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:26.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.369383, Val Loss = 1.336207\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:27.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.363348, Val Loss = 0.356879\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:27.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.319792, Val Loss = 0.315143\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:27.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.306643, Val Loss = 0.302007\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:27.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.297976, Val Loss = 0.293468\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:27.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.291294, Val Loss = 0.287129\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:27.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.285652, Val Loss = 0.282004\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:27.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.280643, Val Loss = 0.277620\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:27.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.276067, Val Loss = 0.273697\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:27.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.271855, Val Loss = 0.270181\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:27.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.267003 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:27.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:27.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:27.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.238439, Val Loss = 0.222244\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:28.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.187915, Val Loss = 0.165253\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:28.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.158842, Val Loss = 0.144241\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:29.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.149940, Val Loss = 0.140824\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:29.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.141409, Val Loss = 0.138751\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:30.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.138716, Val Loss = 0.138838\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:30.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.135662, Val Loss = 0.138471\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:31.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.129518, Val Loss = 0.137196\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:32.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.126289, Val Loss = 0.136894\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:32.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.123996, Val Loss = 0.136155\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:33.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.106844 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:35.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 94 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:35.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:35.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.660447, Val Loss = 0.543127\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:35.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.318833, Val Loss = 0.325603\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:35.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.286413, Val Loss = 0.294385\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:35.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.273885, Val Loss = 0.282877\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:35.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.267635, Val Loss = 0.277524\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:35.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.263473, Val Loss = 0.274158\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:35.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.260096, Val Loss = 0.271499\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:36.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.257091, Val Loss = 0.269144\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:36.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.254323, Val Loss = 0.266980\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:36.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.251745, Val Loss = 0.264962\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:36.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.263090 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:36.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:36.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:36.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.217782, Val Loss = 0.187115\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:37.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.153857, Val Loss = 0.119679\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:37.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.138529, Val Loss = 0.113006\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:38.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.126110, Val Loss = 0.107465\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:38.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.117572, Val Loss = 0.105386\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:39.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.111428, Val Loss = 0.105047\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:40.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.106619, Val Loss = 0.106498\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:40.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.103929, Val Loss = 0.108091\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:41.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.102802, Val Loss = 0.107730\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:42.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.101606, Val Loss = 0.107846\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:42.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.098153 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:44.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 135 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:44.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:44.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.697520, Val Loss = 0.552552\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:44.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.328029, Val Loss = 0.327249\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:44.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.307422, Val Loss = 0.308663\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:44.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.297254, Val Loss = 0.300009\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:45.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.290518, Val Loss = 0.294528\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:45.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.285070, Val Loss = 0.290186\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:45.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.280248, Val Loss = 0.286372\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:45.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.275826, Val Loss = 0.282888\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:45.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.271721, Val Loss = 0.279665\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:45.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.267892, Val Loss = 0.276665\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:45.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.273900 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:45.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:45.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:45.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.234965, Val Loss = 0.220580\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:46.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.168827, Val Loss = 0.144954\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:47.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.150743, Val Loss = 0.138501\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:47.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.137588, Val Loss = 0.133108\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:48.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.129555, Val Loss = 0.131227\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:49.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.122831, Val Loss = 0.129156\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:50.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.118699, Val Loss = 0.129102\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:51.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.115515, Val Loss = 0.129758\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:51.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.113950, Val Loss = 0.128591\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:52.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.112454, Val Loss = 0.127778\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:53.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.100426 at iteration 997\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:55.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 185 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:55.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:55.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.404337, Val Loss = 0.405257\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:55.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.335649, Val Loss = 0.338959\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:55.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.308887, Val Loss = 0.312921\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:55.958\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.295122, Val Loss = 0.299419\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:56.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.286924, Val Loss = 0.291484\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:56.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.281218, Val Loss = 0.286142\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:56.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.276709, Val Loss = 0.282091\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:56.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.272839, Val Loss = 0.278744\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:56.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.269364, Val Loss = 0.275830\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:56.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.266174, Val Loss = 0.273215\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:56.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.270852 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:56.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:56.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:56.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.233739, Val Loss = 0.201579\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:57.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.166693, Val Loss = 0.136595\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:58.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.146836, Val Loss = 0.126514\u001b[0m\n",
            "\u001b[32m2026-01-24 16:06:59.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.131878, Val Loss = 0.122307\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:00.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.122224, Val Loss = 0.123073\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:01.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.115240, Val Loss = 0.123857\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:02.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.111429, Val Loss = 0.124250\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:03.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.109030, Val Loss = 0.123643\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:04.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.107328, Val Loss = 0.123228\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:06.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.105911, Val Loss = 0.122182\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:07.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.093635 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:09.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 229 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:09.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:09.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.343633, Val Loss = 0.346260\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:09.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.308060, Val Loss = 0.314415\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:09.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.294333, Val Loss = 0.300863\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:09.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.286396, Val Loss = 0.293451\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:09.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.280843, Val Loss = 0.288539\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:09.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.276374, Val Loss = 0.284748\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:09.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.272479, Val Loss = 0.281535\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:10.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.268944, Val Loss = 0.278673\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:10.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.265676, Val Loss = 0.276063\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:10.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.262630, Val Loss = 0.273655\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:10.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.271440 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:10.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:10.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:10.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.230951, Val Loss = 0.190028\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:11.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.168451, Val Loss = 0.133773\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:12.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.148268, Val Loss = 0.126211\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:14.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.134579, Val Loss = 0.121976\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:15.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.127980, Val Loss = 0.122147\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:16.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.124503, Val Loss = 0.123681\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:17.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.118386, Val Loss = 0.123442\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:18.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.114802, Val Loss = 0.123945\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:20.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.112726, Val Loss = 0.124194\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:21.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.111062, Val Loss = 0.123536\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:22.538\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.097588 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:24.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 275 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:24.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:24.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 2.518694, Val Loss = 0.883369\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:24.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.253939, Val Loss = 0.266635\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:25.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.251479, Val Loss = 0.264494\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:25.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.249233, Val Loss = 0.262658\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:25.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.247142, Val Loss = 0.261022\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:25.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.245183, Val Loss = 0.259532\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:25.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.243343, Val Loss = 0.258163\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:25.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.241612, Val Loss = 0.256895\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:26.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.239981, Val Loss = 0.255717\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:26.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.238444, Val Loss = 0.254621\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:26.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.253608 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:26.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:26.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:26.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.208663, Val Loss = 0.173732\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:27.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.151403, Val Loss = 0.123929\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:29.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.129107, Val Loss = 0.112119\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:30.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.114987, Val Loss = 0.107308\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:32.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.108742, Val Loss = 0.108594\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:33.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.103799, Val Loss = 0.109786\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:35.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.100219, Val Loss = 0.109478\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:36.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.098516, Val Loss = 0.109995\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:38.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.097444, Val Loss = 0.110001\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:39.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.096640, Val Loss = 0.109649\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:41.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.089571 at iteration 997\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:43.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 321 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:43.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:43.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.201204, Val Loss = 0.512632\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:43.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.300594, Val Loss = 0.307662\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:44.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.282823, Val Loss = 0.290210\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:44.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.274231, Val Loss = 0.282533\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:44.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.268958, Val Loss = 0.278241\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:44.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.265003, Val Loss = 0.275197\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:44.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.261658, Val Loss = 0.272670\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:44.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.258657, Val Loss = 0.270406\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:45.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.255894, Val Loss = 0.268311\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:45.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.253320, Val Loss = 0.266351\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:45.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.264527 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:45.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:45.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:45.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.223596, Val Loss = 0.184264\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:47.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.161677, Val Loss = 0.126320\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:48.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.138912, Val Loss = 0.119556\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:50.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.128371, Val Loss = 0.117359\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:52.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.121122, Val Loss = 0.115914\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:54.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.115434, Val Loss = 0.116056\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:55.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.113564, Val Loss = 0.117009\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:57.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.112103, Val Loss = 0.117765\u001b[0m\n",
            "\u001b[32m2026-01-24 16:07:59.029\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.111339, Val Loss = 0.117660\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:00.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.110416, Val Loss = 0.117911\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:02.376\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.101044 at iteration 995\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:05.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 365 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:05.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:05.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.919660, Val Loss = 0.565954\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:05.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.304399, Val Loss = 0.300614\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:05.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.293618, Val Loss = 0.292680\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:05.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.287197, Val Loss = 0.288138\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:06.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.282326, Val Loss = 0.284660\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:06.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.278130, Val Loss = 0.281593\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:06.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.274323, Val Loss = 0.278761\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:06.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.270802, Val Loss = 0.276116\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:06.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.267520, Val Loss = 0.273644\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:07.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.264454, Val Loss = 0.271336\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:07.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.269204 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:07.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:07.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:07.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.234636, Val Loss = 0.196081\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:09.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.169910, Val Loss = 0.139095\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:11.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.149388, Val Loss = 0.131786\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:13.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.135995, Val Loss = 0.128025\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:15.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.128806, Val Loss = 0.126224\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:17.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.123207, Val Loss = 0.125903\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:19.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.121733, Val Loss = 0.126271\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:21.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.120306, Val Loss = 0.127012\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:23.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.119223, Val Loss = 0.127638\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:25.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.118704, Val Loss = 0.127869\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:27.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.108573 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:29.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 408 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:29.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:29.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.985683, Val Loss = 0.362003\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:30.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.288704, Val Loss = 0.297905\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:30.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.281723, Val Loss = 0.291264\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:30.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.277044, Val Loss = 0.287036\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:30.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.273233, Val Loss = 0.283756\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:30.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.269840, Val Loss = 0.280937\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:31.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.266715, Val Loss = 0.278402\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:31.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.263802, Val Loss = 0.276074\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:31.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.261072, Val Loss = 0.273919\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:31.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.258511, Val Loss = 0.271911\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:31.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.270056 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:31.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:31.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:31.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.228024, Val Loss = 0.189179\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:33.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.161634, Val Loss = 0.129469\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:35.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.141000, Val Loss = 0.121596\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:37.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.126682, Val Loss = 0.116162\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:39.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.117769, Val Loss = 0.114823\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:41.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.113889, Val Loss = 0.114099\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:42.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.112721, Val Loss = 0.115171\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:44.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.112047, Val Loss = 0.115065\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:46.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.111863, Val Loss = 0.115346\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:48.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.111160, Val Loss = 0.116298\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:49.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.106432 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:51.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 454 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:51.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:51.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.921343, Val Loss = 0.341615\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:52.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.284725, Val Loss = 0.292997\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:52.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.278676, Val Loss = 0.287997\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:52.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.274199, Val Loss = 0.284483\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:52.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.270458, Val Loss = 0.281601\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:53.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.267126, Val Loss = 0.279038\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:53.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.264070, Val Loss = 0.276678\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:53.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.261231, Val Loss = 0.274474\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:53.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.258578, Val Loss = 0.272405\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:54.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.256093, Val Loss = 0.270458\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:54.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.268644 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:54.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=1.0, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:54.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:54.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.227105, Val Loss = 0.192741\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:57.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.160392, Val Loss = 0.128160\u001b[0m\n",
            "\u001b[32m2026-01-24 16:08:59.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.146806, Val Loss = 0.122853\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:02.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.136119, Val Loss = 0.120830\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:05.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.126024, Val Loss = 0.117490\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:08.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.119878, Val Loss = 0.116411\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:11.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.114285, Val Loss = 0.113812\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:13.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.111128, Val Loss = 0.113225\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:16.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.109027, Val Loss = 0.113159\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:19.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.107585, Val Loss = 0.113108\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:22.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.105199 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:24.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mModel initialized\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:24.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mModel initialized\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:24.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mTraining set: 864 samples, Validation set: 97 samples\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:24.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 50 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:24.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:24.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.309092, Val Loss = 1.200554\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:24.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.404362, Val Loss = 0.401968\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:24.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.307560, Val Loss = 0.314100\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:24.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.275018, Val Loss = 0.283805\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:25.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.260933, Val Loss = 0.271314\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:25.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.253709, Val Loss = 0.265366\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:25.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.249179, Val Loss = 0.261828\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:25.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.245783, Val Loss = 0.259205\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:25.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.242930, Val Loss = 0.256979\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:25.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.240388, Val Loss = 0.254969\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:25.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.253132 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:25.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:25.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:25.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.232184, Val Loss = 0.197979\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:26.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.156026, Val Loss = 0.126407\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:26.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.129846, Val Loss = 0.111807\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:27.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.119749, Val Loss = 0.108793\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:27.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.109861, Val Loss = 0.102879\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:28.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.106823, Val Loss = 0.100129\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:28.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.105378, Val Loss = 0.099023\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:29.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.104263, Val Loss = 0.098211\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:29.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.103296, Val Loss = 0.097489\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:30.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.102273, Val Loss = 0.096554\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:30.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.095797 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:32.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 91 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:32.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:32.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 2.727576, Val Loss = 2.414962\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:32.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.353945, Val Loss = 0.364816\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:32.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.319719, Val Loss = 0.329041\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:32.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.304408, Val Loss = 0.313487\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:32.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.295552, Val Loss = 0.304991\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:32.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.289092, Val Loss = 0.299163\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:32.958\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.283678, Val Loss = 0.294498\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:33.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.278853, Val Loss = 0.290457\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:33.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.274450, Val Loss = 0.286830\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:33.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.270393, Val Loss = 0.283526\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:33.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.280522 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:33.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:33.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:33.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.264661, Val Loss = 0.221183\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:33.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.174068, Val Loss = 0.136974\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:34.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.149570, Val Loss = 0.120634\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:35.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.141214, Val Loss = 0.117093\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:35.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.136961, Val Loss = 0.117207\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:36.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.128212, Val Loss = 0.115268\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:37.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.122837, Val Loss = 0.111658\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:37.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.120002, Val Loss = 0.108959\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:38.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.117824, Val Loss = 0.106905\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:39.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.116084, Val Loss = 0.105483\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:39.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.104523 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:41.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 133 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:41.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:41.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.360704, Val Loss = 0.994409\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:41.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.340454, Val Loss = 0.343287\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:41.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.327638, Val Loss = 0.331224\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:41.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.318280, Val Loss = 0.322682\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:41.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.310477, Val Loss = 0.315780\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:41.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.303556, Val Loss = 0.309804\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:41.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.297249, Val Loss = 0.304449\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:41.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.291444, Val Loss = 0.299577\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:42.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.286075, Val Loss = 0.295112\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:42.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.281102, Val Loss = 0.291006\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:42.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.287255 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:42.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:42.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:42.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.273667, Val Loss = 0.225825\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:43.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.193128, Val Loss = 0.144128\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:43.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.163597, Val Loss = 0.124648\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:44.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.151251, Val Loss = 0.122226\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:45.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.145794, Val Loss = 0.123010\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:46.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.138628, Val Loss = 0.119918\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:46.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.134265, Val Loss = 0.118181\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:47.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.131772, Val Loss = 0.116428\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:48.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.129312, Val Loss = 0.114513\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:49.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.127004, Val Loss = 0.112205\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:49.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.110657 at iteration 992\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:52.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 178 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:52.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:52.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.574773, Val Loss = 0.493416\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:52.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.308339, Val Loss = 0.320296\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:52.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.294467, Val Loss = 0.305391\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:52.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.286501, Val Loss = 0.297125\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:52.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.280646, Val Loss = 0.291423\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:52.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.275704, Val Loss = 0.286887\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:52.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.271282, Val Loss = 0.283002\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:52.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.267240, Val Loss = 0.279558\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:53.028\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.263514, Val Loss = 0.276447\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:53.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.260068, Val Loss = 0.273609\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:53.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.271034 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:53.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:53.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:53.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.255680, Val Loss = 0.222060\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:54.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.166111, Val Loss = 0.128096\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:54.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.139281, Val Loss = 0.112062\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:55.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.129187, Val Loss = 0.108635\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:56.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.124794, Val Loss = 0.107978\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:57.493\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.122464, Val Loss = 0.107944\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:58.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.121052, Val Loss = 0.107967\u001b[0m\n",
            "\u001b[32m2026-01-24 16:09:59.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.115475, Val Loss = 0.105502\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:00.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.112485, Val Loss = 0.103966\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:01.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.111006, Val Loss = 0.102150\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:01.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.101110 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:03.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 222 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:03.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:03.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.465991, Val Loss = 0.364833\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:03.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.309959, Val Loss = 0.308850\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:03.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.300537, Val Loss = 0.300720\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:04.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.293324, Val Loss = 0.294755\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:04.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.287213, Val Loss = 0.289812\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:04.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.281779, Val Loss = 0.285468\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:04.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.276846, Val Loss = 0.281554\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:04.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.272327, Val Loss = 0.277992\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:04.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.268173, Val Loss = 0.274739\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:04.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.264347, Val Loss = 0.271767\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:04.958\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.269072 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:04.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:04.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:04.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.257353, Val Loss = 0.221143\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:06.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.169830, Val Loss = 0.136497\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:07.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.148962, Val Loss = 0.121692\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:08.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.136627, Val Loss = 0.114450\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:09.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.131481, Val Loss = 0.112969\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:10.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.128777, Val Loss = 0.112704\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:11.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.127203, Val Loss = 0.112798\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:12.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.126223, Val Loss = 0.112972\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:13.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.125583, Val Loss = 0.113177\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:14.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.125171, Val Loss = 0.113435\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:15.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.112692 at iteration 504\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:18.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 267 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:18.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:18.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 8.953004, Val Loss = 2.803262\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:18.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.283693, Val Loss = 0.290534\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:18.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.273621, Val Loss = 0.280716\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:19.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.267460, Val Loss = 0.275115\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:19.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.262917, Val Loss = 0.271236\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:19.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.259145, Val Loss = 0.268157\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:19.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.255823, Val Loss = 0.265532\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:19.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.252819, Val Loss = 0.263211\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:19.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.250073, Val Loss = 0.261128\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:20.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.247550, Val Loss = 0.259246\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:20.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.257554 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:20.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:20.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:20.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.243710, Val Loss = 0.207124\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:21.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.157623, Val Loss = 0.121979\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:23.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.128809, Val Loss = 0.104370\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:24.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.117353, Val Loss = 0.099105\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:25.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.110058, Val Loss = 0.097206\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:27.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.105202, Val Loss = 0.096670\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:28.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.102951, Val Loss = 0.096406\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:29.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.101489, Val Loss = 0.095772\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:31.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.100106, Val Loss = 0.095022\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:32.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.098820, Val Loss = 0.093983\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:34.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.093085 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:36.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 313 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:36.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:36.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 4.264331, Val Loss = 1.154564\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:36.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.270888, Val Loss = 0.275321\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:37.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.265686, Val Loss = 0.271710\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:37.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.261599, Val Loss = 0.268799\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:37.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.258039, Val Loss = 0.266184\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:37.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.254812, Val Loss = 0.263763\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:37.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.251845, Val Loss = 0.261514\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:37.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.249104, Val Loss = 0.259428\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:38.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.246566, Val Loss = 0.257500\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:38.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.244214, Val Loss = 0.255721\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:38.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.254094 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:38.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:38.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:38.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.238532, Val Loss = 0.200951\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:39.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.150260, Val Loss = 0.115850\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:41.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.123878, Val Loss = 0.102102\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:43.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.114074, Val Loss = 0.099964\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:44.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.106650, Val Loss = 0.096174\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:46.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.104190, Val Loss = 0.095749\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:47.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.102737, Val Loss = 0.095187\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:49.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.101560, Val Loss = 0.094907\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:51.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.100364, Val Loss = 0.093976\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:53.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.099446, Val Loss = 0.093137\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:55.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.092618 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:57.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 356 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:57.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:57.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.862448, Val Loss = 0.534267\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:57.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.282542, Val Loss = 0.294411\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:57.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.275003, Val Loss = 0.287473\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:58.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.269828, Val Loss = 0.283013\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:58.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.265697, Val Loss = 0.279599\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:58.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.262110, Val Loss = 0.276696\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:58.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.258870, Val Loss = 0.274099\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:58.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.255895, Val Loss = 0.271724\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:58.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.253142, Val Loss = 0.269533\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:59.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.250587, Val Loss = 0.267504\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:59.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.265640 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:59.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:59.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:10:59.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.247033, Val Loss = 0.208426\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:01.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.166345, Val Loss = 0.126581\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:02.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.133365, Val Loss = 0.100661\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:04.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.122597, Val Loss = 0.097773\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:06.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.118153, Val Loss = 0.097229\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:08.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.112324, Val Loss = 0.096199\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:10.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.108723, Val Loss = 0.095349\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:11.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.106820, Val Loss = 0.094390\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:13.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.105367, Val Loss = 0.093601\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:15.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.104268, Val Loss = 0.092809\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:17.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.092161 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:21.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 402 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:21.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:21.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.658747, Val Loss = 0.332704\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:21.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.288723, Val Loss = 0.296496\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:21.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.280097, Val Loss = 0.288762\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:21.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.274217, Val Loss = 0.283764\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:22.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.269513, Val Loss = 0.279875\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:22.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.265420, Val Loss = 0.276532\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:22.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.261723, Val Loss = 0.273531\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:22.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.258331, Val Loss = 0.270793\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:22.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.255200, Val Loss = 0.268278\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:23.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.252302, Val Loss = 0.265964\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:23.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.263851 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:23.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:23.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:23.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.248690, Val Loss = 0.201569\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:25.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.157848, Val Loss = 0.118412\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:27.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.136790, Val Loss = 0.106789\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:30.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.127064, Val Loss = 0.102499\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:32.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.122719, Val Loss = 0.101677\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:35.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.120400, Val Loss = 0.101564\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:37.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.119006, Val Loss = 0.101603\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:40.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.118114, Val Loss = 0.101669\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:42.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.117512, Val Loss = 0.101734\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:44.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.113669, Val Loss = 0.100084\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:47.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.098433 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:50.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 444 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:50.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:50.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.565650, Val Loss = 0.293712\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:50.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.268049, Val Loss = 0.276952\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:50.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.263858, Val Loss = 0.273291\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:50.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.260241, Val Loss = 0.270267\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:51.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.256977, Val Loss = 0.267625\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:51.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.253981, Val Loss = 0.265254\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:51.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.251215, Val Loss = 0.263102\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:51.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.248656, Val Loss = 0.261137\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:52.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.246285, Val Loss = 0.259335\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:52.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.244087, Val Loss = 0.257680\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:52.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.256173 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:52.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.1, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:52.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:52.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.241576, Val Loss = 0.192714\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:55.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.152817, Val Loss = 0.111438\u001b[0m\n",
            "\u001b[32m2026-01-24 16:11:58.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.127368, Val Loss = 0.095384\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:00.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.117872, Val Loss = 0.092936\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:03.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.113825, Val Loss = 0.092673\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:06.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.106489, Val Loss = 0.091940\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:08.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.103282, Val Loss = 0.091854\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:11.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.101364, Val Loss = 0.091071\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:13.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.100487, Val Loss = 0.090519\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:16.028\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.099753, Val Loss = 0.089927\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:18.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.089353 at iteration 998\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:21.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mModel initialized\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:21.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mModel initialized\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:21.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m107\u001b[0m - \u001b[1mTraining set: 864 samples, Validation set: 97 samples\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:21.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 50 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:21.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:21.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.413701, Val Loss = 1.549334\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:21.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.541621, Val Loss = 0.531528\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:22.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.396524, Val Loss = 0.387526\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:22.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.331624, Val Loss = 0.330053\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:22.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.298465, Val Loss = 0.301412\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:22.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.280620, Val Loss = 0.286104\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:22.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.270448, Val Loss = 0.277416\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:22.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.264182, Val Loss = 0.272085\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:22.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.259955, Val Loss = 0.268461\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:22.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.256824, Val Loss = 0.265758\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:22.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.263584 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:22.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:22.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:22.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.252805, Val Loss = 0.213797\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:23.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.167712, Val Loss = 0.158446\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:23.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.144944, Val Loss = 0.141583\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:24.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.130260, Val Loss = 0.130254\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:24.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.124215, Val Loss = 0.124865\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:25.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.120104, Val Loss = 0.123406\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:25.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.117266, Val Loss = 0.120359\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:26.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.114774, Val Loss = 0.117177\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:27.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.112910, Val Loss = 0.113832\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:27.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.108235, Val Loss = 0.110515\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:28.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.097908 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:29.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 94 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:29.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:29.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.907776, Val Loss = 0.671815\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:29.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.252689, Val Loss = 0.255852\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:30.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.240836, Val Loss = 0.245879\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:30.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.235615, Val Loss = 0.241471\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:30.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.233043, Val Loss = 0.239314\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:30.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.231561, Val Loss = 0.238105\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:30.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.230547, Val Loss = 0.237320\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:30.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.229743, Val Loss = 0.236738\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:30.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.229043, Val Loss = 0.236263\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:30.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.228402, Val Loss = 0.235851\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:30.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.235478 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:30.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:30.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:30.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.226918, Val Loss = 0.183785\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:31.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.144803, Val Loss = 0.137867\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:31.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.120091, Val Loss = 0.113605\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:32.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.108393, Val Loss = 0.106468\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:33.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.104193, Val Loss = 0.104804\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:34.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.102363, Val Loss = 0.103832\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:34.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.101411, Val Loss = 0.103167\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:35.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.100881, Val Loss = 0.102732\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:35.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.100586, Val Loss = 0.102471\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:36.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.100438, Val Loss = 0.102339\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:37.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.085814 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:38.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 136 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:38.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:38.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 3.924451, Val Loss = 2.809121\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:38.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.346728, Val Loss = 0.350960\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:38.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.318022, Val Loss = 0.320222\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:39.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.302837, Val Loss = 0.304393\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:39.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.293488, Val Loss = 0.294986\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:39.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.286802, Val Loss = 0.288497\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:39.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.281437, Val Loss = 0.283439\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:39.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.276811, Val Loss = 0.279167\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:39.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.272663, Val Loss = 0.275392\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:39.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.268870, Val Loss = 0.271970\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:39.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.268860 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:39.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:39.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:39.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.263835, Val Loss = 0.226342\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:40.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.181707, Val Loss = 0.184228\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:41.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.157325, Val Loss = 0.162175\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:41.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.146413, Val Loss = 0.153590\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:42.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.141308, Val Loss = 0.148002\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:43.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.138752, Val Loss = 0.146129\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:44.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.137224, Val Loss = 0.144972\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:45.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.136129, Val Loss = 0.144051\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:45.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.135265, Val Loss = 0.143301\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:46.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.134541, Val Loss = 0.142687\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:47.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.119583 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:49.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 181 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:49.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:49.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.675814, Val Loss = 0.514738\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:49.901\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.269839, Val Loss = 0.278418\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:50.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.262487, Val Loss = 0.270685\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:50.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.258011, Val Loss = 0.266213\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:50.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.254696, Val Loss = 0.263052\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:50.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.251926, Val Loss = 0.260492\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:50.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.249468, Val Loss = 0.258264\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:50.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.247226, Val Loss = 0.256256\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:51.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.245155, Val Loss = 0.254416\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:51.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.243232, Val Loss = 0.252716\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:51.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.251155 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:51.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:51.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:51.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.239443, Val Loss = 0.211300\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:52.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.154780, Val Loss = 0.160275\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:53.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.130908, Val Loss = 0.132871\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:55.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.118300, Val Loss = 0.121099\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:56.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.113415, Val Loss = 0.116540\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:57.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.110947, Val Loss = 0.114053\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:58.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.109530, Val Loss = 0.112562\u001b[0m\n",
            "\u001b[32m2026-01-24 16:12:59.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.108639, Val Loss = 0.111624\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:01.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.105954, Val Loss = 0.107422\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:02.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.104019, Val Loss = 0.106028\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:03.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.089328 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:05.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 224 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:05.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:05.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 2.898814, Val Loss = 1.435655\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:06.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.307214, Val Loss = 0.330800\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:06.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.280931, Val Loss = 0.300769\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:06.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.268818, Val Loss = 0.287012\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:06.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.262121, Val Loss = 0.279575\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:06.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.257635, Val Loss = 0.274760\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:06.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.254146, Val Loss = 0.271143\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:07.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.251178, Val Loss = 0.268148\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:07.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.248533, Val Loss = 0.265529\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:07.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.246121, Val Loss = 0.263175\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:07.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.261046 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:07.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:07.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:07.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.243109, Val Loss = 0.220676\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:08.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.160118, Val Loss = 0.169028\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:10.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.139282, Val Loss = 0.147283\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:11.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.127334, Val Loss = 0.133894\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:12.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.115615, Val Loss = 0.119985\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:13.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.110684, Val Loss = 0.113479\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:15.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.107755, Val Loss = 0.109945\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:16.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.106742, Val Loss = 0.108567\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:17.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.106024, Val Loss = 0.107764\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:19.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.105384, Val Loss = 0.107118\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:20.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.093289 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:23.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 268 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:23.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:23.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.527111, Val Loss = 0.349146\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:23.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.274599, Val Loss = 0.281481\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:23.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.268679, Val Loss = 0.276165\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:23.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.264305, Val Loss = 0.272255\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:24.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.260706, Val Loss = 0.269041\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:24.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.257549, Val Loss = 0.266219\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:24.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.254690, Val Loss = 0.263661\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:24.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.252059, Val Loss = 0.261308\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:25.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.249617, Val Loss = 0.259127\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:25.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.247345, Val Loss = 0.257098\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:25.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.255225 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:25.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:25.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:25.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.244568, Val Loss = 0.226993\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:27.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.160619, Val Loss = 0.172967\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:28.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.137528, Val Loss = 0.147277\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:30.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.127222, Val Loss = 0.135752\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:32.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.114635, Val Loss = 0.119454\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:34.358\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.110327, Val Loss = 0.113684\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:36.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.108180, Val Loss = 0.111221\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:37.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.107058, Val Loss = 0.109948\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:39.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.106168, Val Loss = 0.109103\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:41.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.105353, Val Loss = 0.108384\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:43.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.095384 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:46.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 311 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:46.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:46.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.453251, Val Loss = 0.366743\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:47.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.300002, Val Loss = 0.308962\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:47.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.284649, Val Loss = 0.293410\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:47.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.276572, Val Loss = 0.285631\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:47.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.271161, Val Loss = 0.280625\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:48.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.266865, Val Loss = 0.276726\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:48.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.263140, Val Loss = 0.273362\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:48.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.259780, Val Loss = 0.270330\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:48.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.256699, Val Loss = 0.267547\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:49.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.253855, Val Loss = 0.264979\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:49.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.262625 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:49.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:49.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:49.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.250001, Val Loss = 0.237226\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:51.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.163945, Val Loss = 0.182377\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:53.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.139362, Val Loss = 0.153936\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:56.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.129493, Val Loss = 0.142818\u001b[0m\n",
            "\u001b[32m2026-01-24 16:13:58.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.120154, Val Loss = 0.131815\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:00.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.114796, Val Loss = 0.124566\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:03.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.112984, Val Loss = 0.121771\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:06.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.111519, Val Loss = 0.120053\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:08.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.110456, Val Loss = 0.118964\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:11.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.109501, Val Loss = 0.118051\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:13.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.096453 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:18.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 358 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:18.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:18.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 4.869257, Val Loss = 0.828797\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:18.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.304667, Val Loss = 0.302854\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:18.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.289220, Val Loss = 0.291241\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:19.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.280759, Val Loss = 0.284898\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:19.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.274915, Val Loss = 0.280351\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:19.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.270203, Val Loss = 0.276511\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:20.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.266093, Val Loss = 0.273041\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:20.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.262383, Val Loss = 0.269835\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:20.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.258984, Val Loss = 0.266859\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:20.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.255851, Val Loss = 0.264097\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:21.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.261562 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:21.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:21.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:21.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.250407, Val Loss = 0.236516\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:23.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.168553, Val Loss = 0.193590\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:26.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.147879, Val Loss = 0.169459\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:29.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.136344, Val Loss = 0.156327\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:31.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.127867, Val Loss = 0.146400\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:34.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.124551, Val Loss = 0.142970\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:37.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.120643, Val Loss = 0.137868\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:40.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.119727, Val Loss = 0.136604\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:42.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.117601, Val Loss = 0.133953\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:45.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.114045, Val Loss = 0.129540\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:48.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.099955 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:52.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 401 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:52.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:52.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.480131, Val Loss = 0.326124\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:52.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.294637, Val Loss = 0.301359\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:53.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.285412, Val Loss = 0.293095\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:53.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.279590, Val Loss = 0.287950\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:53.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.275001, Val Loss = 0.283878\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:54.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.270988, Val Loss = 0.280283\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:54.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.267339, Val Loss = 0.276993\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:55.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.263978, Val Loss = 0.273949\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:55.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.260868, Val Loss = 0.271125\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:55.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.257984, Val Loss = 0.268507\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:56.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.266100 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:56.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:56.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:56.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.253495, Val Loss = 0.247629\u001b[0m\n",
            "\u001b[32m2026-01-24 16:14:59.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.173313, Val Loss = 0.192731\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:02.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.147631, Val Loss = 0.167041\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:06.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.132475, Val Loss = 0.147703\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:09.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.125562, Val Loss = 0.139545\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:12.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.122557, Val Loss = 0.136076\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:16.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.117436, Val Loss = 0.129255\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:19.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.114438, Val Loss = 0.124820\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:22.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.112901, Val Loss = 0.122985\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:26.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.108501, Val Loss = 0.116567\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:29.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.096416 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:34.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mCreating network with 445 neurons\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:34.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:34.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.103901, Val Loss = 0.348400\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:35.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.274224, Val Loss = 0.282879\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:35.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.264063, Val Loss = 0.272718\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:35.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.258455, Val Loss = 0.267173\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:36.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.254820, Val Loss = 0.263658\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:36.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.252088, Val Loss = 0.261088\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:36.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.249809, Val Loss = 0.258999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:37.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.247793, Val Loss = 0.257189\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:37.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.245954, Val Loss = 0.255566\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:37.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.244253, Val Loss = 0.254085\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:38.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.252734 at iteration 999\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:38.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m186\u001b[0m - \u001b[1mUsing SSN optimizer with alpha=1e-05, gamma=0.01, th=0.5, lr =1.0\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:38.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m265\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:38.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 0.241115, Val Loss = 0.230112\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:41.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 100: Train Loss = 0.159017, Val Loss = 0.172439\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:45.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 200: Train Loss = 0.133269, Val Loss = 0.145852\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:49.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 300: Train Loss = 0.120250, Val Loss = 0.133426\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:53.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 400: Train Loss = 0.115046, Val Loss = 0.128787\u001b[0m\n",
            "\u001b[32m2026-01-24 16:15:56.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 500: Train Loss = 0.112645, Val Loss = 0.126525\u001b[0m\n",
            "\u001b[32m2026-01-24 16:16:00.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 600: Train Loss = 0.111322, Val Loss = 0.125167\u001b[0m\n",
            "\u001b[32m2026-01-24 16:16:04.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 700: Train Loss = 0.109392, Val Loss = 0.121526\u001b[0m\n",
            "\u001b[32m2026-01-24 16:16:08.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 800: Train Loss = 0.104534, Val Loss = 0.114527\u001b[0m\n",
            "\u001b[32m2026-01-24 16:16:12.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 900: Train Loss = 0.103069, Val Loss = 0.112783\u001b[0m\n",
            "\u001b[32m2026-01-24 16:16:16.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscr.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m340\u001b[0m - \u001b[1mBest validation loss: 0.094952 at iteration 999\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from scr.PDPA import PDPA\n",
        "\n",
        "pdpa_list_l2 = []\n",
        "best_iteration_l2 = []\n",
        "best_neurons_l2 = []\n",
        "for gamma in gammas:\n",
        "    pdpa = PDPA(\n",
        "        data=data_dict,\n",
        "        alpha=alpha,\n",
        "        gamma=gamma,\n",
        "        power=power,\n",
        "        activation=torch.relu,\n",
        "        loss_weights=loss_weight_l2,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "    best_iteration, best_neurons = pdpa.retrain(\n",
        "    num_iterations = num_iterations, \n",
        "    num_insertion= num_insertions, \n",
        "    threshold = pruning_threshold,\n",
        "    verbose=False\n",
        "    )\n",
        "\n",
        "    pdpa_list_l2.append(pdpa)\n",
        "    best_iteration_l2.append(best_iteration)\n",
        "    best_neurons_l2.append(best_neurons)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "747843f1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[184, 95, 275, 444, 94]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_neurons_l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8cb5bb44",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[3, 1, 5, 9, 1]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_iteration_l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a37177b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# pdpa_list_h1 = []\n",
        "# best_iteration_h1 = []\n",
        "\n",
        "# for gamma in gammas:\n",
        "#     pdpa = PDPA(\n",
        "#         data=data_dict,\n",
        "#         alpha=alpha,\n",
        "#         gamma=gamma,\n",
        "#         power=power,\n",
        "#         activation=torch.relu,\n",
        "#         loss_weights=loss_weight_h1,\n",
        "#         verbose=False,\n",
        "#     )\n",
        "\n",
        "#     best_iteration = pdpa.retrain(\n",
        "#     num_iterations = num_iterations, \n",
        "#     num_insertion= num_insertions, \n",
        "#     threshold = pruning_threshold,\n",
        "#     verbose=False\n",
        "#     )\n",
        "\n",
        "#     pdpa_list_h1.append(pdpa)\n",
        "#     best_iteration_h1.append(best_iteration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9f3d4d7c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "model_l2 = {\n",
        "    \"gammas\": gammas,\n",
        "    \"pdpa_list_l2\": pdpa_list_l2,\n",
        "    \"alpha\": alpha,\n",
        "    \"power\": power,\n",
        "    \"num_iteration\": num_iterations,\n",
        "    \"num_insertion\": num_insertions,\n",
        "    \"pruning_threshold\": pruning_threshold,\n",
        "    \"best_iteration_l2\": best_iteration_l2,\n",
        "    \"best_neurons_l2\": best_neurons_l2\n",
        "}\n",
        "\n",
        "# model_h1 = {\n",
        "#     \"gammas\": gammas,\n",
        "#     \"pdpa_list_h1\": pdpa_list_h1,\n",
        "#     \"alpha\": alpha,\n",
        "#     \"power\": power,\n",
        "#     \"num_iteration\": num_insertions,\n",
        "#     \"num_insertion\": num_insertions,\n",
        "#     \"pruning_threshold\": pruning_threshold,\n",
        "#     \"best_iteration_h1\": best_iteration_h1\n",
        "# }\n",
        "\n",
        "\n",
        "with open(\"models/experiment_4/pdpa_gausscos_model_l2_10.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model_l2, f)\n",
        "\n",
        "# with open(\"models/experiment_2/pdpa_gauscos_model_h1_0.pkl\", \"wb\") as f:\n",
        "#     pickle.dump(model_h1, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8591213b",
      "metadata": {},
      "source": [
        "In each iteration we tried to add 5 neurons. The following plots indicates the relation of loss & number of neurons. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cf79243f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<Figure size 1000x600 with 1 Axes>,\n",
              " <Axes: title={'center': 'PDPA best loss vs best neuron count (best-so-far by iteration)'}, xlabel='Best iteration neuron count', ylabel='Best iteration validation loss'>)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from scr.metric import plot_pdpa_best_loss_vs_neurons_by_iteration\n",
        "\n",
        "# Plot raw (iteration-by-iteration) (neurons[t], val_loss[t]) pairs; exclude NaN/Inf points\n",
        "plot_pdpa_best_loss_vs_neurons_by_iteration(\n",
        "    model_l2,\n",
        "    pdpa_key=\"pdpa_list_l2\",\n",
        "    best_so_far=True,\n",
        "    marker=\"o\",\n",
        ")\n",
        "# from scr.metric import plot_pdpa_best_neurons_by_iteration\n",
        "\n",
        "# plot_pdpa_best_neurons_by_iteration(model_l2, pdpa_key=\"pdpa_list_l2\")\n",
        "# plot_pdpa_val_loss_histories_by_gamma(model_h1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
