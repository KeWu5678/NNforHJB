{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeebd44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to Python path so model.py can find ssn and net modules\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from src.model import model\n",
    "from src.model_outerweights import model_outerweights\n",
    "from src.greedy_insertion import _sample_uniform_sphere_points\n",
    "from src.training_logger import retrain\n",
    "\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfa9fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "path = '../data_result/raw_data/VDP_beta_0.1_grid_combined.npy'# Initialize the weights\n",
    "data = np.load(path)\n",
    "logger.info(f\"Loaded data with shape: {data.shape}, dtype: {data.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4099fadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameter\n",
    "power = 2.1\n",
    "M = 50 # number greedy insertion selected\n",
    "num_iterations = 10\n",
    "loss_weights = (1.0, 1.0)\n",
    "pruning_threshold = 1e-15\n",
    "\n",
    "gamma = 5.0\n",
    "alpha = 1e-5\n",
    "lr_adam = 1e-5\n",
    "regularization = (gamma, alpha) \n",
    "th = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4273cea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model \n",
    "model_1 = model(torch.relu, power, regularization, optimizer='Adam', loss_weights = loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3470321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "data_train, data_valid = model_1._prepare_data(0.8, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e2c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the initializing weights and bias\n",
    "init_weights, init_bias = _sample_uniform_sphere_points(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0db354",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = model_outerweights(torch.relu, power, regularization, optimizer='SSN_TR', loss_weights = loss_weights, th = th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256a18d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result, weight_raw, bias_raw, outerweight_raw = model_1.train(\n",
    "    data_train=data_train,\n",
    "    data_valid=data_valid,\n",
    "    inner_weights=init_weights, \n",
    "    inner_bias=init_bias,\n",
    "    iterations=1000,\n",
    "    display_every=200,\n",
    ")\n",
    "logger.info(\"Initialization done\"); logger.info(f\"Initial weights shape: {weight_raw.shape}, bias shape: {bias_raw.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b80147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with improved logging\n",
    "VDP_logger_H1_nc, weight_raw, bias_raw, outerweight_raw = retrain(\n",
    "    data_train, data_valid, \n",
    "    model_1, model_2, model_result, weight_raw, bias_raw, outerweight_raw,\n",
    "    num_iterations, M, alpha, pruning_threshold, power, gamma\n",
    ")\n",
    "\n",
    "logger.info(\"Training completed with improved logging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cb5add",
   "metadata": {},
   "source": [
    "The comparable model is about 126 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adb6393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PLOT: Weight space visualization in polar coordinates\n",
    "# Shows the distribution of weights in 2D space for the BEST model (lowest validation loss)\n",
    "# =============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Extract weights from the current training run\n",
    "weights_run = VDP_logger_H1_nc.history['weights']\n",
    "biases_run = VDP_logger_H1_nc.history['biases']\n",
    "neurons_run = VDP_logger_H1_nc.history['neuron_count']\n",
    "\n",
    "print(f\"Training run: {len(weights_run)} iterations, max neurons: {max(neurons_run)}\")\n",
    "\n",
    "# Use the BEST model (lowest validation loss) instead of the iteration with most neurons\n",
    "print(\"Using BEST model (lowest validation loss)\")\n",
    "weights_optimal = VDP_logger_H1_nc.history['best_weights']\n",
    "b_optimal = VDP_logger_H1_nc.history['best_biases'].reshape(1, -1)   # (1, n)\n",
    "best_loss = VDP_logger_H1_nc.history['best_test_loss']\n",
    "print(f\"Best validation loss: {best_loss:.6f}\")\n",
    "\n",
    "a_optimal = weights_optimal.T                         # (2, n)\n",
    "Z = a_optimal / (1 + b_optimal) \n",
    "\n",
    "# Create polar coordinate visualization\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "# Compute angles and radii in weight space (2D)\n",
    "angles = np.arctan2(a_optimal[1], a_optimal[0])\n",
    "r_sphere = np.sqrt(np.sum(a_optimal**2, axis=0) + (b_optimal.flatten())**2)\n",
    "\n",
    "# Plot in polar coordinates\n",
    "radius = np.ones_like(angles)\n",
    "ax.scatter(angles, radius, c=b_optimal.flatten(), cmap='coolwarm', alpha=0.85, s=60)\n",
    "ax.set_title(f'Weight Space - BEST Model\\nNeurons: {weights_optimal.shape[0]}', fontsize=14)\n",
    "ax.grid(True, alpha=0.5)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('../data_result/plot/weights_polar_analysis_best.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"Polar coordinate analysis saved to ../data_result/plot/weights_polar_analysis_best.png\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b0f71",
   "metadata": {},
   "source": [
    "## Test with the L1 Penalty ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bceb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameter\n",
    "power = 2.1\n",
    "M = 50 # number greedy insertion selected\n",
    "num_iterations = 10\n",
    "loss_weights = (1.0, 1.0)\n",
    "pruning_threshold = 1e-13\n",
    "\n",
    "gamma = 1e-10\n",
    "alpha = 1e-5\n",
    "regularization = (gamma, alpha) \n",
    "th = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b7549f",
   "metadata": {},
   "source": [
    "The comparable model is about: 207 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac139d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model \n",
    "model_1 = model(torch.relu, power, regularization, optimizer='Adam', loss_weights = loss_weights)\n",
    "model_2 = model_outerweights(torch.relu, power, regularization, optimizer='SSN_TR', loss_weights = loss_weights, th = th)\n",
    "\n",
    "# Prepare data\n",
    "data_train, data_valid = model_1._prepare_data(0.8, data)\n",
    "\n",
    "# Set up the initializing weights and bias\n",
    "init_weights = np.random.randn(M, 2) * 0.1\n",
    "init_bias = np.random.randn(M)\n",
    "\n",
    "model_result, weight_raw, bias_raw, outerweight_raw = model_1.train(\n",
    "    data_train=data_train,\n",
    "    data_valid=data_valid,\n",
    "    inner_weights=init_weights, \n",
    "    inner_bias=init_bias,\n",
    "    iterations=1000,\n",
    "    display_every=200,\n",
    ")\n",
    "logger.info(\"Initialization done\"); logger.info(f\"Initial weights shape: {weight_raw.shape}, bias shape: {bias_raw.shape}\")\n",
    "\n",
    "# Training with improved logging\n",
    "VDP_logger_H1_lasso, weight_raw_1, bias_raw_1, outerweight_raw_1 = retrain(\n",
    "    data_train, data_valid, model_1, model_2, model_result, weight_raw, bias_raw, outerweight_raw,\n",
    "    num_iterations, M, alpha, pruning_threshold, power, gamma\n",
    ")\n",
    "\n",
    "logger.info(\"Training completed with improved logging\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b6c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PLOT: Weight space visualization in polar coordinates\n",
    "# Shows the distribution of weights in 2D space for the BEST model (lowest validation loss)\n",
    "# =============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Extract weights from the current training run\n",
    "weights_run = VDP_logger_H1_lasso.history['weights']\n",
    "biases_run = VDP_logger_H1_lasso.history['biases']\n",
    "neurons_run = VDP_logger_H1_lasso.history['neuron_count']\n",
    "\n",
    "print(f\"Training run: {len(weights_run)} iterations, max neurons: {max(neurons_run)}\")\n",
    "\n",
    "# Use the BEST model (lowest validation loss) instead of the iteration with most neurons\n",
    "if 'best_weights' in VDP_logger_H1_lasso.history:\n",
    "    print(\"Using BEST model (lowest validation loss)\")\n",
    "weights_optimal = VDP_logger_H1_lasso.history['best_weights']\n",
    "b_optimal = VDP_logger_H1_lasso.history['best_biases'].reshape(1, -1)   # (1, n)\n",
    "best_loss = VDP_logger_H1_lasso.history['best_test_loss']\n",
    "print(f\"Best validation loss: {best_loss:.6f}\")\n",
    "\n",
    "a_optimal = weights_optimal.T                         # (2, n)\n",
    "Z = a_optimal / (1 + b_optimal) \n",
    "\n",
    "# Create polar coordinate visualization\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "# Compute angles and radii in weight space (2D)\n",
    "angles = np.arctan2(a_optimal[1], a_optimal[0])\n",
    "r_sphere = np.sqrt(np.sum(a_optimal**2, axis=0) + (b_optimal.flatten())**2)\n",
    "\n",
    "# Plot in polar coordinates\n",
    "radius = np.ones_like(angles)\n",
    "ax.scatter(angles, radius, c=b_optimal.flatten(), cmap='coolwarm', alpha=0.85, s=60)\n",
    "ax.set_title(f'Weight Space - BEST Model (L1 Penalty)\\nNeurons: {weights_optimal.shape[0]}', fontsize=14)\n",
    "ax.grid(True, alpha=0.5)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('../data_result/plot/weights_polar_analysis_best_l1.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"Polar coordinate analysis saved to ../data_result/plot/weights_polar_analysis_best_l1.png\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Optional: Show weight evolution across iterations\n",
    "if len(weights_run) > 1:\n",
    "    print(f\"\\n=== Weight Evolution ===\")\n",
    "    print(\"Neuron counts across iterations:\")\n",
    "    for i, count in enumerate(neurons_run):\n",
    "        print(f\"Iteration {i}: {count} neurons\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
