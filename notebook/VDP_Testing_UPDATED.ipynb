{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeebd44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to Python path so model.py can find ssn and net modules\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from src.model import model\n",
    "from src.model_outerweights import model_outerweights\n",
    "from src.greedy_insertion import _sample_uniform_sphere_points\n",
    "from src.training_logger import run_training_with_logging\n",
    "\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dfa9fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-27 05:52:44.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mLoaded data with shape: (1800,), dtype: [('x', '<f8', (2,)), ('dv', '<f8', (2,)), ('v', '<f8')]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "path = '../data_result/raw_data/VDP_beta_0.1_grid_combined.npy'# Initialize the weights\n",
    "data = np.load(path)\n",
    "logger.info(f\"Loaded data with shape: {data.shape}, dtype: {data.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4099fadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameter\n",
    "power = 2.1\n",
    "M = 10 # number greedy insertion selected\n",
    "num_iterations = 30\n",
    "loss_weights = (1.0, 1.0)\n",
    "pruning_threshold = 1e-15\n",
    "\n",
    "gamma = 5.0\n",
    "alpha = 1e-1\n",
    "regularization = (gamma, alpha) \n",
    "th = 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4273cea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-27 05:52:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_configure_logger\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mVDPModel initialized\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_configure_logger\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mVDPModel (outer weights) initialized\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model \n",
    "model_1 = model(data, torch.relu, power, regularization, optimizer='Adam', loss_weights = loss_weights)\n",
    "model_2 = model_outerweights(data, torch.relu, power, regularization, optimizer='SSN_TR', loss_weights = loss_weights, th = th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9e2c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the initializing weights and bias\n",
    "init_weights, init_bias = _sample_uniform_sphere_points(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "256a18d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-27 05:52:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 10 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=1000, batch_size=1620, display_every=200\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 30.764525\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 200: Train Loss = 2.444243, Val Loss = 3.180010\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 400: Train Loss = 1.949529, Val Loss = 2.258545\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 600: Train Loss = 1.778414, Val Loss = 1.916494\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 800: Train Loss = 1.715715, Val Loss = 1.826174\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mInitialization done\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mInitial weights shape: (10, 2), bias shape: (10,)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_result, weight_raw, bias_raw, outerweight_raw = model_1.train(\n",
    "    iterations=1000,\n",
    "    display_every=200,\n",
    "    inner_weights=init_weights, inner_bias=init_bias,\n",
    ")\n",
    "logger.info(\"Initialization done\"); logger.info(f\"Initial weights shape: {weight_raw.shape}, bias shape: {bias_raw.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50b80147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-27 05:52:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 0 - weights shape: (10, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.652817, Val Loss = 1.765804\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.652817, Val Loss = 1.765804\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.652817, Val Loss = 1.765804\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.652817, Val Loss = 1.765804\u001b[0m\n",
      "\u001b[32m2025-08-27 05:52:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.652817, Val Loss = 1.765804\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (10, 2), biases: (10,), outer_weights: (1, 10)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (10, 2), biases: (10,), outer_weights: (1, 10)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 20 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 26.628509\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.601931, Val Loss = 1.793667\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.563075, Val Loss = 1.781957\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.534516, Val Loss = 1.766643\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.450300, Val Loss = 1.540569\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.425583, Val Loss = 1.448468\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.408063, Val Loss = 1.428045\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.355587, Val Loss = 1.314167\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.349479, Val Loss = 1.321153\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.346108, Val Loss = 1.315596\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.394736, Val Loss = 1.366992\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.344594, Val Loss = 1.313582\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.339442, Val Loss = 1.310414\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.336953, Val Loss = 1.309486\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.317758, Val Loss = 1.265668\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.311432, Val Loss = 1.242406\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.311185, Val Loss = 1.244116\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.308292, Val Loss = 1.238274\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.316942, Val Loss = 1.259523\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.306583, Val Loss = 1.236039\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 0 with validation loss: 1.236039\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 0: 20 neurons, test_loss=1.236039\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 1 - weights shape: (20, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.304557, Val Loss = 1.232745\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.304557, Val Loss = 1.232745\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.304557, Val Loss = 1.232745\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.304557, Val Loss = 1.232745\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.304557, Val Loss = 1.232745\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (20, 2), biases: (20,), outer_weights: (1, 20)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (20, 2), biases: (20,), outer_weights: (1, 20)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 30 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 6.620294\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.304751, Val Loss = 1.234497\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.303362, Val Loss = 1.233027\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.303178, Val Loss = 1.230889\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.307114, Val Loss = 1.241529\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.302081, Val Loss = 1.230915\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.423612, Val Loss = 1.346255\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.300753, Val Loss = 1.227314\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.301116, Val Loss = 1.223087\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.304578, Val Loss = 1.242265\u001b[0m\n",
      "\u001b[32m2025-08-27 05:53:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.299732, Val Loss = 1.221099\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.315531, Val Loss = 1.229526\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.298803, Val Loss = 1.219489\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.298678, Val Loss = 1.221006\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.298711, Val Loss = 1.219757\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.298867, Val Loss = 1.218554\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.299072, Val Loss = 1.219865\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.298865, Val Loss = 1.218853\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.298779, Val Loss = 1.218875\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.315086, Val Loss = 1.231433\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 1 with validation loss: 1.231433\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 1: 30 neurons, test_loss=1.231433\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 2 - weights shape: (30, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.298173, Val Loss = 1.218685\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.298173, Val Loss = 1.218685\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.298173, Val Loss = 1.218685\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.298173, Val Loss = 1.218685\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.298173, Val Loss = 1.218685\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 6\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (30, 2), biases: (30,), outer_weights: (1, 30)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 6 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (24, 2), biases: (24,), outer_weights: (1, 24)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 33 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 4.882013\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.296864, Val Loss = 1.217525\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.295898, Val Loss = 1.216083\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.300468, Val Loss = 1.227419\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.296847, Val Loss = 1.222460\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.295440, Val Loss = 1.216409\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.295471, Val Loss = 1.215273\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.389902, Val Loss = 1.300739\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.297033, Val Loss = 1.220168\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.295529, Val Loss = 1.215560\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.297520, Val Loss = 1.220841\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.295043, Val Loss = 1.215545\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.295087, Val Loss = 1.215156\u001b[0m\n",
      "\u001b[32m2025-08-27 05:54:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.295192, Val Loss = 1.214807\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.295196, Val Loss = 1.215322\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.296185, Val Loss = 1.215826\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.294969, Val Loss = 1.214856\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.295060, Val Loss = 1.215897\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.294708, Val Loss = 1.214936\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.297501, Val Loss = 1.238604\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 2: 33 neurons, test_loss=1.238604\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 3 - weights shape: (33, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.294598, Val Loss = 1.214207\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.294598, Val Loss = 1.214207\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.294598, Val Loss = 1.214207\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.294598, Val Loss = 1.214207\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.294598, Val Loss = 1.214207\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 13\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (33, 2), biases: (33,), outer_weights: (1, 33)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 13 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (20, 2), biases: (20,), outer_weights: (1, 20)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 30 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 4.512750\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.294608, Val Loss = 1.215225\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.293719, Val Loss = 1.214593\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.294233, Val Loss = 1.217831\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.294471, Val Loss = 1.215079\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.293718, Val Loss = 1.213116\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.419277, Val Loss = 1.348931\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.294026, Val Loss = 1.213172\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.293573, Val Loss = 1.213534\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.294777, Val Loss = 1.214395\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.293828, Val Loss = 1.213856\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.294298, Val Loss = 1.214698\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.294082, Val Loss = 1.214037\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.293363, Val Loss = 1.213801\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.294073, Val Loss = 1.214083\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.294878, Val Loss = 1.215286\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.296653, Val Loss = 1.227096\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.300313, Val Loss = 1.225571\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.294151, Val Loss = 1.214249\u001b[0m\n",
      "\u001b[32m2025-08-27 05:55:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.293797, Val Loss = 1.213584\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 3 with validation loss: 1.213584\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 3: 30 neurons, test_loss=1.213584\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 4 - weights shape: (30, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.293380, Val Loss = 1.213594\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.293380, Val Loss = 1.213594\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.293380, Val Loss = 1.213594\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.293380, Val Loss = 1.213594\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.293380, Val Loss = 1.213594\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 9\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (30, 2), biases: (30,), outer_weights: (1, 30)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 9 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 31 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 4.378776\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.293105, Val Loss = 1.214394\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.292487, Val Loss = 1.213656\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.293176, Val Loss = 1.220236\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.292521, Val Loss = 1.212138\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.292802, Val Loss = 1.212727\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.292991, Val Loss = 1.215114\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.293911, Val Loss = 1.212435\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.292953, Val Loss = 1.212977\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.293358, Val Loss = 1.213795\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.293503, Val Loss = 1.211848\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.451626, Val Loss = 1.338041\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.293255, Val Loss = 1.213024\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.292844, Val Loss = 1.213356\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.293059, Val Loss = 1.213166\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.294219, Val Loss = 1.213733\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.292946, Val Loss = 1.213178\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.324664, Val Loss = 1.276093\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.294441, Val Loss = 1.213230\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.293962, Val Loss = 1.213639\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 4: 31 neurons, test_loss=1.213639\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 5 - weights shape: (31, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.293507, Val Loss = 1.213803\u001b[0m\n",
      "\u001b[32m2025-08-27 05:56:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.293507, Val Loss = 1.213803\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.293507, Val Loss = 1.213803\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.293507, Val Loss = 1.213803\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.293507, Val Loss = 1.213803\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (31, 2), biases: (31,), outer_weights: (1, 31)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 30 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 4.377794\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.292929, Val Loss = 1.213808\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.291861, Val Loss = 1.212566\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.292138, Val Loss = 1.210632\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.294907, Val Loss = 1.214260\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.296350, Val Loss = 1.211310\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.291814, Val Loss = 1.211757\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.292691, Val Loss = 1.211891\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.314034, Val Loss = 1.212381\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.292370, Val Loss = 1.213294\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.292332, Val Loss = 1.212489\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.292853, Val Loss = 1.212730\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.293035, Val Loss = 1.212927\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.292597, Val Loss = 1.212084\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.292528, Val Loss = 1.211865\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.296492, Val Loss = 1.218301\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.293249, Val Loss = 1.212533\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.293019, Val Loss = 1.212561\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.292953, Val Loss = 1.213188\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.292853, Val Loss = 1.212834\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 5 with validation loss: 1.212834\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 5: 30 neurons, test_loss=1.212834\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 6 - weights shape: (30, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.292497, Val Loss = 1.212614\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.292497, Val Loss = 1.212614\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.292497, Val Loss = 1.212614\u001b[0m\n",
      "\u001b[32m2025-08-27 05:57:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.292497, Val Loss = 1.212614\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.292497, Val Loss = 1.212614\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (30, 2), biases: (30,), outer_weights: (1, 30)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (20, 2), biases: (20,), outer_weights: (1, 20)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 29 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 4.504352\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.292091, Val Loss = 1.212301\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.291481, Val Loss = 1.213186\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.296442, Val Loss = 1.221790\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.291515, Val Loss = 1.209959\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.291442, Val Loss = 1.210392\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.291495, Val Loss = 1.210703\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.292141, Val Loss = 1.210253\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.320273, Val Loss = 1.302674\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.294110, Val Loss = 1.229130\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.292694, Val Loss = 1.212688\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.332838, Val Loss = 1.226479\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.292133, Val Loss = 1.212691\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.292085, Val Loss = 1.212424\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.301078, Val Loss = 1.212092\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.377025, Val Loss = 1.435608\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.291949, Val Loss = 1.212420\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.292114, Val Loss = 1.212366\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.291986, Val Loss = 1.212057\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.292911, Val Loss = 1.212797\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 6 with validation loss: 1.212797\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 6: 29 neurons, test_loss=1.212797\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 7 - weights shape: (29, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.292266, Val Loss = 1.212356\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.292266, Val Loss = 1.212356\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.292266, Val Loss = 1.212356\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.292266, Val Loss = 1.212356\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.292266, Val Loss = 1.212356\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 9\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (29, 2), biases: (29,), outer_weights: (1, 29)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 9 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (20, 2), biases: (20,), outer_weights: (1, 20)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 30 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 4.340204\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.291686, Val Loss = 1.211672\u001b[0m\n",
      "\u001b[32m2025-08-27 05:58:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.291018, Val Loss = 1.211492\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.293102, Val Loss = 1.209377\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.291138, Val Loss = 1.210176\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.291071, Val Loss = 1.210124\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.291351, Val Loss = 1.209882\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.291277, Val Loss = 1.210597\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.291939, Val Loss = 1.213537\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.292658, Val Loss = 1.212078\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.295359, Val Loss = 1.210916\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.294778, Val Loss = 1.215511\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.291653, Val Loss = 1.211960\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.292152, Val Loss = 1.212074\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.292366, Val Loss = 1.212226\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.292500, Val Loss = 1.211428\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.292713, Val Loss = 1.212251\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.291731, Val Loss = 1.212269\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.291910, Val Loss = 1.212396\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.292024, Val Loss = 1.212550\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 7 with validation loss: 1.212550\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 7: 30 neurons, test_loss=1.212550\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 8 - weights shape: (30, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.292656, Val Loss = 1.213002\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.292656, Val Loss = 1.213002\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.292656, Val Loss = 1.213002\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.292656, Val Loss = 1.213002\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.292656, Val Loss = 1.213002\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 9\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (30, 2), biases: (30,), outer_weights: (1, 30)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 9 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 31 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 4.335028\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.291314, Val Loss = 1.211999\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.290919, Val Loss = 1.211093\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.291124, Val Loss = 1.208910\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.297952, Val Loss = 1.216114\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.290789, Val Loss = 1.210170\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.291277, Val Loss = 1.210034\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.291036, Val Loss = 1.210464\u001b[0m\n",
      "\u001b[32m2025-08-27 05:59:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.293141, Val Loss = 1.212183\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.292397, Val Loss = 1.212052\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.438404, Val Loss = 1.531485\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.291387, Val Loss = 1.211360\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.291421, Val Loss = 1.212206\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.297343, Val Loss = 1.219339\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.291237, Val Loss = 1.211027\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.293026, Val Loss = 1.214227\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.292059, Val Loss = 1.212065\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.291612, Val Loss = 1.212366\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.309808, Val Loss = 1.323026\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.622733, Val Loss = 1.694629\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 8: 31 neurons, test_loss=1.694629\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 9 - weights shape: (31, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.410378, Val Loss = 1.335341\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.410378, Val Loss = 1.335341\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.410378, Val Loss = 1.335341\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.410378, Val Loss = 1.335341\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.410378, Val Loss = 1.335341\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (31, 2), biases: (31,), outer_weights: (1, 31)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 30 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 4.340291\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.291205, Val Loss = 1.211680\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.290520, Val Loss = 1.211397\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.291189, Val Loss = 1.209476\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.295966, Val Loss = 1.220029\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.294628, Val Loss = 1.208521\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.292409, Val Loss = 1.212592\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.290767, Val Loss = 1.210779\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.290652, Val Loss = 1.210998\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.362308, Val Loss = 1.350114\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.291444, Val Loss = 1.211431\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.293927, Val Loss = 1.212627\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.291958, Val Loss = 1.211795\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.291139, Val Loss = 1.211576\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.322663, Val Loss = 1.215476\u001b[0m\n",
      "\u001b[32m2025-08-27 06:00:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.294987, Val Loss = 1.216084\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.291418, Val Loss = 1.211669\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.291733, Val Loss = 1.211974\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.291388, Val Loss = 1.210972\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.444668, Val Loss = 1.687769\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 9: 30 neurons, test_loss=1.687769\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 10 - weights shape: (30, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.340289, Val Loss = 1.307271\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.340289, Val Loss = 1.307271\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.340289, Val Loss = 1.307271\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.340289, Val Loss = 1.307271\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.340289, Val Loss = 1.307271\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (30, 2), biases: (30,), outer_weights: (1, 30)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (20, 2), biases: (20,), outer_weights: (1, 20)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 30 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 4.358592\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.291513, Val Loss = 1.212389\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.290682, Val Loss = 1.210779\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.290823, Val Loss = 1.210689\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.296758, Val Loss = 1.228641\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.310618, Val Loss = 1.261878\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.291501, Val Loss = 1.221119\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.291346, Val Loss = 1.211128\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.291617, Val Loss = 1.211049\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.347839, Val Loss = 1.246583\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.291446, Val Loss = 1.211841\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.291088, Val Loss = 1.211230\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.291567, Val Loss = 1.212742\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.291364, Val Loss = 1.211431\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.291698, Val Loss = 1.211990\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.291610, Val Loss = 1.211852\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.291413, Val Loss = 1.211694\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.291936, Val Loss = 1.211279\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.291568, Val Loss = 1.212006\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.291431, Val Loss = 1.212174\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 10 with validation loss: 1.212174\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 10: 30 neurons, test_loss=1.212174\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 11 - weights shape: (30, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:01:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.291577, Val Loss = 1.212085\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.291577, Val Loss = 1.212085\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.291577, Val Loss = 1.212085\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.291577, Val Loss = 1.212085\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.291577, Val Loss = 1.212085\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 9\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (30, 2), biases: (30,), outer_weights: (1, 30)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 9 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 31 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 4.390890\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290783, Val Loss = 1.211531\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.290112, Val Loss = 1.210199\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.290382, Val Loss = 1.208404\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.294518, Val Loss = 1.209832\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.306466, Val Loss = 1.210272\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.291534, Val Loss = 1.211231\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.290946, Val Loss = 1.210637\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.290996, Val Loss = 1.211160\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.291184, Val Loss = 1.211247\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.356009, Val Loss = 1.259817\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.290891, Val Loss = 1.210756\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.293670, Val Loss = 1.211282\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.291287, Val Loss = 1.211519\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.290893, Val Loss = 1.210992\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.291844, Val Loss = 1.211798\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.291912, Val Loss = 1.211579\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.296012, Val Loss = 1.217418\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.291766, Val Loss = 1.211505\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.291732, Val Loss = 1.211336\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 11 with validation loss: 1.211336\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 11: 31 neurons, test_loss=1.211336\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 12 - weights shape: (31, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.292104, Val Loss = 1.212004\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.292104, Val Loss = 1.212004\u001b[0m\n",
      "\u001b[32m2025-08-27 06:02:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.292104, Val Loss = 1.212004\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.292104, Val Loss = 1.212004\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.292104, Val Loss = 1.212004\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (31, 2), biases: (31,), outer_weights: (1, 31)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 30 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 4.139420\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290933, Val Loss = 1.211492\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.290045, Val Loss = 1.210462\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.290261, Val Loss = 1.209655\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.290287, Val Loss = 1.209777\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.290532, Val Loss = 1.210122\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.290743, Val Loss = 1.209060\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.292394, Val Loss = 1.219043\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.290976, Val Loss = 1.211537\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.291865, Val Loss = 1.210337\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.290662, Val Loss = 1.210916\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.290659, Val Loss = 1.210910\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.291060, Val Loss = 1.210661\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.290823, Val Loss = 1.210765\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.290559, Val Loss = 1.210704\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.291778, Val Loss = 1.211965\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.292099, Val Loss = 1.210056\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.291490, Val Loss = 1.211516\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.291530, Val Loss = 1.211781\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.291458, Val Loss = 1.211499\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 12: 30 neurons, test_loss=1.211499\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 13 - weights shape: (30, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.291902, Val Loss = 1.211614\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.291902, Val Loss = 1.211614\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.291902, Val Loss = 1.211614\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.291902, Val Loss = 1.211614\u001b[0m\n",
      "\u001b[32m2025-08-27 06:03:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.291902, Val Loss = 1.211614\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (30, 2), biases: (30,), outer_weights: (1, 30)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (20, 2), biases: (20,), outer_weights: (1, 20)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 30 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 3.929232\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290995, Val Loss = 1.213413\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.290043, Val Loss = 1.210590\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.293489, Val Loss = 1.224781\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.290448, Val Loss = 1.208842\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.318164, Val Loss = 1.226016\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.290592, Val Loss = 1.210333\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.290816, Val Loss = 1.211154\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.290856, Val Loss = 1.210917\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.291061, Val Loss = 1.211258\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.474634, Val Loss = 1.430630\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.291221, Val Loss = 1.211364\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.290736, Val Loss = 1.210951\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.313039, Val Loss = 1.213071\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.294941, Val Loss = 1.219226\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.340484, Val Loss = 1.285914\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.291383, Val Loss = 1.211574\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.320235, Val Loss = 1.222070\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.297003, Val Loss = 1.235313\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.291785, Val Loss = 1.211898\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 13: 30 neurons, test_loss=1.211898\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 14 - weights shape: (30, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.291687, Val Loss = 1.211932\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.291687, Val Loss = 1.211932\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.291687, Val Loss = 1.211932\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.291687, Val Loss = 1.211932\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.291687, Val Loss = 1.211932\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 9\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (30, 2), biases: (30,), outer_weights: (1, 30)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 9 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 31 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 4.117085\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290559, Val Loss = 1.211085\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.290052, Val Loss = 1.209960\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.294885, Val Loss = 1.211297\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.290763, Val Loss = 1.208676\u001b[0m\n",
      "\u001b[32m2025-08-27 06:04:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.291033, Val Loss = 1.209115\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.290613, Val Loss = 1.210277\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.290699, Val Loss = 1.210124\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.358018, Val Loss = 1.372942\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.303627, Val Loss = 1.323059\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.291041, Val Loss = 1.210420\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.293689, Val Loss = 1.248385\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.291016, Val Loss = 1.211327\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.359430, Val Loss = 1.297350\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.332169, Val Loss = 1.342279\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.567000, Val Loss = 1.758093\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.291957, Val Loss = 1.212685\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.291376, Val Loss = 1.211328\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.291569, Val Loss = 1.211651\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.291138, Val Loss = 1.210900\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 14 with validation loss: 1.210900\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 14: 31 neurons, test_loss=1.210900\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 15 - weights shape: (31, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.291200, Val Loss = 1.211232\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.291200, Val Loss = 1.211232\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.291200, Val Loss = 1.211232\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.291200, Val Loss = 1.211232\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.291200, Val Loss = 1.211232\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (31, 2), biases: (31,), outer_weights: (1, 31)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 31 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 4.018404\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290473, Val Loss = 1.210913\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.289784, Val Loss = 1.210342\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.290389, Val Loss = 1.209050\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.344888, Val Loss = 1.379985\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.290261, Val Loss = 1.209728\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.290220, Val Loss = 1.209017\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.290352, Val Loss = 1.210348\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.306170, Val Loss = 1.229490\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.367309, Val Loss = 1.438942\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.290768, Val Loss = 1.211365\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.295151, Val Loss = 1.212775\u001b[0m\n",
      "\u001b[32m2025-08-27 06:05:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.290751, Val Loss = 1.210797\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.291774, Val Loss = 1.213433\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.291348, Val Loss = 1.211491\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.291212, Val Loss = 1.210857\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.291539, Val Loss = 1.211927\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.292271, Val Loss = 1.211866\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.291676, Val Loss = 1.211356\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.291139, Val Loss = 1.210907\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 15: 31 neurons, test_loss=1.210907\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 16 - weights shape: (31, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.290843, Val Loss = 1.210887\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290843, Val Loss = 1.210887\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.290843, Val Loss = 1.210887\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.290843, Val Loss = 1.210887\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.290843, Val Loss = 1.210887\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (31, 2), biases: (31,), outer_weights: (1, 31)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 30 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 4.009395\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290518, Val Loss = 1.210664\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.289727, Val Loss = 1.210727\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.289942, Val Loss = 1.208973\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.290361, Val Loss = 1.210367\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.289929, Val Loss = 1.209531\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.290275, Val Loss = 1.209429\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.290503, Val Loss = 1.209352\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.297827, Val Loss = 1.219141\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.290628, Val Loss = 1.210970\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.290974, Val Loss = 1.211153\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.296969, Val Loss = 1.214238\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.291219, Val Loss = 1.210403\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.290551, Val Loss = 1.210976\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.303007, Val Loss = 1.209544\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.290575, Val Loss = 1.211689\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.290830, Val Loss = 1.211045\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.290754, Val Loss = 1.211052\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.290975, Val Loss = 1.211613\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.291339, Val Loss = 1.210874\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 16 with validation loss: 1.210874\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 16: 30 neurons, test_loss=1.210874\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 17 - weights shape: (30, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:06:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.291334, Val Loss = 1.211489\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.291334, Val Loss = 1.211489\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.291334, Val Loss = 1.211489\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.291334, Val Loss = 1.211489\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.291334, Val Loss = 1.211489\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (30, 2), biases: (30,), outer_weights: (1, 30)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (20, 2), biases: (20,), outer_weights: (1, 20)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 30 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 3.998900\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290495, Val Loss = 1.210832\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.289836, Val Loss = 1.210980\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.289808, Val Loss = 1.210432\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.290529, Val Loss = 1.208443\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.290040, Val Loss = 1.209176\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.290211, Val Loss = 1.208905\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.290625, Val Loss = 1.210158\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.290853, Val Loss = 1.209849\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.291976, Val Loss = 1.211116\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.291143, Val Loss = 1.210826\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.290241, Val Loss = 1.210714\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.319849, Val Loss = 1.238790\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.291104, Val Loss = 1.211935\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.291055, Val Loss = 1.210872\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.290650, Val Loss = 1.210894\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.291626, Val Loss = 1.211461\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.291274, Val Loss = 1.211076\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.291644, Val Loss = 1.211392\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.291947, Val Loss = 1.211747\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 17: 30 neurons, test_loss=1.211747\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 18 - weights shape: (30, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.291629, Val Loss = 1.211315\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.291629, Val Loss = 1.211315\u001b[0m\n",
      "\u001b[32m2025-08-27 06:07:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.291629, Val Loss = 1.211315\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.291629, Val Loss = 1.211315\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.291629, Val Loss = 1.211315\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 9\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (30, 2), biases: (30,), outer_weights: (1, 30)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 9 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 31 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 3.870003\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290653, Val Loss = 1.211771\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.289808, Val Loss = 1.210565\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.289961, Val Loss = 1.209551\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.290180, Val Loss = 1.208774\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.290107, Val Loss = 1.209549\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.290659, Val Loss = 1.209123\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.290261, Val Loss = 1.211936\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.290348, Val Loss = 1.210653\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.291007, Val Loss = 1.210324\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.290576, Val Loss = 1.210559\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.337472, Val Loss = 1.255414\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.290913, Val Loss = 1.210628\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.290743, Val Loss = 1.210904\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.290448, Val Loss = 1.211055\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.291106, Val Loss = 1.211037\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.291433, Val Loss = 1.211844\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.292066, Val Loss = 1.213433\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.291370, Val Loss = 1.210797\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.291226, Val Loss = 1.211347\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 18: 31 neurons, test_loss=1.211347\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 19 - weights shape: (31, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.290903, Val Loss = 1.211220\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290903, Val Loss = 1.211220\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.290903, Val Loss = 1.211220\u001b[0m\n",
      "\u001b[32m2025-08-27 06:08:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.290903, Val Loss = 1.211220\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.290903, Val Loss = 1.211220\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (31, 2), biases: (31,), outer_weights: (1, 31)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 31 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 3.941453\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290375, Val Loss = 1.211334\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.289735, Val Loss = 1.210172\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.290400, Val Loss = 1.207840\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.292053, Val Loss = 1.209031\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.289856, Val Loss = 1.208559\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.290312, Val Loss = 1.210845\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.293867, Val Loss = 1.210182\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.290748, Val Loss = 1.211532\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.290638, Val Loss = 1.209987\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.299324, Val Loss = 1.214068\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.291028, Val Loss = 1.210895\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.291026, Val Loss = 1.210656\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.290786, Val Loss = 1.210176\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.290510, Val Loss = 1.210760\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.291834, Val Loss = 1.211366\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.359457, Val Loss = 1.404261\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.292131, Val Loss = 1.211487\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.291518, Val Loss = 1.211410\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.291148, Val Loss = 1.211542\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 19: 31 neurons, test_loss=1.211542\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 20 - weights shape: (31, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.291220, Val Loss = 1.211588\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.291220, Val Loss = 1.211588\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.291220, Val Loss = 1.211588\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.291220, Val Loss = 1.211588\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.291220, Val Loss = 1.211588\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (31, 2), biases: (31,), outer_weights: (1, 31)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 31 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 3.978826\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290172, Val Loss = 1.211044\u001b[0m\n",
      "\u001b[32m2025-08-27 06:09:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.289657, Val Loss = 1.209739\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.305671, Val Loss = 1.210022\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.289750, Val Loss = 1.208917\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.290281, Val Loss = 1.209108\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.290227, Val Loss = 1.209034\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.290383, Val Loss = 1.210401\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.291055, Val Loss = 1.210765\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.290046, Val Loss = 1.210230\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.291140, Val Loss = 1.210734\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.290382, Val Loss = 1.210886\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.455959, Val Loss = 1.575905\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.290611, Val Loss = 1.210672\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.290859, Val Loss = 1.210864\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.290930, Val Loss = 1.210765\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.294255, Val Loss = 1.214052\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.291372, Val Loss = 1.210864\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.291262, Val Loss = 1.211738\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.290849, Val Loss = 1.210814\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 20 with validation loss: 1.210814\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 20: 31 neurons, test_loss=1.210814\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 21 - weights shape: (31, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.291148, Val Loss = 1.211345\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.291148, Val Loss = 1.211345\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.291148, Val Loss = 1.211345\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.291148, Val Loss = 1.211345\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.291148, Val Loss = 1.211345\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (31, 2), biases: (31,), outer_weights: (1, 31)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 31 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 3.893639\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290259, Val Loss = 1.211298\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.289576, Val Loss = 1.209835\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.294383, Val Loss = 1.207062\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.321206, Val Loss = 1.210239\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.290054, Val Loss = 1.210188\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.289985, Val Loss = 1.209326\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.290304, Val Loss = 1.210053\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.290503, Val Loss = 1.210736\u001b[0m\n",
      "\u001b[32m2025-08-27 06:10:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.338761, Val Loss = 1.307729\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.291259, Val Loss = 1.211265\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.294657, Val Loss = 1.218378\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.341395, Val Loss = 1.354737\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.292726, Val Loss = 1.215175\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.291195, Val Loss = 1.210345\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.290685, Val Loss = 1.211216\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.291237, Val Loss = 1.210920\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.291450, Val Loss = 1.211646\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.291085, Val Loss = 1.210822\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.291750, Val Loss = 1.211183\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 21: 31 neurons, test_loss=1.211183\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 22 - weights shape: (31, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.291493, Val Loss = 1.211641\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.291493, Val Loss = 1.211641\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.291493, Val Loss = 1.211641\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.291493, Val Loss = 1.211641\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.291493, Val Loss = 1.211641\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (31, 2), biases: (31,), outer_weights: (1, 31)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 31 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 3.908986\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290416, Val Loss = 1.210870\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.289629, Val Loss = 1.210649\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.310561, Val Loss = 1.250789\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.290440, Val Loss = 1.210025\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.298879, Val Loss = 1.225085\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.290150, Val Loss = 1.209866\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.290193, Val Loss = 1.210660\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.290563, Val Loss = 1.210072\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.487612, Val Loss = 1.598980\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.290725, Val Loss = 1.210621\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.296291, Val Loss = 1.209038\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.290806, Val Loss = 1.211048\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.290280, Val Loss = 1.210729\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.292965, Val Loss = 1.215656\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.304983, Val Loss = 1.254082\u001b[0m\n",
      "\u001b[32m2025-08-27 06:11:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.291654, Val Loss = 1.211985\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.363422, Val Loss = 1.353276\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.290798, Val Loss = 1.211737\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.380259, Val Loss = 1.395267\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 22: 31 neurons, test_loss=1.395267\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 23 - weights shape: (31, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.291267, Val Loss = 1.210505\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.291267, Val Loss = 1.210505\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.291267, Val Loss = 1.210505\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.291267, Val Loss = 1.210505\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.291267, Val Loss = 1.210505\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (31, 2), biases: (31,), outer_weights: (1, 31)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 30 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 3.884295\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290811, Val Loss = 1.211777\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.289573, Val Loss = 1.210224\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.289773, Val Loss = 1.209213\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.289817, Val Loss = 1.208549\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.305183, Val Loss = 1.207966\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.290146, Val Loss = 1.209939\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.290104, Val Loss = 1.210572\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.291390, Val Loss = 1.217486\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.290713, Val Loss = 1.210548\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.291158, Val Loss = 1.210576\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.290798, Val Loss = 1.211799\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.290949, Val Loss = 1.211065\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.420073, Val Loss = 1.538515\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.300491, Val Loss = 1.286996\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.301675, Val Loss = 1.211341\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.290864, Val Loss = 1.211022\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.290842, Val Loss = 1.211329\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.290928, Val Loss = 1.211048\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.291697, Val Loss = 1.211734\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 23: 30 neurons, test_loss=1.211734\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 24 - weights shape: (30, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.290511, Val Loss = 1.210989\u001b[0m\n",
      "\u001b[32m2025-08-27 06:12:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290511, Val Loss = 1.210989\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.290511, Val Loss = 1.210989\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.290511, Val Loss = 1.210989\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.290511, Val Loss = 1.210989\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (30, 2), biases: (30,), outer_weights: (1, 30)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (20, 2), biases: (20,), outer_weights: (1, 20)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 30 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 3.869362\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290115, Val Loss = 1.211212\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.289501, Val Loss = 1.209181\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.291915, Val Loss = 1.210317\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.292065, Val Loss = 1.207951\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.290193, Val Loss = 1.209541\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.289852, Val Loss = 1.209421\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.290415, Val Loss = 1.210139\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.291521, Val Loss = 1.213202\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.292340, Val Loss = 1.210114\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.317621, Val Loss = 1.352143\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.291250, Val Loss = 1.210622\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.314321, Val Loss = 1.324465\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.290642, Val Loss = 1.211191\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.290869, Val Loss = 1.210404\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.294431, Val Loss = 1.208676\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.292079, Val Loss = 1.210797\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.291078, Val Loss = 1.211906\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.389354, Val Loss = 1.358795\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.291192, Val Loss = 1.210647\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 24 with validation loss: 1.210647\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 24: 30 neurons, test_loss=1.210647\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 25 - weights shape: (30, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.291644, Val Loss = 1.211100\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.291644, Val Loss = 1.211100\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.291644, Val Loss = 1.211100\u001b[0m\n",
      "\u001b[32m2025-08-27 06:13:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.291644, Val Loss = 1.211100\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.291644, Val Loss = 1.211100\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 9\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (30, 2), biases: (30,), outer_weights: (1, 30)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 9 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 31 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 3.898471\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290559, Val Loss = 1.212268\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.289688, Val Loss = 1.210700\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.289670, Val Loss = 1.208857\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.290759, Val Loss = 1.213317\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.294853, Val Loss = 1.212178\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.290842, Val Loss = 1.209546\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.290699, Val Loss = 1.211432\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.290460, Val Loss = 1.211143\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.290674, Val Loss = 1.210896\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.311316, Val Loss = 1.231431\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.290353, Val Loss = 1.211513\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.290572, Val Loss = 1.210751\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.290634, Val Loss = 1.210670\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.317038, Val Loss = 1.352145\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.294951, Val Loss = 1.263144\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.294289, Val Loss = 1.218873\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.292378, Val Loss = 1.210931\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.291208, Val Loss = 1.211548\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.291390, Val Loss = 1.211230\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 25: 31 neurons, test_loss=1.211230\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 26 - weights shape: (31, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.294013, Val Loss = 1.215328\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.294013, Val Loss = 1.215328\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.294013, Val Loss = 1.215328\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.294013, Val Loss = 1.215328\u001b[0m\n",
      "\u001b[32m2025-08-27 06:14:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.294013, Val Loss = 1.215328\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (31, 2), biases: (31,), outer_weights: (1, 31)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 31 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 3.765773\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290813, Val Loss = 1.212483\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.289826, Val Loss = 1.211359\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.295046, Val Loss = 1.231121\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.290250, Val Loss = 1.208407\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.290527, Val Loss = 1.212247\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.290039, Val Loss = 1.209432\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.304338, Val Loss = 1.238000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.293306, Val Loss = 1.209668\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.290647, Val Loss = 1.210768\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.290617, Val Loss = 1.210812\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.295052, Val Loss = 1.234927\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.348633, Val Loss = 1.412044\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.292930, Val Loss = 1.214858\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.577092, Val Loss = 1.692034\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.303292, Val Loss = 1.250022\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.291562, Val Loss = 1.213195\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.290905, Val Loss = 1.211164\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.290825, Val Loss = 1.211492\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.291720, Val Loss = 1.211847\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 26: 31 neurons, test_loss=1.211847\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 27 - weights shape: (31, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.290168, Val Loss = 1.210527\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290168, Val Loss = 1.210527\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.290168, Val Loss = 1.210527\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.290168, Val Loss = 1.210527\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.290168, Val Loss = 1.210527\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (31, 2), biases: (31,), outer_weights: (1, 31)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 31 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 3.952059\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290137, Val Loss = 1.210614\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.289477, Val Loss = 1.209372\u001b[0m\n",
      "\u001b[32m2025-08-27 06:15:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.289779, Val Loss = 1.207548\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.302683, Val Loss = 1.225786\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.290161, Val Loss = 1.210852\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.290156, Val Loss = 1.209066\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.290476, Val Loss = 1.211083\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.290623, Val Loss = 1.211250\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.293440, Val Loss = 1.211818\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.290613, Val Loss = 1.211141\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.290778, Val Loss = 1.210466\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.290955, Val Loss = 1.212105\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.290272, Val Loss = 1.210688\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.291189, Val Loss = 1.211563\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.291342, Val Loss = 1.211157\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.290835, Val Loss = 1.211659\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.290634, Val Loss = 1.210332\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.301133, Val Loss = 1.226231\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.862820, Val Loss = 1.778277\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 27: 31 neurons, test_loss=1.778277\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 28 - weights shape: (31, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.291031, Val Loss = 1.211056\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.291031, Val Loss = 1.211056\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.291031, Val Loss = 1.211056\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.291031, Val Loss = 1.211056\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.291031, Val Loss = 1.211056\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (31, 2), biases: (31,), outer_weights: (1, 31)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 31 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 3.987924\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.289988, Val Loss = 1.210556\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.289497, Val Loss = 1.210905\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.333331, Val Loss = 1.267121\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.289667, Val Loss = 1.210047\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.367355, Val Loss = 1.330172\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.291015, Val Loss = 1.208225\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.290437, Val Loss = 1.211165\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.328584, Val Loss = 1.252012\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.299626, Val Loss = 1.240702\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.291135, Val Loss = 1.211681\u001b[0m\n",
      "\u001b[32m2025-08-27 06:16:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.290959, Val Loss = 1.210760\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.291128, Val Loss = 1.211047\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.450404, Val Loss = 1.611453\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.291162, Val Loss = 1.210650\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.291301, Val Loss = 1.210979\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.291324, Val Loss = 1.211289\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.291300, Val Loss = 1.211634\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.290823, Val Loss = 1.210895\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.297341, Val Loss = 1.219443\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 28: 31 neurons, test_loss=1.219443\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36msave\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mSaved training history to /Users/ruizhechao/Documents/NNforHJB/data_result/weights/training_history_20250827_061710.pkl\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1mTraining completed. History saved to /Users/ruizhechao/Documents/NNforHJB/data_result/weights/training_history_20250827_061710.pkl\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mBest validation loss: 1.210647\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mTraining completed with improved logging\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Training with improved logging\n",
    "training_logger, weight_raw, bias_raw, outerweight_raw = run_training_with_logging(\n",
    "    data, model_1, model_2, model_result, weight_raw, bias_raw, outerweight_raw,\n",
    "    num_iterations, M, alpha, pruning_threshold, power, gamma\n",
    ")\n",
    "\n",
    "logger.info(\"Training completed with improved logging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "794aec85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['weights', 'biases', 'neuron_count', 'test_metrics', 'hyperparameters'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_logger.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adb6393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training run: 29 iterations, max neurons: 33\n",
      "Optimal iteration: 2 with 33 neurons\n",
      "Polar coordinate analysis saved to ../data_result/plot/weights_polar_analysis_single.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArsAAALeCAYAAACqWtlrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAADy2ElEQVR4nOydB3iUxdqGx4oFFFRABKQpTREEFTtNsYLYG1bs2PWoeOy9H8WGvRxR1N8GqKiHZm/YUOm9IyJFwZ7/uicObDabZDfZ8n0zz31da2SzSb4y38wz7zzvO2sUFRUVGSGEEEIIITxkzUIfgBBCCCGEELlCYlcIIYQQQniLxK4QQgghhPAWiV0hhBBCCOEtErtCCCGEEMJbJHaFEEIIIYS3SOwKIYQQQghvkdgVQgghhBDeIrErhBBCCCG8RWJXiDyyxhprmM6dO1fpd4waNcr+nmuuuSZrxyVE1NtYNp6dOPPkk0/aa8BXIURmSOyKoPj444/tgLHvvvum/P75559vv9+yZcuU37/77rvt96+88koTJyorFP78809z3333mV122cVsvPHGZt111zX16tUzHTt2NBdccIH58ssvc3K8cebEE0+013v69OmV+vmlS5ea66+/3uy4446mZs2aZr311jNNmjQxJ5xwgvniiy+ydpw+i0cn1s8444wS73O+vB9FaC8cG+1HCJFd1s7y7xMi0uywww6mevXq5oMPPrBCbu21Sz4CI0eOtAPOhAkTzPz5883mm29e6vvQtWvXSv39cePGmQ022MDEgb/++svst99+5n//+5/ZYostzOGHH27q1q1rlixZYkVX//79zYYbbmi23377Qh+qN3z22WemZ8+etu1tu+225vjjj7fthXYzaNAg89///tdcffXV9pVLdtppJ/s3N9tss5z+HZE+Bx98sNl5553tZFMIkRkSuyIoELd77LGHefPNN62wIGLp+PHHH83YsWPtoPLyyy9bYXv00Uev+v7ff/9t3nvvPVOtWrUSP5cJZUWMo8izzz5rhS5R8MGDB5t11lmnxPcRZHPnzi3Y8fnGzJkz7bVmMvHggw+WikoyATvggAOstaB27drmrLPOytmxILDj1FZDgJUVXkKIzJGNQQRHly5dVi11JjJ69GhTVFRkzj33XLPJJpusiuI6vv76a/PTTz9ZocvSsuObb74xRx11lI24sMzfqFEjc84551jxnO7SMUuYRx55pP27RJ47depk3n33XSts+JnkY3V8/vnnZu+99zY1atSwAyFCPXH53C3nuvPj/92rIu/fRx99ZL+efvrppYQuEPVu3759ymXiX3/91Vx22WVmyy23tNeqVatW5t5777XXN3nJ/tZbb7XnS/SY68dXIppTpkxJeVz8jieeeMJOWljmR5htvfXW9jgRjIksX77cRkG32WYbs/7669vP77PPPub999836YKg53cQVatTp46d7DRu3NiKzYULF5b4LO8/9dRT9v+xHrhrnY5d4PLLLzeLFy82/fr1KyV0oUWLFua1116z94LPcO1S+Tn5DJFZrgui+OSTTzYLFizIqE2U5dnl/Hjxt88880zb5onu77nnnqssFlyv3r1722vFNe/evbuZNGlSqfN55ZVX7GRyq622ssdK++WevvTSSyYXcD6cr/t/90q2DaT7PCfaDoiC8+xtuummJSws6Z4j1532ArSfxONzz355nl1WqpgI0X/wvDFRoc2uWLEi5XWgPdImsMYQvec+0b7L6meEiDuK7IpgxS5iFtHg4N+u02dASha77t/u54GI5xFHHGHWXHNNc9BBB5mGDRua77//3vpc33rrLfPJJ5+YWrVqlXs8c+bMMbvuuquZN2+ejexhCyCKh4gtzy5BZPq2226zx4PQwz/76quv2uj0t99+awc9hAmD3rXXXmsH7cSBvV27duUeFwM3TJw40WQK14TjOfTQQ+2/GdyZRCAC7rzzzlWfQyRcddVV9hwQCwin8ePH26jy66+/bgUUx50YXWdS8H//93+mfv36VkhstNFG9ve+8MIL1naBwAaEIyLsu+++M7vttpsVkMuWLbNikL/34osvml69elV4Lkw6OOZu3bpZrzJik3Mj+so95hhdxA3PN2KEidF5551nxTVwH8rjl19+scfPPbv44ovL/Byi/ZBDDjHPP/+8Pf5TTjmlxPe5zhzTYYcdZvbaay/rUWdiwIrEp59+attiVdoE/P7777ZtMqHhXiCaOHb+3ocffmgnEwhFBO/kyZPNkCFDrBDjXq+11lqrfg/PHmJy9913t5//4Ycf7PPEsWORQWBmE86ZezNjxowSNpDEc67M88w50me0adPGXktEMeeVyTlyDLSXe+65x7Rt27ZEu6yo7dAOeA6YhHE/mGS8/fbb5rrrrrPHjIBNnJwDqwccE+32uOOOs5M22hT3bsyYMdZCI4RXFAkRGH/++WfRxhtvXLThhhsW/f7776ve33bbbYu6dOli//+uu+4iBFk0a9asVd/v0aOHfe/dd9+1/160aFHRRhttVFS/fv2i6dOnl/gbzz33nP3s2WefXeJ93uvUqVOJ93r37m3fv/HGG0u8/9hjj9n3eY0cOXLV+/y/e3/QoEElfua4446z7/P3K/q7FTFmzJiitddeu2jdddctOv3004sGDx5cNHfu3HJ/hr/B32rRokXRkiVLVr3P//PeGmusUfTZZ5+VeP/HH38s9XtGjBhRtOaaaxadcsopJd6/99577e/v1q1b0YoVK0p8j38n/q5jjjnGfvaRRx4p8bkFCxYUNWzYsKh27dpFK1eurPA68Pnly5eXev+pp56yv/+GG24o8f4JJ5xg3582bVpRuowaNcr+zG677VbhZx9++GH72ZNPPnnVe0888cSqNjFs2LASn7/sssvSbovJbezqq68u8X6jRo3s+4cffnjRH3/8ser9W2+91b5fs2bNogsuuKDo77//XvW9M888037vpZdeKvG7pkyZUurvcp3btGljn89ffvkl7eMt6/hpt6naZyoyfZ65v+6aX3XVVSl/Zybn6H4f7ScV7h7z1bF06VL7e6pVq1b09ddfr3r/r7/+KjryyCPt56+77roSv8cd81lnnWU/53j00UdTXjMhfEBiVwSJE67vv/++/ffChQutELv22mtXCT2+//TTT9t/MygwkK+//vpFv/32WwlB7D6TTPv27Ys222yzcgfsX3/91Q5UderUsf+fCIIBgViW2N1zzz1L/U33vQsvvLDcv5suAwcOtOfgBkheDRo0KDrxxBOLPv/881Kfd2LimWeeKfW9//73vylFV1kgCBo3blzivVatWhWttdZaRRMnTiz3Z3/44Qf7ua5du6b8fv/+/e2xDBkypKiycH8QR507d66y2GXSws8cddRRFX72zTfftJ/db7/9SgmhvfbaK6W4ou1yrInipipid8aMGSXenzlzpn2/evXqpUQqk8PyBGEyd955p/08E4B8it1Mn2cnTjfffPNVfUK6pDrHyohdjpX3mFAkwz1istq0adMS7/N5JvrJEzgmL3ye8xTCN2RjEEGCZ43lVawJLHGz1Mc44LyVLCuyxMf3Web76quv7NIfS7VuiZIlYmBpM5W/lGXeRYsW2VdZWe3YFX777TdbJYJlyGRvHfYGPpOKDh06lHqvQYMG9ivHmg2OOeYYu2z+zjvvWJ8rS5wsVbMc/PTTT5v7778/pb8UG0hZ7yWXK+PaU9KN68i1okqGw11r+Pnnn+1SOP5HPLrlgcWDahJc21S1Yp2HFMvEgQceWOF1IGHxoYcespYFfNv8bkeUkvRSXXc84LRnrvPUqVPt9asKLOM7q4jDVQjgviRXG3HfS75OLJ3fcsstNlkUa8HKlStLfD/f17WyzzO2g8R2ms9zdM9SKk8496hp06bWhoR3HV+/o3nz5rZdJCfvumorQviGxK4woSepXXHFFat8bXgyAc8enjbn001VcgxPKCD4KvJjliV28ZACPrtUMPiUBV7VZFwptUQxVlW4Lj169LAvN+jfcccdttYwPkP8hckl2lIdt3svMbEKvyE+QwZe/IL4ExFLLhEHgeBwP4dXtyLcvSFxh1d596Yi8OvioyXZi2QrJhR4uwGRjqCuKu76zZo1q8LPus+kKkFVVntJde0rS3ntrrzv/fHHHyXuD3WESShksskkEn8znl4mlviqs3FdM6Gyz3NZ1zwf5+j6j7KOgTaC2OVziWI31X1y9yqbfYcQUUFiVwQJ0RgiVEQpSbhBzJJkkhhdJVpCkhTJTy5LOTE5zQ0YJIRVNqHD/Y7krH5HYhZ9VED8MkEg2kvyFmLSJaIlHndy9M+dS2L5JKKu/D4ixsnRWurKJuJ+joS+dK/rRRddZIV5ZSHKzAYPiAYESuKkhJUAEgSzAZF9Et+4DgjS8kpMDR8+3H5NVf6urPaS6toXkscee8yKQK4tbSkRIqEIwXxT2ee5rE0q8nGO7pjLuu+UB0z8nBChotJjIkiI3FLuimVFsqNZHk9eCuT7QK1ZstmJPiJKHC4K7Ep0VQbKSSGwETnJUR7EVFV+d/L5Zjtik7wMmgjXq6z3EjehYLmYsmTJQpfKFCy5J/+91q1bm2nTpqUsZZUIETVESFWvH0vWiE+EZXL0nbJvycvS4CoOZHK9qULBph1EzROrVSRDO6WcFVE6MvrTue7YPxDqCB6WtXPZJtLF2QSoeJDOOWSL8u5NNp7nqpxjZdqNe5ZSlQxjBYBj4J4nRnWFCBGJXREsLkpLCSZIFrvUkGWQoBwQggc/ZOKOayeddJL9/r///W9b3ioZalw6H2BZIHQRLURmWBJPBE8sntJsQP3N2bNnZ/QzRFZHjBhRqjYucF5Ew7keRMSTIZqVuGTO/99www1WgFLb00HpK0o3JUamEHzUcE1c9nb07dvXigFq3CYLTX7OLUVjC6CEFJH722+/PeU54M1MVYc0EVcrFq9u4mfx7ZZVGotrna4lIZGbbrrJrjbw9dFHHy31fQQ+womVCCKDrqxZIkzMKDeVyI033mh9mNQuRuBWpU1kC1dOLrneMSXn3njjjZz93fLuTTae56qcI/ee5yOTdkN7IFpPebnEY6a9X3rppXZlQtsPCyEbgwgYJ3ZdTdpk0UakBa/dsGHDSnzegYfzueeesxE5bBHUyKWYOxFarA8UsCfBzP18Wdx8881WpLAJAz/j6uwOHTrU/k5+PlGkVAa8xtRCxV/L7+fc2JZ2u+22K/NnGNgR+nhkqVeLLQGhRXSROp7UvEV0pfLQkgDDUnBinV2E1YUXXlgiOo5g5MUxIfoZnLFHMFhzTalXmwgimGvEuRAN5hyIWLJcjMhj6djVKH3ggQfsdbzkkkvsNrtEZxGIiAmisohHIsjlbd/MdUdYE23lePAt438k4QgxwwYYqa411onTTjvNnj9RWz5LomN58BlEEALm1FNPtZtwMAFz2wXzN5kAYP0oa/c0ku04Rq4l/mc3KWnWrJmtu1rVNpEtuBZsJsK95/g4d+41Fg0SIkkIzAWcMzWauS/UZOa5d/c1W89zZc+RlQtWJLAG8bO0b9of/59YazoR2v4jjzxi6+wSmcb/znnQn7BaxOYi//rXv7Jy7YSINYUuByFEoaB0lCurlVw+ynHzzTevKrmVWB82kfHjxxf16dPHlmWiJm2tWrVs2axzzz236NNPP02rfNLUqVNt7VJqZm6wwQZFe+yxR9Ho0aNtmS5+5ssvv6ywLFR55YvmzZtXdMQRR9jzpX5tcgmjVFBOirq2lGnbaqutbLkizm/LLbe0xzp8+PBSP+NKO1G/9pJLLrH1bPkZSqhR7iux/irw7wEDBhRts802Reutt54t48S1pBRcWWWi+Blqgu688872mLheW2+9ddEZZ5xhjzm59u5tt91W1KFDB/tZSsc1adKkqFevXrZsU2Kt2LKgFjM1kPkblInj/C+66CJbuol7zisZ/iafX2eddTIu+7Z48eKia665xpaAolyYu+bHH398ynJvyWWpXn311aIdd9zRnuumm25qy8Rx/5Mpr02UV3os1flCWedZVpv86quvirp3726flxo1atif/d///peyxFZ5vz+T0mPcb9ol15MyW6mOK93nuaJSYZU5xwkTJhTtv//+tlQcpRATyw6W9TOuvBul6Pg5jrl58+ZFV155ZdHPP/9c6rPlXcfy7q8QcWYN/lNowS2ESA0VIfAQYgMozyMbFYhEum2XRf6gcgXL8Cxna9laCCFKIs+uEBGA5fRknnnmGVvpgJJFcRC6QgghRBSRZ1eICIC/Fd8k1QZcHU4yrEmYqUrpLCGEECJ0JHaFiADsQsaObiROUbSeJBN2L2PjBpJkhBBCCFE55NkVQgghhBDeIs+uEEIIIYTwFoldIYQQQgjhLRK7QgghhBDCWyR2hRCRhZ2r2EKV1z777JPyM+wSxvdVXzZ7sJUy2zpTJYQtdtlpbKuttrI7dJFEmQxbNbM7Hjvtsascn2fLZnYgpPZvqq2fhRAiX0jsCiFiAVsUjxgxotCHEQTvvfee3baZbZ979+5tzj//fNO+fXszePBguwUt2y8n8vPPP5sHH3zQTjoOOOAAK3wPPvhgM2fOHHPyySfbbYzZXloIIQqBqjEIISId2W3SpIlp3LixmTlzphVcn376qRVViZHdXXbZxUYi2UlMVB0itURnk/n222/NjjvuaDbaaCMzf/78VfcBIfvnn3+addddt8TneW/vvfe2NaOHDh1qhbAQQuQbRXaFEJGnRYsW5rjjjrNL6C+88ELaP7d8+XJz9dVXm2222casv/76pmbNmtYO8f7775f6LIKaV1nbICcKbLjmmmvsewg5RDZCfIMNNrCfdcyYMcP06dPH1K9f3wrBBg0a2H8j3Mv6Gyz587s5lmrVqtno6gMPPJBSkN55552mbdu2ZuONNzYbbrih/ZkjjjjCfP3116YqpBK6gK2hVatWZuHChWbZsmWr3l9zzTVLCV1Ye+21bYQXJk+eXKVjEkKIyqJNJYQQseC6664zgwYNMldccYU55JBDzDrrrFPu5xcvXmw9pN999531jrJxBwLttddeM126dDEvvvii6dWrV5WP6/bbbzcjR440Bx10kOnevbvdAQ8mTpxodt99d/PDDz+YHj16WMFNZPTxxx+3G4gguBGyyRx99NE2er3ffvvZ34W479u3rz3fU089ddXniGTzve22286cdNJJVhjPmjXLHstnn31mRbADEYzwnjZtWpmCPh2mTJliJkyYYBo2bGgFdkUQ8R02bNgqoSyEEIVAYlcIEQu23HJLc84559jtkx966CFz9tlnl/t5PovQfeSRR8wpp5yy6v2bb77Z7LDDDua0004z++67b5lRzHQZPXq0Tehq06ZNifcR1whdjpW/5SBKi3g988wzzfDhw0v9vtmzZ1tRjFUAzjvvPCsUieI6sbt06VIr1jt06GD/thPY8Ndff9mIdjZAdL/xxhs22oxYxrMLAwYMSPn533//3dx0000Gd9yPP/5oz2/8+PFWjHfr1i0rxySEEBmDZ1cIIaLItGnTyCko2meffey/Fy9eXFSzZs2iOnXqFC1fvty+99FHH9nPnHDCCat+7ocffihaa621irp27Zry9/bv39/+zJAhQ1a916hRI/tKRadOneznE7n66qvtexdccEGpz8+YMcN+r3Xr1kV///13ie/99ddfRS1btrTfnzlzZqm/MWLEiDL//rJly+y/ly5dav+92267lfr9qZg8eXLRuHHjin7//feiTLj33nvt33GvunXrFr311ltlfp57kvj5NdZYo+jiiy8u+uOPPzL6u0IIkU3k2RVCxIZatWqZyy67zHpGifCWBcv4RDh/++03639NfpHUBkQdqwrVCZL56quv7NdOnTqV8vrib8Vekfi5RIjWJoPXF5YsWWK/EvXdf//9zQcffGC9wkRTP/zwwzJLfDVr1sy0bNmyQutHMkTPidKuWLHC+oCJhGOvKOvaV69e3X6ea4+l4v777zePPvqo9SMnenyFECKfyMYghIgV5557rrnvvvvssv5ZZ51Vpl8XEIO8yuKXX36p8vHUrVu31HtO2KX6HtSrV6/E5xJx9oXkRC9ARDqwMSByn332WfPvf/971c9iGeB9kuWyBcl9eINJxMOacemll1rhW5YPF0GPQMeqsdlmm9mkuRtvvNHceuutWTsmIYRIF0V2hRCxAuF17bXX2tqufE2FE4wXXXSRjTSW9aJSQ6JAo1RWKvDIlkVy5Dbx7y9YsCDlz1C2K/FzlQExe8MNN5ipU6fa12OPPWarVtxzzz3mggsuMLmCJDwSz6jFm+7ngaoVQghRCCR2hRCxg0oEVDcg+SxVSStqwSJCP/roo4wsEtgjkgUv0d9JkyZldHzt2rWzX999910rqhPh37yf+LmqQi1iNm8gWQ4rgUskywVz5861X9O1RGT6eSGEyDYSu0KI2EH1AZbqXU3aZNiqlqVzfKyUBku1dw5VDPCiJgpkft/AgQNXvcfP9evXL2O7A5UjKG9GNQhKjSXy8MMPm3HjxpmuXbvaEl6VASsBFRuS+emnn6xPObnCBCXD8Cenu21vqi2BnceYSgwI17322mvV+99//32Ja+ngPXZTAzzGQghRCOTZFULEkp49e9o6tqk2iHAlvqgJe8kll9jtbdlljU0lSJxCzBGtnTdv3ipvK8lYTzzxhC1Txla5tWvXtkv1JIVRszbTjRrYPpfjo1wYdXVbt25txS9RV343368sbMO7/fbb2+PCS8umFZT6ooYwgvbiiy8u8XnKfmVSZ/ewww6zPmGS5RDulBTjWnJdmABglUj8PdT7veuuu+z58j72DI7xzTfftMe1xx575NRaIYQQ5SGxK4SILSQ8sWFEKjbZZBMb2SWZ7fnnn7cRW7ymRH0RiVdeeaVNnnKQbMUGCERy/+///s/aAYhGUnmAKHGm4J9FVOMr5ve+/vrrVuSSQIZXuFGjRpU+bwQlEe0RI0aY//3vf1ZQci5UZqAuL8ljVeHyyy+32/tStQKhznUjqe6YY46xk4KOHTuW+PyBBx5o7Qpcb6wj+KnZdAIhftRRR1mLhUuyE0KIfLMG9cfy/leFEEIIIYTIA/LsCiGEEEIIb5HYFUIIIYQQ3iKxK4QQQgghvEViVwghhBBCeIvErhBCCCGE8BaJXSGEEEII4S0Su0IIIYQQwlskdoUQQgghhLdI7AohRI5Yvny5Of/88+1uaeuvv77ZddddzWeffbbq++zpc9VVV9ndyfj+XnvtZbcxToQdydq1a2d3TXvssccKcBZCCBFvJHaFECJHnHLKKeadd94x//3vf83YsWNN9+7draCdM2eO/f5tt91m+vfvbwYMGGA++eQTs+GGG5p99tnH/Prrr6t+R58+fezWxs8++6y5+eabzaxZswp4RkIIET+0XbAQQuSAlStXmho1apjXXnvNHHDAAave79Chg9lvv/3M9ddfb7bYYgtz0UUXmYsvvth+b+nSpaZu3brmySefNEcddZR9j6jwqFGjTJ06dUznzp3NU089ZVq3bl2w8xJCiLihyK4QQuSAP//80/z1119mvfXWK/E+doX333/fTJs2zcyfP99Geh0bb7yx6dixo7UuOLA5tGrVyn5v5513ltAVQogMkdgVQogcQFR3l112sRHcuXPnWuH7zDPPWCE7b948K3SBSG4i/Nt9z9kYfvzxR/PDDz+Ye++9N+/nIYQQcUdiVwghcgReXZxi9evXN9WqVbP+3KOPPtqsuWZmXS9e3lq1auXsOIUQwmckdoUQIkc0a9bMjB492vz88882sezTTz81f/zxh2natKnZfPPN7WcWLFhQ4mf4t/ueEEKIqiOxK4QQOYbILOXFfvrpJ/PWW2+Zgw46yDRp0sSK2uHDh6/63LJly2xVBuwPQgghsoOqMQghRI5A2NLFtmjRwkyePNn861//sglr7733nllnnXXMrbfeam655RZbYQHxS4mxb775xnz//felEtuEEEJUjrUr+XNCCCEqgFJi/fr1M7NnzzabbLKJOfTQQ82NN95ohS5ccskl5pdffjGnnXaaWbJkidl9993NsGHDJHSFECKLKLIrhBBCCCG8RZ5dIYQQQgjhLRK7QgghhBDCWyR2hRBCCCGEt0jsCiGEEEIIb5HYFUIIIYQQ3iKxK4QQQgghvEViVwghhBBCeIvErhBCCCGE8BaJXSGEEEII4S0Su0IIIYQQwlskdoUQQgghhLdI7AohhBBCCG+R2BVCCCGEEN4isSuEEEIIIbxl7UIfgBBCRJk///zTLFy40CxYsMAsW7bMLF++3Pz8888lvpb1/4lf//rrL/v6+++/S71gjTXWMGuuuaZ9rbXWWqv+n9f6669vatSoYapXr26/Jv5/qvcS/3/TTTc19erVMxtuuGGhL6UQQhSENYqKiooKfRBCCJFvfv/9dzN//nwzb968Eq+5c+eW+DdCF0Faq1Yts/HGG5crLMv6f4TmOuusk1LI0gVPmzbNNG7c2AreZEHMv1euXFmmkC7v/3n9+OOP5o8//jAbbbSRFb28tthii1X/n/wex8txCCGEL0jsCiG8BJE4Y8YMM3HixFWvyZMnrxKzixYtsqKuTp06KUVf4r/r1q1rqlWrlrPjnDRpktl6662tEM42CGYEb3mC3v37t99+MxtssMGq80aAN2/efNWLY1SEWAgRNyR2hRCxhe4Le0GioHWvKVOmWKHXrFmzVWJtq622MvXr118lZBGxa69dWDdXrsVuJtdyyZIlJQQwEefEa7p06VJ7/RIFsHs1adLERq+FECJqSOwKISIP3RTia8yYMearr74yEyZMWCXA8NE2bNgwpQAjMlloMRsXsZvOPfjhhx9KiF+O233F29y0adNV137bbbc1HTp0MK1bt5YIFkIUFIldIUSkoEuaPXu2+eKLL6y4dS+EVsuWLU379u1Nq1atSkRrWXqPK3ERuxWdA/fMiWAmI19//bW9h4jg7bbbzgpf99pmm20kgIUQeUNiVwhRMOh+Zs2aVULU8sJjiqBNFEjt2rXz0i/qg9gtC2wknFvivUUAkxyYSgCvu+66hT5kIYSHSOwKIfLGihUrzEcffWRGjx5tPv30Uyt+fvrpJ7vU7UQPkdu2bdt6KWxDE7tlCWASBZMF8K+//mratGljdthhB7P77rubzp07mwYNGhT6cIUQHiCxK4TIubgdNWqUfX3yySc2KQwhs/POO1txS4QvzjaEqhKa2C1LAJNQiOj97LPPzHvvvWdFMJ5r2op7SfwKISqDxK4QImtQDxZxO3LkyBLitkuXLqsEC1n7quO6Gond1JB4+P7776+aKCF+SYBLFL9UhhBCiIqQ2BVCVFncJkZua9euXULcIlAkbstGYjc9JH6FEJVFYlcIkRHUXh0yZIgZPHiwXW6WuK0aEruVg5q/H3zwQQnxS2WOAw880PTs2dPstttukS87J4TIDxK7QogK/ZQkkyFuEbmUlerUqZMVFPvtt5/dtEHitvJI7GZP/GKfoY0OHTrUbpG8//7723a6zz772K2ehRBhIrErhCjFL7/8Yv73v/9ZgSvhkFskdvM7QevRo4dNfBNChIPErhDCMmfOHCtsEQcI3S233HKVONCScO6Q2M2v9Yayd9Rwpl3TvnfccUez5pprFvoQhRA5RGJXiICh3ulzzz1nXnvtNbsN7y677GIFAK8WLVoU+vCCQGI3/3aHYcOGWeH7xhtvmGrVqlmf7+GHH266deumSZ0QHiKxK0RgsO3u888/b5555hnz5ZdfWt/tIYccYm0Km222WaEPLzgkdgsH9hyS3JjsvfDCC/ZeHHXUUaZ37962BrS86EL4gcSuEIF4cBnQBw4caN555x27oQMD+mGHHWY22WSTQh9e0EjsRuc+UNWBSeBLL71k6tWrZ5+RY4891lYYEULEF4ldITzlzz//NMOHD7eD9yuvvGIaNWpkB++jjz5aCToRQmI3mvWj8fgyOXzzzTftFsY8O0cccYRWP4SIIRK7QngEj/Pnn39uB+lBgwbZxJtjjjnGDtRt27bVsmwEkdiNNosWLTIvvviifaao8EA1EqK9+NpD3uZaiDghsSuEB8yaNcs8+eSTNoo7b948c+ihh1qByyYPElDRRmI3XlUdnn32WfuczZ4923rdTzzxRPucaSIpRHSR2BUixiLprbfeMgMGDLDZ5d27dzfHH3+8Lam0/vrrF/rwRJpI7MYPhs0vvvjCit7//ve/ZtNNNzWnn366OeGEE+z/CyGihcSuEDGDyO3jjz9uHn74YZtNfuqpp5pTTjnFNGzYsNCHJiqBxG68+e2332xC20MPPWRtDiR9nnHGGWbXXXdVtFeIiCCxK0QM4DElU/yBBx6w9UG7dOliI0nUB11nnXUKfXiiCkjs5pbJk40ZMcKYn382pnp1Y7p2NWarrXLzt77//ns7CX3qqadM/fr1zZlnnmlXW2rUqJGbPyiESAuJXSEizM8//2yXSu+77z4b0SWCe9ppp5lmzZoV+tBElpDYzQ2zZhlz1VXGvPuuMStWGMMmaX//bQw5ZXvuacx11xmTq8WQFStW2Lq9999/v92qGF9v3759tVGLEAVCYleICIL4IYr7xBNP2Bqf55xzji12Ly+uf0js5kboHn10cVR3o42MIbCKo4DRbvlyY5YtK47uPvdc7gQvMLxibWCySkWHTp06mbPPPttu4KJ7LUT+0IbgQkQEBsYRI0bYgXDbbbc1CxYssDU+x4wZY0466SQJXSHShIguQnfzzYvFrrPO8pV/8z7fv/rq3B4Hnt2OHTvaJLYZM2aYPfbYw/p5mdjcfffdduVGCJF7JHaFKDB///23efXVV+2uZiS37Ljjjmb69Om2xNEuu+yiJBchMgARi3UBUbv22qk/w/t8f/To4s/ng7p165orrrjCPtu33HKLfb7Z6OXaa681ixcvzs9BCBEoErtCFAgqKTz99NOmTZs21s935JFHmpkzZ9rBj61KhRCZQzIaHt2KcsL4Pp8bOdLkFRJK2Yntk08+Mc8//7x59913zZZbbmkuuugiM2fOnPwejBCBILErRAG2IiVxhaXM66+/3lxwwQVm6tSp5sILLzTVSRcXQlQanAEko1W0IML3+Rwe3kLAis1ee+1lt/TGvkQfsNVWW9kE1Mn5CjcLEQgSu0LkiaVLl5qbb77ZNG7c2DzyyCPm1ltvNePHj7cVFqpVq1bowxPCC5gvUnWhotRrvs/nolAVbKeddjKvvPKK9edTtxfPPgmpX331VaEPTQgvkNgVIseQaNavXz+7VEnCGdv6fvnll9a2oIxsIbILdXQpL1ZRxJbv8zk+HxVat25ta/QyCd5ss83sxhQkrL733nuFPjQhYo3ErhA5gkQUvLhNmjQx33zzjXn99detP2+//fZT0pkQOYKSYtTRpbzYn3+m/gzv8/1OnYyJYslqVn8oVzZt2jTTrl07u3nM7rvvbvsQVQsVInMkdoXIMvPnz7e1NFu2bGmzrD/66CM7SDFYCSFyDxtGIHrnzy8WtU4f8pV/8z7fv/ZaE2mo4HDTTTfZxFUE78knn2yrtozMd1adEDFHYleILLFs2TJz5ZVX2iST2bNnW//dc889Z9q2bVvoQxMiKNgogg0j9t+fTTuMmTvXmHnzir/yb97P9YYS2WTjjTc2l112mU1i69mzp+nVq5fZd999rR1KCFEx2kFNiCpCQgm7nd14443Wc0cNTbx2QqSDdlDLLRQ2IBCKR5dkNDy6UbQuZMKPP/5ok13pdxC+VHXRFuJClI3ErhBVECnPPPOMueqqq0zNmjXt4CM/rsgUiV1RWbA3XHPNNXYFqU+fPnZlCeuDEKIksjEIkSHMD4cMGWITRxhoiOiynEjWtISuECJfUOHl8ccfN59//rndkILoLpNvLFVCiNVI7AqRAR988IHd354oCsXfJ0yYYHr37m3WpDq9EEIUgG222cbW6X3nnXfM6NGjrei9++67rcVKCCGxK0RafPvttzYxhKSQvffe20yZMsWcc845Zt111y30oQkhhGWXXXYxo0aNsrV6n3jiCdOiRQu7JTlWGSFCRmJXiHKgdNiZZ55pdtxxR9O0aVObDX311VebGlHYdkkIIZLASoWlCmsVFiusVh06dLCrUkKEisSuECn4+++/zaOPPmqaN29uk0DGjh1rlwVr165d6EMTQogKwVp17LHHmnHjxtndGvfZZx9z4okn2h0dhQgNiV0hkiDZg+VAoiIkfwwdOtTWzhVCiLhRrVo1u135999/b37++Wdrbbj33nvNn2VtLyeEh0jsCpFQu/KMM84we+65p/XmMjjg01WFBSGED5Ub/u///s+88MILdiviHXbYQdYGEQwSuyJ4sCw88sgjNuLBzmdYFq699lqz/vrrF/rQhBAiq3Tv3t1888035qijjpK1QQSDxK4Ims8++8zuNc/+82QvY1nQTkRCCN+tDWw/zOrVL7/8ImuD8B6JXRGsZeH00083nTp1spnLdPo9evQo9GEJIURerQ0vvviifWFtoGrD+++/X+jDEiLrSOyK4CwLDz/8sK2yMHfuXGtZoDSPLAtCiFChdjjWhqOPPtrmK5xwwgmyNgivkNgVwUCN3K5du5qbb77ZPPnkk3bLX1kWhBBitbWBUmVYG1q3bm2ee+45uz26EHFHYlcEEc1lia5t27Z2W02iubIsCCFEaRo2bGirNrACdt5555nDDjtMUV4ReyR2hffR3G7dupk777zTDB482Nx///2mevXqhT4sIYSINIceeqj57rvvzNprr22DBIMGDVKUV8QWiV3hbTQXYUs0t1WrVjaa26VLl0IflhBCxAZ2jHz++efNgAEDzLnnnmujvAsXLiz0YQmRMRK7wjumTZtm9tprL3P77beb1157zTzwwAOK5gohRCVB5BLlXWuttayXl40phIgTErvCq2jugw8+aLbbbjtbN5JoLglpQgghqh7lReTSx/bt29ccfvjhivKK2CCxK7xg+vTptnzOrbfeal599VXbIdeoUaPQhyXEqokYBfv/+OOPVa/ff/991euvv/5a9f+Jn+Fn+Fl5JUVUQOQS5QW8vNToFSLqrFGkXlTEGJrvQw89ZC655BJzzDHHWOuCRK7IRTtDkCI+E18I0eSX+yxfE99LZo011lj1u9nkZJNNNjFrrrlmmcKW75X14nexxOy+klSU+OIzQmQbIr1nnXWWXUEjR4LorxBRRGJXxBbK4Rx//PFm/Pjx5rHHHrM+XSEyBTHqIq0I2FSi1olXhGSimHQCszwhmixKwX0FfvekSZPM1ltvbX8fJHbLqQR1ea/E43fHzd9OFsCJr3XXXXfVuQiRCVgZELzvvvuurV/OjpRCRI21C30AQlSG//3vf6Z37942ooA3d6ONNir0IYkIg+BLtA4k/z9icJ111ikhACmyjwB07/P/+YqQJopOJ7CzGZHmtXLlylXWCr5ybojeVC9FhkVZ1KlTx1oZnnnmGXPkkUeaM88809x44432uREiKiiyK2IFg/K1115r/vOf/5h77rnHnHzyyYpGiVXQnf3222+rXomCFhiAk4WcE7OFakepIruFOIZkH7F7ES120V/3YiKw3nrrFex4RTSZMGGCOeKII+z269Tlbdy4caEPSQiLIrsiNsyePdv6cvE3fvzxx2bbbbct9CGJCAjbX3/91b7c/yNaEWO8NthgA1OzZs1VolYTo9S46DECNlVkOFH8rlixwvz0009WHHNNETZO/EoAhw1VcD755BNz0UUXme23397ayw455JBCH5YQErsiHrz++uvmhBNOMAcddJB58803zYYbbljoQxIFFLZO3Dphi+BC1CK2ELYStdmB6+hsHUwckldZEicZS5YsWSWAnfCVAA4P7jfJamziw8rbyJEjbeJw8kRKiHwiG4OINESSLr/8crtPO+XEjj322EIfksgDdEt4Soki8uL/EV6JAgqR64OwjYKNIVsggJMnJQhgF2VnUsJXxLMIY7v2o446yrYLdmKjjQtRCNTjiEjvhEZHieD9/PPPTfPmzQt9SCKP4pakKIQRpeTq1q3rhbD1HRcFTlx5cclw3FcsSHPnzpX4DYSmTZua999/3/Tr18906NDBbjuMFU2IfKPIrogkL730kunTp4+tuHDHHXdoCSwgceteoYhbnyK76ZAofnkRCZb49Z8hQ4aYE0880Rx88MGmf//+pWwxQuQSiV0RKVj2JLlh4MCBNrnh0EMPLfQhiSyKnF9++cX8/PPP9itCNkRxG7rYTUf8MrmtXr26fSGEQ2wXPjJr1iwb2V28eLHdkIId2ITIB5o+i8gwY8YMO+snweXLL780TZo0KfQhiSrAPBoLCuKWFxMZhAsCZtNNN5WIERaiuFhV3M6HiZMiRBETACd8ifyq5m98adiwoU1Yu+aaa0zHjh1tLoZsDSIfKLIrIgG+LkrUEMmlfi5RPhFfewJCZfny5Va44N9EqPBVheZLE3pktzyo8Uu0102Y+Hdie5LdIb5QVefoo4+2m1DccMMNavsip0jsioLz6KOPmvPOO896c+n4RLxAgDgxQkQOXCQOQaJIXPlI7GZWfs61NWd3cFFhTaTiB1u99+zZ09bnxbqmnTBFrpDYFQWDqN+FF15onn32WbvdJHUZRTyg2yDitmzZMhvBdUvRCFwEiOwJ6SOxWzkoaeaEL22RdrfxxhvbdqjrGB/YoISqO/h5Bw8ebLbaaqtCH5LwEIldURDw4rGP+vz5881rr71mS9SIeETWELi8+DeRGF4SuJVHYjc7E2fXLmmjTLrc5EsrC/G4f5deeql58sknbeJat27dCn1IwjNkeBJ55/vvv7dLV2z3++GHH65KTBHRjaA5IUHCGfdr8803txYFCVwRBVhZ2GSTTeyLNkpb/eGHH+xkmvZKxJfkNrXX6N6/O++8044JjA233nqr6du3r+6XyBqa8saMd9991/To0cNsscUWtiN49dVXS3yfLNeWLVtaIVKrVi2z11572b3KE2ncuLH92cTXLbfcUuIzjzzyiGnUqJHd3zz556vC0KFDzS677GITE15++WUJ3QhHG9n+lQoZ7ILEMjFCgugjbY+ImQYiEUVIbt1ss83sahHZ/0R258yZY6ZMmWIWLlxoI78impx00knmnXfesQlrp59+up245APGP/qz888/f9V7nTt3LjVOnnHGGSV+DtsFmx3hOWZsE9FFkd2YQQJQ27Zt7Z7jVC9Ihgfvvvvusx09WfH/+c9/TPfu3c3kyZNN7dq1V33uuuuuM6eeeuqqfyeKzpkzZ5rbbrvNDBo0yA4SdEBEY6sCS978Tjox6uceccQRVfp9IvtwjygPhsglMkZpMCwK9evXV9a7iB2IE6K5vOrUqWP7Ttr19OnTre2mZs2att+TzSFa7Lrrruazzz4zvXr1snYGNhji/uUK/tZDDz1ktttuu1LfY4xkrHQkboTBpIno8xNPPGH7TsZkxlpVEoomGsFixn777WdfZZFcs/Cuu+6y4vKbb74p4YNyS9GpYEBgIODh5zOI5qrAz59yyinmvffes5FposUiWlFc7jkiF8sCApeovnatEz4JX1chhPa+dOlSu3UxkV7aO/0dkzsRDYjIM14gIHfccUeb19GuXbus/x2SG4899li7kkkgJhnEbVnjJGIXj707LgICvCexG000pfUYloAo2o1fjWhw8rINhf0RnrfffrtNEHDgm0Lo8nPscJOqE0iXuXPnmk6dOtloCjNoCd3oQMeMp5HlXQZ/bC9kQtO5S+gKX0GgYMlh0xpWLRC/9E+saLnES1F4EJrPPfectTPsscceNsKbbYjMHnDAAdbulwrKoWGJYUzs16+ftXM5mCSx6lmvXj1r7aJspmx50UWRXQ/BO0QpFx5MHkQ8UDywjnPPPde0b9/edvgkiPEQz5s3z0aBHUSDsR24/eorw7hx48w+++xjO5IHH3xQkZMIwEBONINyP0Tc6bCJolT2HgsRVxK3q2ayz4SPpDaivUz8mOzLvlP4e3T55ZfboEvv3r3N7NmzbU32bIBN74svvrBBmLJWSVnhQsiyMkq1iAkTJthcE8fVV19tfb5YYSR0o41Kj8W8I3jllVestykRvGmI10WLFtnlmREjRtgks7J8T48//ridPSOCsiVIP/74YztjZuZ87bXXKpkpIglnvHjkNZhHB5Uei+5kEAFDUEArHYXn008/tWMKlribbrqpSmMKNX132GEHGwhyXl0S0rAk3H333Sl/hnEUKyD5L82aNav03xaFQTYGD6ESA8vRO++8s43QImj4WhbsUU5kg6W8bPDGG2+Yvffe2xr7eUnoFg7uK9EqrAoM4iQp0lFjYZHQFaIk9FUI3C233NJWrSFiR0USxFHiErbIPzvttJPdVh5rQ58+fUpY7zJlzJgxNoLPCif9IK/Ro0eb/v372/9nAppqnATErogfGu0C2c61vHI7X331le3Us5Hx+vTTT1vvEsXBDz/88Cr/PlE5SDRj4w4iuSzTNmjQoEQmsRCifFjlwr+OBYxniSV03mOiqBrThYESX1jv9t13X3PwwQeb559/vlL9GhHasWPHlngP/y1lO7ErpFphYZwErIEifkjsxgyic4kzy2nTptmHkKU2OuEbb7zRFuXmgcTGcP/999vyYU54fvTRR9bSwNa8RDD49wUXXGD9UCxtV2X574477rDJbEOGDDFdu3bNyvmKzGBSQ5Y5W/hyf1VVQYiqQaSPQAD9K5NHLGK8x795xiR68wseWqr6MM6RD0KOCuNfJnDfSDpLhAkM95T3WQljG/v999/fvodnl3Fyzz33TFmiTEQfid2Y8fnnn1uh6rjwwgvt1xNOOMEMGDDAjB8/3jz11FNW6PKQUraFEi4Y/IHIBMZ8Np9AGJGRzEPsfk9lI8f/+te/bObqqFGjVHGhAOAvROTi18aLy31VCRwhsgfRPvpUggIumY0X75HoqXq9+YNScW+99ZZNItt9993t/5Nomy3oO//3v/9Z/y59Kr/70EMPNVdccUXW/obIL0pQE1Uub0YtRBLS6HBk3M8fPLr4CBG5bAbBAMBAvM466xT60EQGKEEtvs8fpcp4/pjwE13kGZToze+zc9ZZZ9k8Ecaf1q1bF/qQRESR2BVVslQcdthh1uj/5ptvmrp16xb6kIKK5HLdmWwgcHlJKMUTiV0/KjggevHKE+mV6M3v9Wel8t577zWvv/663Y5eiGRkYxCVguU7ysCwfId1ga8i92A94doT0UXgkngmgSRE4Ss4sDsbohcLGaXLSGyjX5SnN7dwfSlvSbCFKkDY9A488MBCH5aIGJp6ioyhRBk+KXyhzKQldHMPESMSY7j22BSaNm1qy4hJ6AoRLdFLyTKELqKX5xUBrAXU3IOdgSpARx55pP0qRCKK7IqMmDhxoq20QNmXe+65R0t1OYZakpQ9IlLEQKrEMyGiL3pJEuV5ddUbeGap6KCdCnMLtjpsJGy0REWac845p9CHJCKCxK5IGyo9IHSPO+44c8stt2h5LoeQ8ILAxQfIAKkSYkLECwIBJK0hfJmwsjEFNWFZkdHW6bmDakVvv/22rcVLsIBqQ0JI7Iq0+P77763QZavG66+/XkI3R7DcSTQIkYtdQZtBCBFvsBohcPHY81xjbcD6hdVBlVNyA7udsRVw9+7dreClNKYIG4ldUSHsNMOOM3iirr76agndHEHS2YIFC6zgJdmChBddayH8gI0oeK4Rvfh52RCIJXeiv3rOs88OO+xghg8fbjeeQPD269ev0IckCojEriiXr7/+2grd8847z1x55ZWFPhwvoSOmjBiJLBr8hPAb/LvsAuYmt2xQgQhmBy+RXdjgaMSIEVbwkuR71VVXFfqQRIGQ2BVlwjbECN2LLrrIXH755YU+HO8ggosvlygPAx3JZ1rWFCIMsCdRuYE+gC3d6QNIYlMfkF3atm1rBS82PHIhqMkrwkNiV6SEvcCZDZ9xxhnmqKOOstFHluFE9i0L9evXV1RHiABhBYeVHDy8rO7I2pB9nC3s6aefNieccIIdx7Ttb3hIvYhSfPvttzaie+GFF1qfE6VzZs6cabbccksJ3irCUhqbQsiyIIRw0K/K2pAboUt/y7bOjGl4eKnWwPW+7LLLCn14Io9IuYgSjBs3znYK1Cd01oV69epJ8GbRskDimSwLQohkZG3IjdBl3MIr3aZNGyt4sTQwjl188cWFPkyRJ6RaxComTJhgO4HTTz+9hJGfyKMEb+X59ddf7bWTZUEIkYm1AbGGtYEyZVRx0CpQ5YVuooeXsmTY9BjHzj///IIeq8gPUizCMnnyZCt0TzrpJLvPeDISvJXrcInkUlAeywIvDVZCiHSgf6XPZVMK+l12BOPf2kGx8kLX0b59e7vxhBO8Z599dkGOVeSPNYq0aXfw0JHutttudgvgO+64o1xBRnPh80QrJXgrjuYCA5R2PxNl8ddff5lJkyaZrbfe2m5AIEQyVBFAwOHlVZS3akI3kU8++cTsvffe5sEHHzTHHnts3o5T5B+J3cCh8+zUqZNp166deeKJJ9LqQCV4y0bRXJEpErsiXUhgo+91UV9FeSsvdB1YGnr16mVeeeUVu+Oa8BOJ3YBBrO633342KeLVV1/NKAlCgrc0iuaKyiCxKzJBUd7sCV3Hc889Z3NVSF7bcccdc3aconBIoQQ8wPbu3dusXLnSDB06NONsX3l4S3a07HnPi8QSBqDQBx8hRG5Yc801V20nPn/+fFvGcPPNNw82yltVoQtHH320rXO8//77mw8++MA0b948J8cqCseaBfzbooCdA4b87777zrz++uuVrg7gBC8RTAQvG0+EGM2dPn26TR5p1KiRqV27toSuECLnuF0XEXf0QZQrC22hNhtC13HeeeeZU045xVoZ5s6dm9XjFIVHYjdArr/+ejNkyBDz1ltvWU9pVQhV8NLJ4sudMWOGjbBQG1O2BSFEvqO8RHUpaUh/NHv27KD64GwJXcdNN91kqxJh71uyZElWjlNEA4ndwHjooYfMf/7zHzNs2DDbQWSD0AQv50fBdyIpXENFc4UQhY7yMuHG802U95dffjE+kwuhC/TjDz/8sP2dBx10kF25E34gsRsQL7/8srnoootsVHfbbbfN6u8ORfCSDc1gwvkyuKy//vqFPiQhhLBClz6YnAEm44hBH20NuRK6DnJPnn/+ebu1+zHHHGPzW0T8kdgNhNGjR5vjjz/ePPvss2b33XfPyd/wWfC6kmKzZs2y1g/2sVfmvBAiStAH16xZ0+YPkEdAP4xo84VcC10HFYpI3B4/frw566yzvJw0hIbEbgB8/fXXdknmnnvuMT179szp3/JR8HIOiFw6WAYRlfoRQkSZatWq2ZUnl7xGxYa4ky+h66CyDnktb7zxRspdRUW8kNj1HPZV33fffc0ll1xi+vTpk5e/6ZPgxfvGNWRpC6GrJDQhRFyS1+iH69SpY6sLUForrhHKfAtdR8OGDa3gvffee+0uayK+aFMJj6Ho+C677GK6detm+vfvn/doZJw3nnC2BZLQGCzYn17RXJELtKmEyDW//fabFbwIYCxYmdZVD1HoJvLRRx/ZbYVfeOEFW4tXxA+JXY8HUKwLRFXxHhVKaMZR8OJxY2DgGlLShyVBIXKFxK7I185rRHcRjUR8a9SoYaJOFIRu4i5rZ555pvn4449Ny5YtC3YconJEX3mISvHvf//bDqCffPJJQQVm3HZaY0c5MplJUGAJi0iIEEL4UpOXvo3+mGgvybZRXbGKktB1u6yNHTvW5r0wrpK7IeKDIrseMnDgQNO3b1/7QLZo0cJEgThEeOlU2X5T+82LfKLIrsg39MNM6imdiACO2qQ+akI3MTreq1cve/1IXIviOCZSE60WLqrMZ599Zk477TS75BIVoRv1pDXXsSJ08bORhSuhK4TwFfphEm6xbEWtPFlUhS4wKXjmmWfsRIGkbxEfJHY9Ap8ps87rrrvObncYNaIoeImq0XFRk5LOn61/hRDCd4hKIibpj9n2HAtXoYmy0HVstNFGZvDgweapp54yTzzxRKEPR6SJbAyewLJKp06dTKtWrewDGOXIZFQsDb///rvdS57MZG0SIQqFbAyi0P3xkiVLbPJa3bp17aYUhTqOqAvdRIYPH279u++8847ZddddC304ogIU2fUAOgmsCyyxDBgwINJCNyoRXurnEs0gktugQQOJDCFEkNAfk6NAP4jYLEQ93rgJXaCk56233moOOeQQu+mQiDYSux5w5513mhEjRpiXX345NpseFErw0qlSO5eIbu3atW0N3ahPDoQQItdsuOGG1srFbmv0j6w45IM4Cl0HieBEd7EPrlixotCHI8pBNoaYQ0boEUccYUaNGmV22GEHEzfyaWngby1YsMB25tTPJRNZiEIjG4OIWnukT8bmRbQ3l+IzzkLXwXUiyosVbtCgQQqeRBRFdmPM+PHjzTHHHGMeeeSRWArdfEZ4KRlDIhqzb6IXErpCCFEaJlwEA7B4YfUiEJELfBC6wHG/9NJLdrOJm266qdCHI8pAkd2YQkLBTjvtZA477DAvHrBcRniJVLAsB/Lnimy3WyZo7kVbY2LlXnyf9/ia/L6DfzPoY6tx9U6ZBPLi32W9+D5tmWfFvaJWL1XEF9ro4sWLzY8//mjFLzaHbP5uH4RuIl999ZXZY489bGkydi8V0UJiN4Zwyw4//HAbpWQrYF8GuFwIXupHJlZc8OVaifwJWdoQS5V8TRa2biXCiU6+lidQ3Qvccidid9q0aaZJkyb2e65LThbIZb3c8fB5fj5R/LoX7R9BwUvLrCITli5damuQswJH2a2q4qPQdbzwwgvm9NNPN1988YV9nkV00PYfMeTBBx80H330kfn666+9Em/Z3lqY7TARumyPyS5BGuRFKhCtiFn3cuKWF2ISoehetEcsN8lisipti7/PgE87reyqg4sgJ4pw92JS7M4JOF4nfBNfVT0P4Scbb7yxbZfUcadtVWWbXJ+FLrj8maOOOsq899573p1fnFFkN4ZLJbvttpt58803zZ577ml8JBsRXgqkI3SpGcn2vxrEBTBY0654MRminSAEGcwThV9iJDTXE8p8Jai5SHWisE8U+PztatWqWTHvXlwHPTsiG32q70LXQd/SsWNH0717d3P77bcX+nDEP0jsxgh2+erQoYM5/vjjzRVXXGF8piqCl2oLRCHokNn6V4QJUVkGaCdueSHqEHAIuURhV8g97qNQjYFrhfhPnAjwQtAkil8SO7l+Ikwqu1oWitB1TJgwwSaNU53hgAMOKPThCInd+MBt6t27ty2d9dZbbwWRZFUZwZttf5mIn7hl2Z4X7YbnBIGWKG4LKWyjKnbLE8CJIpgXYhex414Sv2HBhJFNFBCs6eRBhCZ0HSSqnX/++XY1lsRoUVgkdmPC448/bvr162d9usyoQyETwUvm8KJFi7KeOSziJW6ThVjUl+GjKnbLOtbkay7xGx7pVrgJVeg6Tj75ZDN58mS76VPUJtmhIbEbA77//ntbZuyVV14xe++9twmNdAQvIped0eh4VUPX76gSNhVeiK04its4i910xC8RdGq08iKSHrf7IdKfbGIXwwfesGHDUm03dKHrtqXfcccdbYnQ6667rtCHEzQSuxGHAQShS92+G2+80YRKWYKX96kDidClw43LdskiPbi/LKM7gcv/c49r1Khho/c+lNKKs9hNdS4M8NwrvoITvtwvn6rHiOLnk816mITS/yb2y6ELXce3335rdt55Z/Paa6/ZndZEYZDYjTinnnqqGTdunC1nEvoySLLgRRgQ0cWnS0dLREn4cZ+dYOJFBAmh5ASTb8+BT2I3+T4S9eUeklxLBNDdR16+3cdQ4T4T4aWqh4vwSuiWhF1Or7rqKuvfrVu3bqEPJ0gkdiPMs88+a8455xz7gNCJiNWCl0GUgZOBVELXj/vKJIYBkhfRWqK3iCJsKT5HBH0Vu8n3FzHkJjDca2wn1HDlHvt8f0MLRPC8MlmV0C15fY455hi7Cjls2DC19wIgsRtRGPwoMzZw4EDTo0ePQh9OpCDSR2kXRFGbNm3soCniCQKI+0h0HtGHwKWKBvc07vaEdAlB7CbDsre770R8Ebzcdyawodx331C/XD5cl/bt25s+ffrYZHORXyR2Iwi+xF122cV07tzZ3HXXXYU+nEhBc8W6sGTJEhvNZaDM1tbCIj9wz+j4WdomEoTAQeiEGuELUewme7JdRB/chEfJbfHBeXSZvNAv06YTPbyiGLYR3mOPPWz50N13373QhxMUErsRhFnf22+/bbcE1jJQSVyHSkfKtanqTmsiv/5NJimIXIQMS9gIm9AEXjIhi93kNkJCrpsIUVmD3boQviFfl6iTnIzGfaNfZhIjwVuau+++2/Tv39988803doIv8oPEbsT49NNPbUSXr9tuu22hDydSuPJidKjOo5uNrYVFboUckxNELv+PwEXAaBK3Gond1EviiCfaDVYXBC/tRtVWokVZVRcSk9ZcMrFY3ba7du1qx/f77ruv0IcTDBK7EQLBhqeHndIuv/zyQh9OpMDYz6YRiULXIcEbPbgXCBWELgIFoUIUN0SbQkVI7JaPWxFAUNGWatWqZduSLA6FpaLyYq4sWVl1eENm6tSppm3btmbw4MGmS5cuhT6cIJDYjRCXXXaZGT58uLUvSLCthoFu4cKFtkMtK7IjwVt4uAdk2hN9R6AQjUOYKBpXPhK7ma0S0L5oa7QtJlG6Zvkn3Tq6fI6d1vjKhj+a7K6GqO6dd95pxo4dKztDHpDYjQiffPKJneF99tlnZptttin04UQGvHuIWDrKirJ7JXgLA9ed+0T0HUGCCMGuoOufHhK7lZ9U8awjeDfZZBO1tzyR6YYRLNvPnDnTenm32GILReQTrgubTLRu3drcf//9hT4c75HYjQB02Ntvv705/vjjVZIkAZJViArUq1fPLlumgwRvfjtrIm3YSwDBgchV9CYzJHYrDysITLKo60rbow3KD547KrszGlYGBC8BCzZVkOAtaWdgdzV8vCJ3SOxGgEsvvdSMHDnSfPjhhxJn/4BYpXOsU6eOjdxkggRv7sUZ1hIia4izTTfdVB7KKiCxW3V41pl0scJAW0T0yj6TXaq6BTC1lWfMmGH788022yxnxxk3iOrefvvt1s6QblBHZI7EboH5+OOP7Yzu888/t8sZIjudogRvbkQZggKRS5IgIlebAFQdid3sQfY/bZQVB9om/YdEb+GFbjaCGL7bGVq2bGkefPDBQh+Ot0jsRsC+cMIJJ9jkNJHd5S4J3ux1xkRyWS5G5CIg2BJUIjc7SOzmZsLMpIwX0TLarOwNhRW6VbGn+c60adPMdtttZ1599VUrfEX2kdgtIJdccokZPXq0+eCDDyTE/hFVs2bNstciW4kMErxVu3YMcNQ3xodbu3ZtRXJzgMRubkUv7Zd2TCSR1Qj1AYUTupVJPA6FBx54wNx2222yM+QIid0C2heYwVF9QfaF3JaokeCtXLY7IoEJCFExyohJ5OYGid3cw25eiDaiilQLwdOra10YoZtJScmQoK/da6+9TPPmzc2AAQMKfTjeIbFboAxi7AsnnXSSTU4LHSdGGZBytduOBG96IAYY4PA+InKJhknk5haJ3fz2vQgs2jdRXtq3qofkX+g6mFAjehs1amRLk4WOszO88sorVviK7KGnvABce+21tkzORRddVOhDiQR4QRmEiOjmarBHsOERI4KAJxhvsCi53Mv2nkTXsSo0bdrURsAkdIVP4DVHvNEXkMQ2ffp0u4oh8i90gQkHGyrQ7zDpC50mTZpYK0OfPn1sOT2RPRTZzTPjxo0zHTp0sJtItGnTxoSO827laylLEd7S14MkHiIsDDr4chVhyS+K7Bau7RNVRNgxwaNCQOhtP59CN/FvkqtBhL1+/frBT7C5HnvssYfZc889zU033VTow/EGid08wqVmaYJliv/85z8mdFwZmnxn5UrwrrYszJ8/3/4/lS8Y8EX+kdgtLKzyIPCYeBNpZEUjRGtDIYRu4j2g3CS5AUy4Q+frr782u+yyi/nyyy9NixYtCn04XiCxm0eef/55c/7555vx48dbG0PIuM6N61CIAuMhC14sCwxqLN9y7WVXKCwSu9EAKxWTP/oGorysdIRCIYWug5wNxoTNN9/cit7QOffcc82ECRPMsGHD1D9ngfCmrwWCqMGFF15od0oJXejSseIPxbZAJKUQhOjh5bpTcJ8kCOcPIytdHakQxX7exo0b28kf/dOcOXPsxNB3oiB0gRre9MlMOAhChM51111nvvrqK/Pyyy8X+lC8QGI3T1x//fWmWbNm5thjjzWhs2DBAhvNomMrpNAKSfASNeEc8Sjii6OOcej+RCFS9QmIXRI0sTIwMeSZ8XUBNCpC14GdjQAICWs+98fpQKUQktUuuOACJatlAdkY8pSU1r59e/Ppp58Gn5TmkqGIoERFbPlsaXDRXK45gzi2hRD9iFFGNobogtWHSCNRR5bXo9Jn+Sh0k/tjouoNGzYMur+i9i7Jap06dVKyWhWR2M0xSkormRBF1i0dWNR2zfFR8BLNZaB2UXSWaUX0kNiN/v2hNi9WNLy82NDibv2JqtBNFHmsRLlJRtyvd1XAyrDrrrvar2w4ISpHuFOmPPHiiy+a7777zlxzzTUmZCjijgeOrP+oCV3fLA0MZNQupoao8yFK6ApROZiA0Ddg/WGFhCX2OHt5oy50wZUhY/me1cCQadeuna27e84553hrp8kHErs5XgIjKe2OO+4IOimNWTpClwxbfEhRxQfB67y5FMxnICMSFfIyoBDZguoMJHWy6oOXl2csbuIjDkLXgWUEwcvxhu5ZJeeHMmTsrCYqh0bBHDdQEh1CT0ojIQ3BhfCKOnEWvAy+lO5RNFeI3Ed5EWFUbYjLzl9xEroO+jBWA7GYxakvzlWyGqVLQxf+lUViN4dJaf379zf33Xdf0H4jBBgRbgaHuFyHuAleIucMuvgKuc6K5gqR+ygvE0qePexC1OiNMnEUug5WRbG+0cfFLZKeTY4//nib76JEtcqhBLUcJqVReeHuu+82Ift0GQjyvUNaSElrHBuDAMfGdfYpWzwUlKDmR7UTdv6K4gYtcRa6ic8IYwkRzkLVZo8CSlarPAr/5ACKQJOUdu2115rQfbp0TnEUulGP8DKAkbjhtthkxi+hK0T++wjEFyKS55E+L0q2Bh+ELjAJxL/LpIKqPqEnq2FnEJkhsZtlyNLt16+f3f0k5KQ0OlgGgrjvcx5FwctgSjSXiguIXGrnRi2aJERIOJ88RMXW4IvQddAHM57Q90WhHy4UVHb68MMPzahRowp9KLFCYjfLPP7441Z4nHzyySZUqEeJVzdOPt24CF5sCwymRM4ZXKNYxk2IEHHRR6wM9BPYGwrlEvRN6Dq4tvTD1A8P1YHJSsIll1xiLr300mCvQWWQ2M0iLK9gXbjxxhsj6e/Ml08XnyuFwH3pYKMieBm4+NusGDRo0CDYNiZElPuJTTbZxApMxC59IRPTfOKr0E3shymxGHL93fPOO8+OBSpFlj4Su1mE6guIkEMPPdSEiEvowkPKyzcKJXi5rnjViGbw92VbECL6toZGjRpZWxt9Rb42ofBZ6CZG0F3ptyjYRQrBhhtuaK6++mpz+eWXB23pyASJ3SzBLP6WW26xr1CFCJ0PUYw41NONi+B1ZcXcJhFxTfYTIjRIGMVTj+AkkTTXwiwEoZs4mWDSH6c6x9mGRDXO/cknnyz0ocQCid0sgcjt2LGj6dq1qwkRaukuWbLEetZ8r/GaL8FLNIhBkg6NKBF/TwgRH+gL6SuwNsyaNctOWnNBSELXwTXlPFnxCnUydcMNN9iEtVAj3JngtyrJE+yVzuYRN998swkRxBgdDhHdEDrZfAhe/N8kohHBIDokf64Q8fbxsvTObpJs/pLNxKIQhW5iH0xfybmHyOGHH253mLv33nsLfSiRR5tKZIFTTjnFRjYHDRpkQsRt5YhfOTQLRy42niD64yYPZB8Lv9GmEuFAYhW1eBGkiN+qroKFKnQT4dyZRDRp0iTIoMA777xjjjjiCDN16lSNF+WgyG4WtgUeOHCgXU4IEUQ+pcaovhCa0M12hJeBi9q5dNxMHNRxCeEX1apVs5YkJjjYGqriN5XQLYZkaEow0m+GGLvbe++9TYcOHcxtt91W6EOJNIrsVhEqL7CM8MADD5jQoKOeNm2aTRRgp7SQqWqEN3HgQujKnxsOiuyGh0s8pVRjZXY/lNAtCUEGxiLGYh8rAVXEZ599Zjp37mz7EVYMRGkkdqvAJ598Yrp162YmT55sI5uhEbJ9IZuC1/0cSQYue1uEg8RumPDcE41kdYznnqhvuj8noVua0O0M+Hfxhj/00EOFPpRIIhtDJaHDueyyy+we1SEK3dDtC9myNBDhIcGRCA/Lmxq4hAinvyASyaoY/UU6GfUSumUTup2BzayeeuopM2HChEIfSiSR2K0kb7/9thk7dqz517/+ZUKuvpDp8pvvZCJ4+R6foWNWxQUhwuwvsIHxwsNLEKEsJHQrhskD1RkIxIRG8+bNzQknnGCuuOKKQh9KJJHYrQR0OmwLjNBl69bQYObMkluI554twet2VmLAwgai5WshwoVkVFbJ3AYyyUjopgcBAwQvY1SIO4tdddVVZsiQIeb7778v9KFEDondSvDuu+/aKgxnnnmmCQ1mzEQfZF+ovODFssB7LLnxGd834RBCpLcMz6Y8CDU26HFI6GZGyHYG2s9xxx1nN7kSJdEoWwnYPKJv377BZX1iX6ADkX2h8oIXoctyZfXq1W0EQhMGIYRjww03tCs9bDzx008/SehWkpDtDJdccol5/vnn7aZEYjWqxpAhX3zxhdl9993tNq61a9c2IYFPl+V3VV/IDFdtwfnxSEih7egaClA1BpEMyWpMimkP9B8SupWvztC0adPgnqujjjrK+sDZ2VUUo8huhrA8wI5poQldymnhJVM0MnO4XptuuqkVuwxi+PN0DYUQZcFqEFuFE+FlBVFCN3Nq1Khhc0sWLVpkQoNKUY8//rgV+6IYid0MmDhxohk8eLC5+OKLTYj1IKnhp043c5x1AT+Vy7oOMXlCCFExzrrA1sKtW7e2/l0sDaJypd24fgRrQqJdu3Z2k4l77rmn0IcSGSR2M4Dt+FgeYEkpJIjoIs6ITorMwPaBuCXKgNeZ3W2ysbWwEMI/kj26VLyhLCHvJSatifQgsstKWojJav369TP3339/yuoeISKxmyYU/n/mmWfMpZdeakLzE9LRItRUNSAzXHkxktG4fkQaKrPxhBDCf8pKRsPO4JLWJFwyh9U0+mKua0jssccepk2bNubBBx8s9KFEAqmXNLnzzjvNAQccYFq1amVCgs4XYYZgE5lNEpggUQLHCV2HBK8QIpGKqi7Qj2CDIkm4vI0nRGkI0tAHc33pl0OL7v7nP/9Ja3c+35HYTQMM7g8//LBtOCGhpLTKwRbAc+bMsQXOy6pHLMErhIB0y4tRlow+g40nJF4yAxsZ1zW0ZLX999/fjkFPPPGECR2J3TS49957za677mp22GEHEwpKSqtamTG+Eokpb5IgwStE2GRaR5fKDCzLs2pEAptIj1CT1ThvgnS333578OOL6uxWAEWpGzVqZP7v//7PdO3a1YQCncKPP/5omjRpIq9uhhMEipkzcBHZzUQg0wln8nMi+hF+BpjEF++5e+66XpZWWQlgckQ9UDdBch5v2oN78f3Ez4j4UpUNI/DvMjbxc9rgx2R03YiKc91CeYbod1q2bGmuueYa07t3bxMqErtpeHVfeOEF8/HHHwfzcDD4Tp061S5/sPwj0oMlMiYJTI4yHYAkeOP3jBBZSxazycKWPgNx6sQqE0cnYoGvfI6laSp18P1EIcz3+FvJvzNZACf+mwx0vobSX8WRqu6Mxs/j33X9RWibJlQWnh/GNurkU+kiFB5++GHTv39/88033wQbvJLYraA+KpFNynf06tXLhALRSc5dO6WlD3UwGbwQuoiNyiDBG21hy31xL54P7g+TmrJEp3uvomcokx3UUkWLk19knjOgYY+hLfKVF8eq57nwZGsLYH4PKwK0H8qThSpiMoXrToSXsT2UScJvv/1mz/ehhx4yPXr0MCGi0bQcXn75ZVv2pWfPniYUGMSJTjZu3FgDY5qQHc3gxeSgskI30cOL4MXDK8GbfxAOTtAyQLDkiXjkPjjRiG+Sr4W4NwgaxFF5AglBnCjOsSPxXPOzieJXAji+Qhe4b6wGUMebPoP/172sGFYrCU7wwv8cAtWqVTN9+/a1+Uehil1Fdstht912M4cddpi54IILTCiwnOpEl6gYRMWMGTOs5QMRlA0U4c0fCEMELROWX375xYpCBGByVDSX9yCTyG5lSRTAiV8RwEzoKS3IS20tHkI3EaL59EEsy4ci3qoKeRUk+TVt2jSYNr9w4ULb7r766ivr4Q0Nid0y+OKLL2xRZpaJatasaUKAAZBOkw5ASQ/piZTp06dbkYsHLJtI8OYOxAHC1glcBJ8Te4WI2OZD7JYngBn4uRa0NQS+uxb8vyKF0Ra6Du4dq0EEKZRnkR6IXcY5qjSEwvHHH28nRUR4Q0NitwxOPvlk2yENGDDAhALLYQxwFOAW5cNjQ2eJGKioxFhV/oYEb3YgYougI4M9aqKuUGI31STATQD4Sntz14hNDSR8oyl0HbRt+gv+BpM2UT4hBnc+/fRT061bNxvEy9ZKZFyQ2E0BHjf8lzQMttsLgRCXdapCYomxXAoUCd7KXzdnT+CF7xbB5sRblAa3qIjd5Kivi/jy4t9sauCuX1SOM+rkS+gmVoRhIyASZdVXpGfbA/zOodCxY0dz3HHHmbPPPtuEhNI3U/Doo4+anXfeORihS4eMn4cNJNRBVgwJfAxeri5qLtHGE5nB9WGyOm3atFWZ6lhMEJJkrNeqVStSQjeqOGsHXvRmzZpZoUYEfPHixWby5Ml2AsZkQrGS6Ahd2HTTTW1fgYjTvakY+ga32hMKZ599trnvvvtW1fwOBYndJBgcH3zwwaBmPURuEAmIXVE+RLuI6hIJyNfOchK85cOgThtG3E6ZMsUuw5Oog0hzHkaVZapa+6PtcU0pX0TUkPewPeFZRwDTb4rCCt3EvoL7QT8lyoeJLzk5IW0jfMQRR9hndvjw4SYkNAIkMWzYMLvkedBBB5mQOmUiAhIE5UO7QFDhaWZJN59I8JaGAZ1OmyLxFNhHUCDGEBf40dSecwNtkIjvVlttZSfIRMZctDekCFnUhK6Ddo8Nj/vCKpQoH8Y+ghi8QqBatWqmT58+QeUjgdask6Do8imnnBLMcj7+LjrnUCpOVNU7i8gt1LVSHd5iqCBAjUzEBB03S5FEb5VAZfIuqsjs5uXuCQk/lDLDLoINIrR7UmihmxixZPWJybkrnydSQx/KpI37Fso2wqeeeqpp1arVqp0bQ0ChjwRYliOyi9gNATw7LN8gFkJ4wKsCPlCiqUS0CnmtQo7wEnlxS+e0XTy4LKkTxVX7LSxMOpy/lwkhOQBE3Im8h+INjIrQdXAfEHEImlDuQWXhOrFyhx0qBJo2bWq6du1qHn/8cRMKErtJiWn77ruvHURDgCUuZrWqy1g+eEARu8yAo7A0HprgZWkckUu1EM4ZQcW9IIIoogX9CcvCDKZMohF+iF76Gp8TpqImdB3cC+6J/LvlQ7/OtSL443M7TeT00083Dz/8cDB++8KP3BEBwYDYpQGEADN9oi484IqKld8usA3g043SUmAIgpfauESlWBoncugEVIjWjbhB+yTiTuSdZ8dVyMBH6puYiKrQTewniFhiWRNlgx0H4RdKdPfAAw+058tqdghI7P7D0KFD7SBKZDcE6Jgpm4WvTpTv0yWCGEVPs6+Cl/MgEoU44hwRuQgmidz4il7uIT5e7itt1ZdkoCgL3UT/Lv0E1x5vtSg7uoudgYmZbxOyVNCf4t0NJVFNYvcfCOdz40Mols6DzAPNg62obtkQ+Sa6WGifbiiClygDwoFlb/xzjRs3tuemurjxh3aK2EX04iXFkoI1Jc7VG+IgdB0ENZiwy79bPlwj+h5fJmMVccopp5i33nrLPou+I7H7z25Y77zzjjnhhBNMCLCUCKFtF5gJFMzHv4U3NOoToLgLXmepQeQyyOCZp3QS1gXhX/SMer2IXu4vFhUEGJPKOBEnoevAAsT1J3lQpIbrw6SMYFAINGjQwCaqPffcc8Z3JHaNMYMGDTK77757EIlpiuqmJ74YgBkc4pIEFVfBi1jAroCfkONHOMTlmouqLaFiTUH00nZpAwQd4pAsE0ehC1xnJu8cdyi+1MpGd1lxIOCRCtrolVdeaWt601eRMHv99dfH1vrQu3dv88wzzxjfkdg1xt7oY4891oRSWQAhhBlfpIaBjMGYGX6ciJPg5dioAYrAIdKHZSHEuqyh4/yk3H/8pJSVo4+KKnEVuonXm0kGm7DEYWJRCOj7EbysNqXi1ltvtbussuXuuHHj7L9vu+02c++995o40qtXL7vz5DfffGN8JnixO2HCBDN27Fhz2GGHmRBwUd0olNCKIiyjuyhjHIVXHASvi+YC0REmXnG81iJ7YGlgZY2+iUkQYixq3tK4C10HzxvXW3aGsiHQQfQ7VULfhx9+aHdYPeCAA+wkDe3QvXt38+mnn5o4Ur16dSt4Bw4caHwmeMXDDabRRjHbPhdCjoc3hHOtDAyuVF8g0hjXgSzKgpfjwB5CNLdu3bp2SVUVFkRyEpuL8jIhikqikC9C111nkm7J3ZCdoewIODktqaK7u+66qxk+fLiZOHGi/ffXX39t3n//fbPffvuZuHLssceaZ599NnITzGwStNilA0Ps4lkJJarLYBL1hKtCEVf7QhwELwMr4oXOlGiudj0TZYGQRFDyHFK1gclRIQdhn4Ruophjwik7Q9lQg557TnWGRC677DJz1FFHmZYtW9rruP3225vzzz8/1lbIvffe204w3333XeMrQYvdjz/+2M7c9t9/f+M7GO6Jkvgg5HIBPsE42xeiKnhdNJdBFa9g/fr1Fc0VabVdLA1Eeem7ChXl9VHoOphw0jdod7XUcK9Z4k+O7r7wwgs2SEYk9IsvvjBPPfWUueOOO+zXuLLOOuuYI4880utEtTWK4ppCmAXOPvtsW/KGGru+g+AgostsXpSEqBGDKYOrj5MBtzkGooEBO19ik2guIpeMZdqd6uWmhsjapEmTzNZbb61VlzLa708//WRLAeI3dSW08vF3fRW6DqKW9H1MirVtfGnoMymPR8UF12/iLSe627dv31Wfu+GGG6xQHD9+vIkrn3zyidlnn31snx2l3UKzRbCRXR5ySo6FYGHgXBEePgq5bMCAhhDz1cuc7wivK92WGM2V0BXZjPLmejOKEIRuop0hLmXf8g19JpP1JUuWrHqPFYbkyRaT1Lj7XXfaaSc7kXz99deNjwQrdtk1ZIMNNrD1dX2HB5Vdi3ztsKsCtRS5PlHeJS1OgpeJFb/f7YCmSgsi215eJqW0MYRoLghF6CbaGajOQORclIYgEWOEWwTv0aOHufHGG60opFTeK6+8Yu666y5z8MEHmzizxhprWN+xr1aGYG0MRx99tB2Mb775ZuMzzDapoUfmO4JXrIamzxIV14UZbQjk0tLAxIGyUVxPokUqb5cesjFkDitVtGOECNVTsjWhCk3oOrDzETFv1KiRl0vYVW0T7O7IGMHEgLbHphKIXMq3MbaiJ6666qrYt5dJkyaZbbfd1j5brKb4RJBil8bKYExdPG6sz5B0RRUGMuAVYSsJs3V3bUISZrkQvLQzbAsMCAgQtbX0kditHGSPU62BqCSCo6rPcKhC18G5s0TPuev5LQnjBEnMXBvf6dixo+nTp4857bTTjE+EM8InwIysefPm3gtdILFD4qM0LOPTueMpDUnoZtvSgEAgusGLfda1DbXIF4hcIpGsXrFCQ3SysoQudF2pLfqCXNlD4gx2LFaucu0VjwK9e/f2coOJsEb5f8CTEkJiGg8nAwBLL6Ik+NMQe5SWCZFsCF4ikkTWKEyP6JBNRuQbViXIjif/AsFbmfJkErrFMOln8s/EVclqpdsZ42hiopqvHHnkkeajjz6yz5NPBCd2iXSOHDnSHH744cZ3eDB5QLU0WnoSwLI7VpaQo5BVEbwsIdMZ8jsQuqEKBFF4aIM8y1hoZs2aZfv4dJHQLQmTf/oDJauVhsRI2onvE4E6deqYTp06mVdffdX4RHBid9iwYWabbbaxA7TP8EDyYPpaTquyMLhRZofl9tAHtsoKXiK5CF0GRsqKaTIlogB9HVFehBr+8YrSUSR0y544ECgJYck+EyhBRhsJwebRs2dPM2TIEOMTwYndwYMH2xvpO0QuETDKrC19XZgI4E8TmQteombU0KVUGxGAkCPjInpgZ6DKDqs3RHnLqn0qoVs2XAuCAQQFAsxfr3BClViGzFd69OhhRo8ebcdLXwhK7FL7880337Q30md4EGmkiuqWhIGPqE++dmDyTfCybSYCgeiZfOAiyhsluJU7BG/ysrOEbsUQDGC8ZBVHrIZ+j+vie9S7cePGplWrVnYl3BeCGvHfe+89O/Pv0KGD8RmiGjyQ2v6xdFSSRANdl8wFL6V3eCF0Wc4TIsowmaU6CF8TBa+Ebnpw3RC8XCvfo5iZXhcqM4SQqNajRw+7Eu4LQYldbtyBBx7ofVSPqC4PpO/nmQkMdog1orpaek9f8DJpYsAjqiuhK+IE/R+ecia4iW1ZQjc93MqgT0vZ2YCxNYREtZ49e5o33njDPjc+EIwaYnYagl+XpXo2zeCBFKtB6CLUVB4rfcFLHdPvv//eCl3EgfzfIq6CF2E7btw4u7ojoZt+P8DudFi/yvI+hwj9IO3Hd4vHjjvuaMeADz74wPhAMGKXQZsM3W7duhmf4QEkkkEjFcUwM2WQC2VL4GwNdHgfiV7w/6q4IOIMfSK2HMSvVrzSB8sX1y6Tcm4hQDDJ94j3mmuuaVfCfbEyBPPUc8P23ntv75dhWV7BRK+l+tUQmaDTVmQys2tGZ966dWtbYqyqO60JUQicR5fVLkpOkrPBRii+L0FnC8YRggSsjOmarYbxxOXG+EzPnj2tdvLBtx2M2KVmnO8WBsQI+3crU77k5gdMAFiOE+mBbYFIDh5dJgjZ2lpYiHySnIzGatcWW2xhI5WpqjSI1GD94vlH8IpiWPUicMYkymf22msvM2fOHDN+/HgTd4IQu9QL/PTTT21I3md48JyfSKyOULLkpGuSHohcrhmZ7C4Sno2thYXIJ2VVXaAtI3ix5RDhlRc1PYju0jf4HsnMBIJKvm8wscEGG1jB68MGE0GI3ddff93ssMMOdmeYECwMohhqIeJh1gYS6bcfV0c32e4jwSviQkXlxVzSGm2aqJUPS7S5hv4AOxOrPuXB9ezdu7ftc/mZNm3amM8//9z4amVg5ZBXCFaGuBOE2A3BwvD7779bcacasquhYyaqy5KTKB/8ZyRwEvUqy9cuwSuiTrp1dJ3gdeXIRMWwqxr1Zct67on87rbbbra/ZfMmksLvvPNOU6tWLeMjrA4wAfA9unvggQeajz/+OPbPyZohDOJvv/2292KXBw5vFX40USz+sXUoqlsxDF5EZLhWdN7lIcErokqmG0YgVrDrIOB8z6zPBkyCWdYuqzLDrbfealeFnnjiCbPTTjuZJk2amO7du5tmzZoZ360MPq8O1KtXz7Rv397W3I0z3ovdd9991/qNyMT1FR40WRhKR3WJciuqWz54FhG6DGJEbtJBgldEjcrujMbniPCyqkFgRJQPE2LEbqrkPpa6sQsefvjhpk6dOmb77bc3jzzyiPEZggP0ob63nQMPPNDaQeOM92J35MiRtrauz6W4sC8gOCqKyoUCS5NEahTVrVggkLzJ18033zyjZ0SCV0SFqm4BzIoYAREmfUrAqji6S1WLVJHwqVOnmgcffNBsvfXW5q233jJnnnmmOffcc81TTz1lfIV+kKCK71aGbt26mVGjRsU6gu292OUGde7c2fgMDxoPnIqlF0PkgQFMG2tUfJ0oVUdkqzJtR4JXxF3oOvCV0mcgeFWhofxnnhUgVs6SrxP/Zrn7pptuslHd0047zZx66qlmwIABxmdYUcUyF2chmM5uaiR7swthXPFaHdEAyQTt1KmT8RUeMM5TiWnFsLyGB09R3fJB5CISELpVsXpI8Iq4C13XjqnWw1csDT4Ll6rCCiJ+5+RoJv0Am9Ak0qpVK9sv+B7tpt3Qp/rKuuuua5MPCR7GFa/FLns6N2rUyHaEvkLZE2bUeC5FcbQS4eX7TnlVTd4jgoV1IRvXSYJXxFnoJldoWLFiRYUltkLGRXfZZCJxUoAYmjBhQonPTpw40Y7Bvl8PJgA+i11ghVxiN6KEYGFgaYHlN1kYipfRELuK6pYf+aaYfs2aNW1ZtmwhwSviLHQdVLOhQgNCjr5VpMYlQyfuIHbBBRfYElXYGCZPnmyeffZZ8/DDD5u+ffsa30Hs0l58XhHo/I/Yjes5eq2QQhG7SkwrhsGPwUpR7tTQSc2dO9faFkjIyTYSvCLOQtdB+2XVg2fF9w0DqvKs43NOLEOGr/OVV14xzz33nNl2223N9ddfb+6++25z7LHHGt9hzCGQ4HN72THmvl1vxW4Ifl0yh3m4iOyGDoMgXl0ilj5X3qgKDExYGNg4IlfXSIJXxFnoJkYu6UvmzZsX20hWrmFliEpAvBJLVI0dO9a+hygiQS0EWFllHPZ5NWDdmPt2vRW777//vvd+XR4sRIU2kiguv4aQy+bSvE9wbRAKCFGSS3KJBK+Is9B1bLbZZvbvYmkQpaEfob8ta5OJ0HBWBp/p3LmzLecaR7wVu6FYGFSFoRg6XDpeeZdLw4BNhIpIVb4sHhK8Is5CF+hLsDMgdhOjl2I19CncFz3fxfWaWWn1uVZz5xj7dr1VBr6LXZKxyBqWX7d4u1tsK77uwZ6NiQDXKBc+3fKQ4BVxFboOqpVQeUDlyFLDs83L900V0oEVVq6Fz1UZdtxxR3t+33//vYkbXopdHrwxY8Z47delwZFolO/OP4qwmw+Dkq5F+faFQkS9JXhFXIWug+ousjOUDUEG8iU0GfDfyrBujH27XordEOrrqgpD6cQ0UXj7QiokeEVchS7IzlA+jENUImClMXRcvV2fd+HrHNN6u16KXW5Ely5djM8DgcRuMXSwdCzyLkfHvpAKCV4RR6GbbGdQdYbUkwHyJVhhCx3aKiuuPlsZunTpEkvfrrdi12e/rosuaJewYgsDHa3KjZW2LyxatKhg9oVUSPCKOArdxOoMIDtDaVg9Im+CCG/IuN3UfLYy7LDDDjbI9N1335k4EY1RMMtC8IsvvrC+El9h1kjmZ+gCj46VDlblxlLbF7guUdtgQ4JXxFHoJrZd2RlKw72qVq1aiR3VQoWxmTE6bpHPTO71TjvtZD766CMTJ7wTuxS0Zkm7cePGxleYVUVNxBQCZs+ukxUl7QtMBKJgX0iFBK+Im9B10GZlZyh7Iw5ZGYpXXOl/fS5B1qFDBxtUjBPeiV2qMHAjfI164k9duXKlxO4/VTcU1S0JHSyigYSaqNgXUiHBK+ImdJPtDIsXLy70oURO7BLx9lnkpQP9Lv2azwl7HTp0sForTkR3NKyi2PUVOhN2rsEEHzJ0qHQmSkwrCT5drkkcJkMhCl6EHefJc0z7ZbmTFx5rvvIek1nat88Z3XEVuq7d1qlTx4rd0D2qyXVm6XdUc9fY6+C72P3mm29iNbFZ20ex269fP+O7hcHXyHW64A1juSh00Z8Iu/cw0DRp0sTEBSd4WRZG8CJ44r79NQIO8YqgdZEuBC4vxBHfJ/rDpJXz598I3YULF676txP+fIbr4Sa4WHaYHPA119s+55o4Cl0HfTD3AMEbVbtQoaK7eJqxeoQ8RtE+nNXFx+uw1VZb2eeVJLV27dqZOBDvUSXFYP/tt996HdlF7NKhhA4DpGrrlo7qYuuIk2jwQfAiYBGrRGQRt/RDDHJudykGPs4n8ZVoMXH+PiYpTsDy87zvRDIvt5qBwOLf3Gf3N0iK4d9xGVjjLHSB64zIpb3SD2nSXQyrSgsWLLDPAO0yVBJ9u3Fr2+lA/9W+fXsbXIyL2F3Tt+Q0yn7EKbKVCfLrFkNHyksWhtXQLkjYY7enOBI3SwORW0Qnxzp58uRV5agQPmxo07x5c/u1bt26NsrFBJXnloEvHS8118NtP0qfxu9FXDVo0MBGVZo1a2aX0vl9CO3p06ebqVOn2ugwgjjKyVNxF7qJgoZ7k0kpsltuucXe2/PPP9/4CG2baxK6lUG+3egRn/BJGnDhmW3EJbpRGUEjv25xVJcONe7LuNkWD4iqOLeNqEd4idKwWx8WGv4f8cqEi2PO93Xn7/FyG8swEUb0MuGZO3eu/Tffc+XnotIn+iJ0HUxApk2bZp+9is7ls88+Mw899JDZbrvtjM8wsZs/f769NlFpd4X07fq6AtmhQwdzzz33mLiwpo9i11fk1y0GsaGo7moQOUS6GXDjTtQivIgz2tusWbNs5JTrTDY+0dWGDRuaWrVqRWKCQSTJCW+ivhwbEwWEL8dN9DEK19InoQucAxMKzqs8mIQce+yx5pFHHrFtxmew1HCvQ69F7MRulFdZqip2v/7669gkqXkndn3364ZuYWD5mIeLDlWsFhDYF3yJdEdB8OK3w6bgrAEsWTdt2tTaCIhcRflac/04XmwOiHIibEyIpkyZYqPmhRAhPgpdB88eYpaVt7Lo27evOeCAA8xee+1lfIf2R/8c+gYTvtfb3Xrrre1z/P3335s4EJ01wipCxAXPrq9il2VJBilEQMgwqCD4oyw28gkDCm3Dt6WyQlkauJZYFYiE0pEjFImYxnU1heNGnPOij2TDkRkzZthzIkKdD9Hps9AFIvtEazlHzi+ZQYMG2QL82BhCIVMvs+++Xd/avDu/7bff3gYZ27Zta6KON5FdqjAggljC8xH5dVeLXedTDJ3EqG6UN5CIQ4SXa4nIxX/JLlD8XYQLIjGuQjcZSmWx2QgRas6Jc8Vbmevr6rPQdfAMEowggp4I9pfzzjvPDBw4MKjqBER2WYXjFTIh1NsdE5MkNW9GSGbOviensSzi6/mlA0tCXAeJ3WIQZ7QHn3eRy4fgZQKF8CMSRSSXrcZpY74+a0yYuaacJ9cTqwaCNNubWIQidIFABIKX8030aCIEsMEwNrmyc6NHjzb9+/e3/+/rphRcD4Qez1bIcA3Ks7fEnQ4x2jbYGxuD737d0OsWAh0n0anQo9vAgIo4o7SVr6Is15YGhB5ChGgcS/pYQXy/lonwLOFBZjDmOiBKuc7ZyAsISeg6sDJgE6Gfcgm03bp1s/a6RE466STTsmVLc+mll3ptx2LCiM3Kh8TZqjxjeHaZ1Ph4rzv8k6RGXxqlyjleR3Z9F7sskUns/qzEtH9gEEGYhRLlznaEl+tHNJdoJnW5ESohCd1EWDFCkHINZs+ebTcFqEqUN0ShC1iJnOB1IHq33XbbEi/6MKLA/L/P0DcxkfI1ep0OCECCM75WpmjevLkV8ePGjTNRxwuxS+fKxfa183C7J4Usdt2WqqGIu4qgUkBoAi0bgpefoRwXXlWi4vXr1498RCJf15YIHNYGBmYmApXxGoYqdB1YihB4rMSFDiLPbXoSMvRXvordNddc07Ru3ToWFRm86OVZ3qRj9jU5jY6TjsPHZZB04f667NbQYTAl8cNnr24uLA20IYQubYhorkRuaRAnXFOik0R53c5t6UyqQhe6QJsiqZHrRzJgKkaNGmVCgeAEK3Ihb3FPf+Pz5Kd58+Zm4sSJJup4EdnlQtO5shznI7IwFG+cwPJfSJHMsmAgReiGOvmpTISXZD4y41k+VjQ3vSgv2x0jVBC9FS1FS+iuhhUXKnoUehOPKECfTd/t68YK6fp2fU5Say6xmz+40FxwX5HYLY5mhr6hBmBnwW/q+y5M2RK8DLJ4UBFibsczTZjSH6QRvEBt3rLKSEnoloQ2SeAFwRs6XAf83yGXIKM9uCQ1H2kusZs/uNAtWrQwvhK62KWT4BpI7Bo7gHIdQhcU6Qhe/k00F/sCok3tJ3NYPaBiA8vRCN5k/6WEbmqYVLGaEHJEM3E3P59rzVZECElqEydOjHxb90bs+hrZVXJacVTXdRghQ2eC2PVtt7RcCF6eGcQZYg2hKxFWtWvM1sO8sDS4iKWEbtkwOeD6hCzyQtlYIXTf7tZbb20ndosWLTJRRmI34ig5rTixSFG5Yt8yA6gqUpQveGkvfMUvuMUWW3i5u1whwCdOlBdbCL5xCd2Kt2lGBISOE7tRj/zl2hLka2S3evXqtp+NupUh9qMAkZwpU6Z4K3ZDtzCA/LrFMHAiOOQ5LVvwsgJAEX/aSwgbbuQbJhAk+E2fPt2Wb5PQLRtWYEjwCz1RTb5dv8uPxcW3G/uUZDpdIjd0uj4SutiVX9esWpYnsstSchyYPNmYESPYCISZvzFduxqz1Va5/ZuICgZUImpEkmg7qrqQm3rXrk/iOkvspobr4hLVqAISKom+XSKcIcLzQt/k605qzSV2cw8XeKuttvKyATkbQ4j1VB3y6xbDcnEcEtNmzTLmqquMefddhBBFx41hM65bbzVmzz2Nue46Yxo2zM1kAOsCO1ZRF5aoYza3FhYlPbrUNGdygYcXMRNyH1VRdBcvI6XcQl5lcFaGUKvI0AfxYjz3MXDTvHlz8+GHH5ooE3sbg89+XQYXBvGoC5xcIr9uMZQbi3phdoTu0Ucb8+abZPEbs8UWxtSrV/yVf/M+3+dz2YQl0jlz5tjoEZFvVnqyubWwSJ2MxnOJpYGJRegJSOX5GWl/viYnpYt8u8WRfl+tHM1jENmV2I0wCF0IOaqJhcHXzUIyaQcMlvglowwRXewLbByFLneBLL7yb97n+1dfnb2/yeCJ2CJqxo5VLnqWja2Fhamw6gJtkgkGkw3XX4nVMPHiGuHdDRmeQyalIbcR38XupEmT7D2OKhK7EYYHA6Eb6vIXg2zonmVgoOQaRHk5HhGLdQFRW9Zh8j7fHz26+PPZYPHixTZiRIQxueqCBG/VSae8GEv12EewNER5sCv0lrkhw7Ppc0WCdODZ8VXsN2nSZFVd86gisRtxsRuyhYGOgcE21KQGBwlBUS83RjIaK9k1apT/Ob7P50aOrPrfRED8+OOPthxWWRMBCd7Kk24dXa4xlS8QNPPmzQt6qToVRHZZmfFV6KSLxK6/kd11113XCt4oWxliLXaJ6DCToKixj4QudukY6SBDjWwDkbI4iF0CVwRWK7pVfJ/PLV9e9Wdj7ty51rpQUeRfgjdzMt0wgmtMdJ1nlmi7WA0TMdpe8u5zoeF7+a10xa6vk8HmEfftxlrs4hOjARFV8BGJXVkYGCCxskS9HaDFWcGuqB/n+3yuoghw+b+jyEYQqQCQbtKeBG/6VHZnNEQdxeWpPhCyqEmFrAyrdxHzVexVhMu98bXv2XLLLWVjyBUMeAxgvkb+JHYldhkgGSij3sapo0vRjIoitnyfz/H5ysLuXQwYlBjLBAneiqnqFsAkk1Jmi6TB8kTNzTffbHbccUfr9SXBrVevXmbChAnGV3iGmbiG7GlmlS7kJDX6HwSvr1aGevXqWU0WVbwQuz5Cp8BgHKrYVXJa8TVwYjfqsGEEdXSXLSNykfozvM/3O3Uyplmzyv0dBgrEGM99ZbYBluDNndB1sIECvws/dVmMHj3a9O3b13z88cfmnXfesQKoe/fu3i71cy2JfPt6funA88p1CDnq77Nvt17ExW5007vTAM+er2KXB4LOwdfNMipCyWnFkW2IS+k1NoyYNKm40gLuAqwKBKQJ8BHRRegiiq+9tmr2BbL/q1J72Qlefpc2nsiu0AX6LbzUXFsmaqkmrMOGDSvx7yeffNJGeMeMGWP2ZNbkGbQ5othMXvkaum836jXDc4XEbuGIfWQXj5jPFoaoL1/nCiWnFVsYyOSOyzVgZ7TnnjNm//3Z5pnJKM9o8Vf+zft8v7I7qFXWvpAKRXhzI3ST7QzpVmdgS13gZ3yFZ5nIbqie1UTfbqj4bGPYYostbAAyqsQ6nEFH2rJlS+Mjoft16RBDjuo6scuScJxAyD7+eHF0l/JiRHQJZOHRrax1AdhTnsSnVPV0K4sivLkRuo7NNtvM7vyHkCUaX55l6/zzzze77bab2XbbbY2vsBrBuYa8UQ5itzx7i+/4HtldvHhxZMfuWPfszCK6dOlifCT0bYLpEEL263L/uQZR3zWtLLAr8MoWDJAIhGxfj5AFby6Frru2CN6FCxfaZeuyJil4d7/99lvz/vvvG5/heriqDKGKXSKbrKIweQ3Rouc2luDZi8uKXbq4rdpJTm3UqJGJGrG3Mfjq2aVDCGXQTUXoke2VK1fa2XGIA0IyDA5YGLJhX0hFiJaGXAtdB/5U+jHuXyrOPvtsM3ToUDNy5Ei7OYjvIHJ5tkOFtkCfFmpFBjem+9jHrLXWWlbwRtW3G3ux66tnN2Sxy0AcutgNvRJFItgXEE25vB4hCd58CV13XZmkEJknmpd4DAjdV155xYwYMcLuvhQCodea9X0pP53nAVHoa/+yRYR9u7EVu8yOlyxZosiup+fOYOCKcIeIxG4xCANEGcvhuSYEwZtPoevAepLs1cS68Mwzz5hnn33WTmRY+uTle9Qz9FqzvidppQPjuo99S9QrMsRW7HJBaTT5GATzDZ1hqJ4moCOkQ8xWIlLcUI3h1SCQ2CktX1F+nwVvIYSug+iuq6YBDz74oE1c69y5s73e7vX8888bn1Gt2bAjuyCxWxhiqya4oGwT7KMgcst9oUZ2Q7cwqMbw6utANn++y1H5KHgLKXSdV5WXKzHG8aR6nXjiiSaUWrOhIrErsVsIYqsUQ/Dr+patmS6hV6JQjeFisCmxBF6ItuCT4C200HXUqlXLRndD9qtC6LVmndgNtR34LHa32GILid1s4/PuaSH7dSH0yK4sDMVWHsQuAqlQ+CB4oyJ0gbJbXFOi9SHjIruhij3aoLPqhQhju6/nXq9ePSWoZRuVHfPfsxsqErvFG2pgUarKtsChC94oCV13LfFfOytDqLgktTi1pWzCc834FmqSns+R3XoRtjHEVlER9fF1a0kehFCT00IX+y45LVc1ZeP0fLPrVhSsHFHfeILd6kaMYIJA9NTtVhctoetA7JJ0iNAJdULrktSoPBHqNfBZ8IV87ptssontu6NIdHrsDGEprCF7k3pIyGKPiAevUM9fyWnF7R8hEKWVmygK3lmzjLnqKmPefdeYFSsQUTw/xtx6a5E59NAfzBFHLDPbbRcdoQuIO3zYiPC4bYWdTUL37fos+NI9dx93UatevbpdmY2iFXHNOC9zUp/RR0IWu5y7K7wdcnKaj1VGMnm2EQNRi3pFydKA0D36aGPefJOdi0gMYQmRr0WmZcsfzNy5y8xll21pFiyI1oADbsvckAm9IkPIYteNbT6ef41/NFkUffmxHVG5mBK7/lo4fJvxpov8usViF0EURaIieInoYl/YfHNjNtqI4+LdItO06Q+mSZNlZsqULc23365rrr7aRA4iu7RzHwf7dAk9Sc3nXcQqgkCGr+e/wQYb2D4yipPZteMsdqM6IFYVlvFDjWyGLPSdjYF6pKFC2//ll18K4llO5X3daqvoWRo4TqwLiNzVf7bINGnyg6lbd5n5+ustzR9/rGu/P3p08edTnUehIGLP6gX3GQ9viLDES0Z+qH09z0vIkW3uOffeN9ZYYw2ry6IY2Y2tqvDZxsBDEOoyduhiN/TzX7FihT3/fPq9yva+GrPnnsZcd50xyekBhRS8CHKOc3WZ8ZJCd+XK4mtH90gVoJEjoyV2E60MoYpd+nfaUKjJyCHbGNz991HsArpMkd0s4ntkV2I3TEI/f2dhyJeNxXlfiX4SCUVA8qdZXSY4gSd20iRjnnuupOAtjgKzXFfPbLrpPNOy5UzToUN+BC/jCN2Dsy6kErrA9/lcBIMs9h5TlSHUvo727QRfiMmooYtd7r/PYnd5BDud2I6qvkZ2eQDwcYU4AABLe1FLTMoX3PdQIz0OlrbZBrwQ3tdEnYpQRPxS5pfv4319/PFUUeA1TFFRPbPTTvNM+/YzzfHHb2kaN85tt8ocn3GS9oJHN5XQBQQ7n4tiN4nAo52zlF3oWsqFwufNBdI9dx8rEoRsY4Co2hhiqah4QHyN7LoHIFSxG7LYcxOdUCO7DH54lvOVoJfa+1oS3nfe1/feS10BoV69Ncy4cfXMRx+tZ+68c6aZPj23ESu8xBtsUGQ237xsoQuMN+hIPh81EDiqSBBudNP1caGev2wM+SeWoyr1CRkYfYzsuuzcEGe7EGrChuv4XaZuiCB8iOoXzvuaGud9vewyY6ZMKR0Fplzqr7+uYcaOrWd++22eefjhmea663JnaWDDCOroUl5szJjiZLRk0BDLlhmz//583kQSiV1/xG66yZ0Oxjefl/IrwudzryEbQ/ZwF9JHsYuId8kLIRKqhy/0qLabxObTv1jS+1o2fJ9xafx4Y9gHwWnY3383Zs6c4t/D93lmFyyoZ37/fZ656qqZ5rTTsm9pcFsAs2EEdXSnTSuuukBXmOg1RugiNq691kQW7jWbS4QsduO+sURlkjtDWMqvCJ/PvXpEbQyxFLuEyGksPhr7Q/brQuhiN1QLQyFqDK/2vpYvePm+C0C6+TVCd+rU4qgu8xNs5sVicw3z8cf1zLrrzjPLl880F120WvBmGv0qfRyrtwBmZ7Qnniiuo4vFgsizExpYF4joInSjvMkk95qdlpjghzjJ41nHox5XKpvcGUJ0syI4d1/92jVkY8j+hhI+Rj9DFnuhnz9iN9TkPCd2N2LUzBOITSJQDMzl/Vm+zxyEl+tyiOgidJ3ILVkBYQ0zcWI9U63aPPPf/840xx23pbn22rVt9IvfhVBmjGeu3qmTMXfemZnQpcwZpdkQECTNITYoL8bvRoxzXlG1LiTiLCtEN0NMUou7jSHT5M6QfKsVwbn7uqFIDdkYwthhqaqELPZCP/+QbQx0/ET58rlaQ1SVpVYiUAzMqYLqzvvasmVxJJfxCZFL4IJblWq+zWfWXnsNM3VqPbP22vPM7NkzzbBhW5olS9a2Qhf4OYJ6r7xizEcfGfPUU8ZsvXX6Qjf5PKJWRzdduN+hit0476KVaXJnqo1NQhe7vkZ2q1evbmYR9o8YsVQVPm8VHLLYY1APtRQN0PmFamNwg36+zx9PIYPw/PnFotYFW/jKv3mf799yS7EgJmDBizE61WPK+MX7dE/Vq69h/ve/embs2PXM9tvP5Cztz7kXzRzB/MMPxgwaZMzs2ZkL3bgTevkt+vs4Cj6X3FnRMMz3+RwrD8mELnZ9PfcaEY3sxlJVEQnIp7cvn4Qsdt3DH2p0k7JbIYtdzj3fEx2sAHgK8biiufC+zptX/JV/8z7f32OP4igwAhhdzmEmHyoCmZ9hgCdAjYilSgMe3p9+Ws906TLTrLfenyU+y4tbjiD417/CEro+LOVXBfo5t4ta3MgkubOsjU18XsqvCJ/Pfb311otk4mUsR1afBSHnFmpk04ndUM8/1ESdQls40vW+EgUm4eabb0ontjnhisglUQcx4FbySFr75JN6pmPHeVbwjhy5pfn11+Kul9/jApvU8XXLvYlCd/r0Lc0ZZ6xrq0FAixbGXH65Md26VT3prdD4UJGgstDP0ebjGNnOJLmzrI1NfF7KDzmyu2ZEzy1jxfjuu++aHj16mC222MI+rK+++mopP+3ZZ59tGjRoYNZff33TunVrM2DAgFKJKH379jWbbrqp9XcceuihZsGCBSU+M3jwYNO8eXPTokULM3To0GDEbshiz93XUM8/ZAtHFCpRIBJPPdWYCy8s/pqc5OWiwN27Fw/waDQ8uFRqIDiH0G3QwBgCsIjQRJzgTY7wFn9v9e9DbDuh++23y8y++25p9t57XTN8eHFSHC/E7V57EUEpTnAjAYgkN77us48xJ520WmhHnTj7VrMBz3scI3zFG5tUvBV1eRub+BzdDJk1qyh277//ftO4cWMbIe7YsaP59NNPV31vwoQJZrfddrP68oYbbsjsuDI9EEqltG3b1h5QKi688EIzbNgw88wzz5hx48aZ888/34pfxKvjggsuMEOGDDEvvviiGT16tJk7d6455JBDVn2fmT5i+IEHHjD33XefOfPMM23ySihiN1RCFnuOUM8/CmI3HRC8//d/xWKTQLTr051YnTbNmO+/Xx2tTUfwMt7zKl7uLRa6H320zBx88JZmypSyrQv8PewW669fvJMbEWWOiYQ7SkLFQfBSkSFksQtxFHwuudPZelLhkjuZkKWqDhJXoZ8NfD73Nasgdp9//nmrIa+++mrzxRdfWK25zz77mIULF9rvoyV79+5tXnvtNfv68MMP0z+uTA9mv/32s4r64IMPTvl9/vgJJ5xgOnfubNX5aaedZg/YqfOlS5eaxx57zNx1112ma9eupkOHDuaJJ56wP/fxxx+vErvM+Nu1a2e23377UktdPotdXx+AdAj53EMX+3FKzkNELlpU/P/cLsqP8XKW2pUry/7Z8iK866xTZDbZ5Aczc+Yyc/LJW5ply9Lz6CKwiQW4kk+UgnIln6JOXJfxs0Wcn/d0kzvL29gk9D7fR9asgthFF5566qnmpJNOWuUKoFLL4//Urvvpp5+sZtxuu+2su2DJkiXpH5fJMrvuuquN4s6ZM8c25JEjR5qJEyea7qz9GWPGjBljE3H2IjTyDy1btrQJGB9Rg8fQYW9kT7ZevXr2hIjsJlZf8Fnsxr0DrCohn3vIxEnoU18UwctAXrNm8eD+xx/FgjOdIGUqwbvWWkWmfftFplWrZXar4cWLM0tGmz697JJPcYhwhSp64hzhSze5s6yNTeLyvIv8iF1W79GHidqQ38W/nTa87rrr7L8RwHyPqG+6ZD2Ucu+999poLp4KIjUc0COPPGL2ZM3DMNubb7OKazJKJFC3bl37PQdhbCwQ/HxymTHfxa4IkzgJvmwTlwE/sb4oXsTGjYs9u64c2eLFxZUVKiIxaa1z5xmmYcNlplWrtczGGzc277yTedUF/j7H4YrU0GUiOvAAxylhLUTi0vZTEfeNTQpJnO97LnaHW7Rokf05tGAi/Hv8P9m5+++//6rE3dq1a2f0+3MidrEjEN1t1KiRTWjDf0uENlGxp8PGG29cbsUCH5e/OCfOz8dzq4iQzx1czc0Qz5/zpvOP+rmTHEYEF4+sm5dsuGHxy1kYEtILKmTMmNrmggtmmu22+8G0bdvcvPvuWubvv7F0ZH5s/G13HICtAvER5UuKX5d7z2pfiJVIVq5caa19cd9Uo0mT4lciFbU7RAtkKlp8YMWKFau2yvaNgQMH2hX9XG5EU5k2s3a2H9zLL7/cvPLKK+aAAw6w7+Gt+Oqrr8wdd9xhxe7mm29ubzJei8ToLtUY+F46IHT5W5OoA+ThQ0DnH8WizLmGAY/zjmLZknzw448/Bltrl/uO2OEaRBm8ufvtV1x6KRXbbFO+Z7ckRaZu3RWmXr3fzfrrF5kff/zOrLPOJubQQ8lSz/zYiDYnil26ELrUKHeTDPb48KZMmRLkqgbjIM88VYxCg7GOCa6P43hFoIGITvp47rvssouZh58lQzbbbDM7BiRX5spEG5ZHVkdVHlpeyRYDTsAJGMzFZOAOHz7clhxz5SRmzpxpL1I68PuwQmxd1v6aHgiebNzcuMEEhsoczQJd/+K5YQWEkn2hgYUJkU+HF2WwMFDtIDGym8jSpcZMmZLObyoy2223yKyxxlrmlFOam7//nmZXsqZN+9MMG9bALF+eede85ZYMGMX/T4IQQaNLLjGmaVMTWejrpk6davvyEMXu9OnTbZunBGdolLVsHcpYhyBsGuWHs5Kwok++Vaag6dCHaMNevXrZ99CN/JsqDFUl4x6VGejkhKyHadOm2cjtJptsYpPMOnXqZP71r3/ZAZuTprTY008/bbPsgA69T58+trwEP0My2jnnnGOF7s4775yRAdrHZS/OjZeP55bujkIhnju4+x7i+XPOcWj3eBFvvZWIXHEkNRk0C3P98q0MRaZt2x9Mw4Y/mxo1Gluv7qRJ65r69eubbbZZaPbZZ4559dXVG0+kA5eNlXAELklyP/1UnCAU9XiA20glxNUMoL/j3KPe7nN17nF45nOB7+P8mpXMqUIXUs1rhx12MDvttJO5++67bblbChZUlYx7mM8//9x06dKlxMEBB/jkk0+aQYMGmX79+pljjz3WLF682AreG2+80ZxxxhmrfuY///mPvRhEdikpRkYdNXXjvkNH6Nm5VSXEyE4iId/7uJSgcvVFie4iLlNpNCKsZVdBKBa6jRsvM/Pnb2nuvZdktL9W3f/tt69nmjSZZ7p2nWlGjEhf8OIIw6NLRJdXRSWfokLIuwZCqM+7I/Q+30f+rkIBgSOPPNJ6ua+66iq72kf5WfZtyEb0P2OxS/3c8h5Qlt+pm1se7IzBphRlbUwRstgNmbiIvVxu0RqH8w9921i3bTDtgOgu2eeM2dw6fLK8ttuuOLo6e/bq+qNO6DZtusysueaW5sUX17XZ7Ikan2dg333rma+/Lr21cFkwriC6qb6AACeii9Atq+RTlCjkNtFRQYIvPHyuvPN3FatlYVnIhm0hmViuHUns+om7r1HtCKitSo1VfJuUl+J5phmyrE20DxFUFYERF7Ef+raxrr4omzZQyxaR6dpCsthkm99778WbWWS23voHs8suy8wBB2xpWrQoXV4MYXzNNbSvNczPP9czLVpULHhxfmFvI3EuueRTLidloe2clyui2tflgzhtJCPSJ6qlYWPZ0nwWu3R8vp5bRbhOP4oDAEKXLVhdNI+tWROjeSxrE+0rr4h6RSQmcoZG3LaNTbe+aLduvFe8BTDZ1+Q1kIiRKrHt9NNJ1i1uXw0arGFWrKhnNt98ntl//5nmzTeLBS+iFssCxW7+/e/UtUxzPSnLJiGLXVdqL4rCIF/nH+q5u/KpPvK3xG72YLCIy5JnpoQseNwDEsWHBfGAsKFIRuLY7LZoJaLntmj9Z2fDjGHQj5PgyyacOwN/FCc65UGktLxoKedTkdCFUaOKqziUbF9rmKlT65mWLeeZ3r1nmrfe2tJ067Z2ue0rH5OybBKy2HWrWCGff9T6+Xzh87n/9ttvNngRNWJ5tSnT4mtdwpAjuzz8UTz/xF2zyhqXsrFFa8hil0leHDaVyIR0hS4id8aM4shw6fa1hhk/vp5ZsaJ4a+GPPvqz3PaVOCmjPbp5g5uU8b6blEWBkMUu5+5zRn5FhBzV9lns/vzzz6V2vY0CsbzaXEhfN13w2aIR1/PH98hycEXPL9/nc5XdPCZksct9Jxrgy4pNukLXRXX/+KO89lUseP/4Yz3Ttu1MM2rUnwWdlGW7uH5518ZnQk/OC9nG4PO5L1++XGI3W/gc2Y2i2Av9/Glq9EsVra7zfT5X2XlYyGLXVWn59ddfTUhC17Uv2k757WsNM2FCPbN8+XrGmJkp20m+JmXZgnNgUwnue4iEHNX2PboZ8rkvX748kpukxPJqM2ugk/QlChR1sRf6+fPcckgVFUrg+3yuspNaid34i91Mha5rX7SditvXGubLL+uZddddz+44mdxW8jUpyxbca6L5oUY3JXb9FXwhn/vPsjFkDzdr8NHKwAPAgBlqCaooil0y7ElAq6i58X0+x+d9L78Vsthl+f/hh41hU0i+OjtAZYQudO5cXDosnfa1/vprmF13rWevVbLgzdekLFsQrAg1qgsSu/4KvpDPfblsDNmDrYhpKD5aGSR2oyd23a5Z7ExVlhblfb7fqVPqclDpwMDHuUft/PNFtWrV7IpNVJPUqHTArpX77FOc4HXnncVf+fdJJxWZ77/PXOgC7aVRo2Ixm0772mqrNeze88mCN1+TsmzBxEZiN0yxy/jms+CrCJ/PfblsDNmDjH0upq+RXQhV8EQ1ukltUkTv/PnFosPNRfjKv3m/qlu0cu607Siefz5g4GdZO4rRXVfSi9JdrLpT0qteveKva61VZKZP/8E88sgys9ZamQndxOguojfd9kU7SRa8+ZqUZQuJ3XDFruvjQrWw+Cx2f5aNIbtwMX2M7DKIRbH8Vr6Iqm/V7ZrF7lgEHtk1a9684q/8m/erWruU+x7V88/nqs0vv/xiokbZJb2KtwBu1WqZGTJkS3P99ZWrLLDxxsY8/XRm7SuV4M3HpCxbVRg4Xu53qIQsdlm9Qej6KvhCFrvLIxrZje2T5mv5MYndtc3KlStNnHfNqgqhi106yUWLFpk6deqYqFB2Sa8i06TJD6Zu3WXm66+3NGutte6qkl6V2Za3QYPM25cTvPPmzbOCFwvFc8+tndZWxoWEQMUGG2zg7YBfEa6mdKhiN2ShH4LYrRHByG5sW5vP5cdC3kUtDmKvol2zfLRx5IsNN9zQCrco1V91Jb2wLJQldFeuXNcKU8QlQrUq7SPT9pVK8D7++No5nZT5utSZL5w3P1TBJ7Hrr9j9OaLPdmxbm6+RXeAhiGqSTq6Jg9jNJQg8krRCBbFPxI8Oc5NNNjFRoHRJr9JCt9AlvVIJ3q22Wjtnk7KqwPPN6g3HGyo84/Tzvgqeigh9Qw1fd48rKiqKrI0htlfb1wQ1J/hCF7uhVqOgIkEUE7RCXrUpWdIrtdCNQkmvVB7eKIInm3ZOMmKouOQ87lmIhBzZ9dnCsnLlShu1jmJkN7Zi19cEtdCjm5y76wxCrjUbqth3YpdOMyptYHVJr7KFblRKesVB8NJvRzHyk09UiSJcseueSR/P/+d/NJnEbhbxObIbsm/TLe1FRegUwsaAYPFxd8B0IeKHEKBmbRQoLulVZOrX/8HUrp1a6EappFeUBS/PdVQ9fflEYjdssevKTPrG8uXL7X2NSr6FF2K3Zs2a5qeffjI+EnJkN/TzpwNkiTdksQsbb7yxWbJkSSQi3BzDxRf/YNq2XWbeemtLs2DBupEt6RV1wbt06VJ7TLTxUKE9afe4sMWur+e+ZMkS23dHUcjHVuzSkc9nhPGQkMWei+yRjR8qcdk2N5dstNFGNomn0NfBbQFcrdoyc955W5pOndbNWZ1l3wUv15LBkEBFyCB0uTehepbxdNIWQz1/n8XuvHnzzBYly9ZEhthecTrxuYw0HhK62A29IgHiBFEQMlhZiBCwelOojQec0E3cAjjXdZbzUaWhUAPtihUrrI1BFoawk9NcJQpfBV/IYnfu3LmRrbIS2yvuOnCfqzEw2IbYISIqoriLViGS1EK8/45atWqZadOm2cEx31GgVEI3H3WWfRa8TFyI6vpYcikTQvfruhraofZtvlZiAPqYqIrd2PY6hMqxMUTB05dtQq9IQEcYso3BCauQr4G7DmwykW9vfnlCN64U2tLA0j0T2NAtDCCxG50NYwqBz5HdeRK72YcLykOzePFi42tFglCtDM7G4ONEJl1hIt9uMZtuuqkVu/mytfgodKMgeNkCGltKqD7N5OS0kBP0GLdDbgcSu4UhtmKXiA/eL/l2/cN1BKH7diV2jfXrUmbwxx9/zPnf8lnoFlLwUjOZcmNMXELHJaf52LbSRZFdf8Xu3LlzI5ugFluxG4JvN1Sx6waDkJfxJXZXs9lmm9mSVblsDyEI3UIIXndd2fo55Gieg2eaqG6oftXQxS7Pg89id54iu7mBGYTErp9I7BaLXcr0hA7igCVwRFMuCEno5lvw4tMlmonYFcVR7kJVF4kC5KHwCuEZS4V7zthUwjf+/vtvs2DBAondXOBzZDf08luh19rl/jPhCbkqRSIsgbMUjljIJiEK3XwJXq4tXl3unY+De2WuR+hbJdOn0xZCbQ+usoyPFUkWLVpk+xCJ3Rzgc63d0COboe8ihhDBk+72Gg8dBgiig0QOspW4GLLQzYfgJbGQKJ4qMBTjbEkhR3aVnOdvct7cuXPtsx7V9h1rseuzjSH0yGZirdlQIQmTyG7I1yARIoRci2wkq0no5lbw0ncR6eH3+hjFqgxMXHmmQ/brquyav37leRH260KseyHfbQxERUL17bqi4yEL/g022MD6oJSoVgyiafPNN7dityrXREI3t4KX60u/jM+aNiyKCd3CABK7EruFQmI3ouBpwrMZqm+XwZflrpCFHteAwVFWhtWwRIadgee+MhFvCd3cC17sC/xs7dq1s36McRY5vIjshopqDEvsFpLYi118Ir4u88rKoPJbErulcfVaM7UzSOjmXvDSX3GNZV8oCc8wE7VQE7Mg9BrD9D8Er3w9/7lz50rs5ooGDRpYMZSPgvOFIPQkNYndYt8ubSDUCH8qEFF0qjz36VarkNDNveDFcjNnzhxTq1Yt2ReSkIVBNYZdH+5rgtqsWbOsJosqsRa7dB50ypMmTTI+IrGrJDUiQUSEli9fXuhDiVzbwL9LNKGiZ0RCN/eC1/l0aa+yL5SE3AtK5lFdJWToy6OaqZ/PSgy+iv1JkyaZ5s2bm6gSa7ELXNyJEycaHwld7DpREvI1cJM61dstDQlQvGbPnm0FRSokdPMjeKm8gJihQo6vg3ll4dml3fka0UsX+XX99ev++eefZsqUKRK7uSQEsRtqZJNBU1aGYrG7YsWKMgVdyBBFRESkSliT0M2P4OX6kpTGEqav26BWBVkYip/F0Csx+OzXnTFjhv3aqFEjE1UkdiMMg7jbSztU6ByzvWtW3KCD5KXobmoxRjTRJUY5JHTzI3gRMPPnz7ffDzlqVxbaNW11Owk5Oc33yO7EiRNNs2bNIj3ZldiNeCJO6BUZSHQhqhk6DJYIN1EafKJEFZcuXWqT1iR08yN4WZYmKWWzzTYL3o9aFkxQ6cdDjmgCAQv68pAtLr6L3eYRtjB4I3YxRpMJ7COhb5tLB0knEXJ0G/CmMnCqKkNqGEQaNmxoxe7UqVMldHMseLnG06dPt5UXqHssUrNkyRL77IYs8oCARcgVOrCg+WxjmCixm3uaNm1qxSAlb3wkdM8qUTsEf+jRXTpJBgtFd8uGdsI1WrhwoY00+jqwFBJEG+KWpXn6XYScSA3ihglqzZo1Tciw0hK62GUMZ5U2ysv8VUFiNw8woDVu3NhbK0PoYhdkZSgGYUGkKNSExfJw1gWelW222cZOCnytv11IuL5YF4iis7kH/x/6qktZYKuh7wq9CoMbv0L2dPuenDdRYjc/+Ozb5QFhGT/kTHyJ3WKIVmLX0bUoSbJHd6ONNrJibPHixWbBggWaHGQJopT4dbEuUAWDxMCqbi3sK7Q5xG7oUV2QX9dvsbty5UrbB0js5gGfxS7LHrzk25Vvl8HCRXdFMWUlozGwsOLDxEDRx6pfYyYOWMXq1q1rE9KysbWwz9DuuG6hV2GA0C0MibvH+cjkyZNtO2eTnygjsRsDQrcyyLe7GiJF+CWVqFZxeTGWj6n7SPuhDmTIE8bKwkoCpcUQu0TLkz26Erypoe6wEtPk101MTvM1sjvxHwtD1Nu6xG4MCF3sgqwMxSDoNtxww+Cju+mWF6PsE8vtCA8Er7ZdTh+EK1FxJglMGsra6lWCtySsQikxrRj5dZWcFhW8EbvTpk3zth6txK6xAo8BRP5LYz2TiF1fy+1VRKZ1dBFjLL2zzMZOa0QqQ7126cK1pU9lkOYaV5RkJcFbMqqLvz70xDSgz6bvjnrUL5cwWfQ1qgsSu3mE5TVmTXTOPsKsWElqG9gB1NcJTabXgvYeYhmyqmwYQeIaPl4GH/oKrRSUhmds7ty5NrEPfy4Cluh4OkjwFi9Zk5jGhFQUb5WM2A0Zn/26wD4HErt5gs64ZcuW5ttvvzU+4pZAQvYcco/pNOk8QwdRwWBKBCmkSHc2dkbjZ/hZrt/s2bOtqFOUtxgsHkwCuB5NmjSxk4NMI3KhC16ELm2sLMtHSLhd9kJP0vO5EkNRUZH57rvvrP6KOl6IXWjfvr0ZM2aM8RVZGYq3zJXYLQYhwmASSnQym1sAu40RiPLyTCHwEHohTRwSYbWESgvYO+rUqWPq169fJX9hqIKX9sMEVDvKFUNfTRvw1auabqSf58tXsTt16lRrVdl2221N1PFG7Hbo0MF88cUXxlckdovFLtcglMGzokg3gyoC0HeRlk2hmyrKy3UkwoswC2XyADxHnDdin/aE+M9WBYEQBS8+es4bv64oFruhR3WJbPucnDZmzBjTpk2bWNg0vBK7XHhfB34GDYo3hwwdBtdB0d1iWIpHRPh8PXIldJMtIWw7jk0GawMVCHyeWBJt4poSlaEkEiIXYZrthKqQBC/WD3bsIxEy5GSsxOtBxC90scuY7WtUF9BcaK844I3Ybdu2rV1CYqDyETxgDBah11eVb3c1ROPYstXX6G6uhW7ytUSoIHqJUlCmjKV9Bitfri39x6JFi6zIJYJNYm+DBg1yGpUJRfAy9jAZV1S3GIQu1yOXz2wc8L3G8BiJ3cKIwdatW3vr26UwPgNGSMusqSBSQEeqpKJiXC1PEmN8Ip9CNxEGaHyriF4inUyeEb5c3zi2Oa4jgp2Sa1OmTLH/j/jkmuYricp3wUuknKguWygrqluMi+qGfD1831CjqKjIWkcldguA70lqDE6hi12iUAiS0K9Dcg1ZInZxFGNRErqJIHQRvc2aNbPJgIgZtsXE4xqHaC8rQOx6Nn36dCvYaSfYFYjmFkKE+Cx4aRv0zaGX2HLwbMivW2xhYMXI1+j29OnTbWJvHJLTwCvXNDOMN954w/gKM0QG25BxCSA8ZKF3pg6uB8KGpVRsDXEmCkI3eUWFBDZ8vfh4SULC1wu0P16InHRr0ebyupEMg8jg5QrZc9yI9UIfX6LgJcqM4OX+xj1xh0kFzx07zIli3GTQ14hmuriorq/R7TFjxlihGxdPcrx7mhRi9/rrr7cPmo8NLNG3G/LuPIg7olUUvY/CIF5oaOssoeIxxdaAQIsjURO6ydeY54+XswYgKjleNmFgUONFx88r1/fAiVsEOC+Ohcg+whuBy9coCknfBC8rKvRHcRnw8wHPL9fExzE4U7Hrs4d7TIz8uhDfXiYF7dq1s0tKRF5YrvPZt0uJoFBxtRsZ4IlaieLEPa4L7Z/l97gRZaGbDIO4E7dca0QnHkUEMJFfNxl1wpdzob3y4hlOd4LGNcEPygTXvZy45W9yHO5vICDjEkXyRfByD2ivbMAhimHCxTXxcfzNBDchJiDjs9g9+OCDTVyIXw9TDnT2rVq1sjfB14fN+XZDFrsMlohcOlWJ3dUQ3UU8ENmLU+Q/TkK3LB95YkUDt3OUE6ZYbpxYBQQv4g7RS1vm/EmAc95a/s1nEbr8P59zYhlhi62Cr9zjOIhbXwUvUV364bi111zCpM8FZULGd79uUVGR1Vk33HCDiQvx6l0y2FyiV69exkfk2y3GJQ0hCuI2SOZyIoSHlOuy+eabmzgQd6GbCidMkxOWkiO1/D/wFd8nbRqhgBB0v8OJYh+Js+BFzCDsqNohVuMCEHGdhGUL3/26M2bMsPd6u+22M3HBu17UbS7hKzxAqrdbvPsV0QOiZqJkdJcoYRw2RfBR6JaHE7G0WyYlRAXdi/fc/yMWeM65Hr4K3ThXaaDdLly40K6gxEWc5wMmbbKWFeNzyTFAY22zzTaxiuB715P6vpMag5/q7RbjrAxiNQgklrnnz58f6WcgNKEr/BG8ROE5xrhXPsk2BB6SLT0h+3V9F7sdYpSc5qXYJUnNZUj7iurtFkOmKxHM33//vdCHEikYhOlwsTNEEQldEVfBS19D2+VYfY+6Z4pyKMLw64LEbgTAJ9emTRvz4YcfGl/hHPGLRTlylw+cL1LR3ZLQ0eLZRexGzc4goSviKnhpu/iLKe/nc9SuMmCrQ+RJ7BYn6TEu+erX/euvv8zHH39sOnbsaOKEd2IXOnfubEaNGmV8hY6WEi9REzKFAI8jHtXQhX+q6H/U7AwSuiLOgtfZF/DFi5LQBzMuycNsvN897quvvrLPKavoccJbsTty5EjjKzQ0HiYeqtDhOiCimE2L6NoZJHRFnAWv7AvlP9vUlybiHTpEuGkrPm8dPXLkSLPnnnvGbvMiL59absT48eO9LtElsbt6YCS6S2cromlnkNAVcRa8si+UD+OQC8CEDkl6rKrFTQhmAqvmBBTjhpdil+Vb6r+NHj3a+AozR2aQoZcgAwYhIru6FmXbGRisC2FnkNAVcRe8si+UD4EGAg6+elQzgXHIZ9H/559/mvfee09iN0r47ttl5oiQUXTX2J2kEP+K7qZms802s1/zbWeQ0BVxF7zshCf7QtkQcAl9R8/ExC2uRQh+3bZt25q44e3T67vYBVkZVkOBd8QuiXsitWDIp51BQlfEXfDShknwlH2hbOhzGYfitD15LqO69HM+93WjRo2KpV/Xa7HLDZkwYYL3vl1mkm7b0ZBhMOIB1I5qqUEoODtDricEErrCB8G7ePFi27fKvpAa+hHELoEG4X8Vhjj7db0WuyH4dhERzKhViaB4MCQCg79OlG1nYCk2l+XIJHSFD4KXPnXRokWyL5QDzzjjD3a60HEVgULw63bp0sXEEa+fYlkZwgLfGB4yipuL1GJhiy22sKsBuZgUSOgKHwQvfQg7cFLJREKu7GedyDdRXSWmFe+aBrRLn/26a665pg0ixhGJXQ/ErnZTKwYbA9HdKNSVjSpEYurXr2+jVtmcJEnoCh8EL7aF2bNn24mzkq7Khr4DG4N2TCtpYfBZ+I+KsV/Xe7G7xx57eO/bdZEHRTOLIdKA+CeLWpTdZohaEb3KxnWS0BU+CF5XT5cJoXy6FUd1sQrK4lF8PeTXjT5et9QQfLuumDdCQxRHLonIKLpbPkRkiILPmTOnSgmOErrCF8FLO8bCgNXH5whdVcEGxXVS5LsYAga0PZ93TfszxvV1gxC7oVgZ6HSoQiArw+pJDteDDlmUDdErxCkR3sq0HQld4YvgpQ1TWQCLT1yXafMFUV0myrpOq9sOASefo9xfxdyvC/7enQSxO3z4cOP7sjQNUVUZikF01ahRw3bKomKhwM5ziNZMkNAVvgheLGBUKCGiW61atZwdpw9wrYjsqtzY6n6QPtD3KPeIESNi7dcNQux27drVTJ8+3UyaNMn43Nkj7mRlKBndXbp0acG2GI0LdF4NGjSw14pXOkjoCl8ELxM9rDyU5fPdc5nNqO7aa69d6EOJBAh/8H3TkaFDh5r99tvPxBnvxS4ikLpwQ4YMMSFYGbTBRDEMenioFN2tGMQqUS2iWxUlOkroCl8EL9UEsPAgVBSpTM+bSiIWgQRRDP0gGsNnj/ePP/5oPvzwQ3PggQeaOOO92IWePXt6L3ZZfkN4qObuauiU8eFpAlAxTAzw8FJ2qawKDRK6whfB6yovAJVJfBYr2YLAAYmt2hp49WSJAJPv5dfeeOMN065dO7sCGGeCELvMSN5//33vd9fioZOVYTVEbBj0VJkhPYhusUQ5a9asUsl9ErrCF8HrhC5tnIQ0nxOLsgUTYJ79TTfdtNCHEhkILGHn8HkjCRg8eLDp0aOHiTtBPOUMzttuu6158803je9iFw8RPjRRDNFKJjm6JumJBLyLtCMEr7tmErrCF8FLW8au8+uvv5qGDRvKe5ombEKDVU7P/mroD+krfV4V+O2338xbb71lV8fjThBiF7hZzFB8xu1TztKKKIbrQeKJorvpQcfNBAFbAyLBVWqQ0BVxF7y05YULF9qAgIRu+uDjJ4qpqO5qmDxR/ch3C8Po0aPtJAcbQ9wJRuwShiey63vtVVkZSkO0kkoDvt/7bIqEunXr2onC999/byPjEroizoKXnAbaMv0AbVm+0/RwqzrkP+iarYaAEpMo3/vEIUOGWO3kQ/Q6GLHbvn17G+FjFxCfITOUpQdtl7saBjpmp5nWkg0dypKR3Ien0YfOToSLa8ugtpw+but1VWBIbWHwfaIz2BO/blBilwGbm+a7lYFOXdsHl4YlOJbiKiqtJVZHc4hebLPNNrY9uWVgIeLWlhcsWGBFW2JbVv3t9PsB+s44byaQbVghxPNNYMlnxo4da+1/lG71gWDELjix6/u2ukQxWa7z/TwzgSU4qg0ouls+ycloRMUpzeREgqwgIi64ZDSErmvL2dhaOBSY7FJeiwotYjWUs6Q/9N3zPXjwYLPPPvt4U20iKLHLbmokKHz33XfGZ0guYqlOiWolIULBjFzbKqemrKoLtKU6derYSAYiQRYZEXVceTFWchI9ulXdWjjEqK5Ks60G8U8gKYQJwGCPLAwQVCsm4aZ79+7eWxno0HkYmYGK1bAUR7IaEx5FvUtSUXkxV6WBVQNEgiYMIqrgzaV0HpOyVMloErwVQ1IqIpfnXawGKxzjiO/bA8+bN8988cUX5oADDjC+EJTYhRB8u0AnRVRDy84lwcqAsPN9g5FMSLeOrhO8bqc1rqEmDSJKIHCnT59uhRptuaylZgnessGbT11dKrIoma8kBJAIJPl+XYYOHWo6duxo+3pfCE7sMlP5/PPPrZfLZ+jk8RUpupu6rBaduRKuKrdhBJ09nyV5geQfCV4RlajbjBkzbJY8O6NVlFQlwZsa+gPGDt+jl5WZSBFA8r0Kgys55sNGEkGLXYTOLrvsYl5++WXjO4gS/EX4jERJTzOv0JPVqrIzGpagRo0aWQ+0hIIodDtm4jV37lybTEk0Kt3ImwRvSbAnMWnwKaKXLQgckbfge2LakiVLzNtvv2169eplfCI4sQvHHnuseeaZZ4zvMDMnuqFEtdKQcEWnzm5KIZKNLYDxQrqlYiJqCF8h8gkTefyFWGrYFa0yUTcJ3pJl2shr0AYSqRPTsMH5zksvvWTatGljWrRoYXwiSLF7+OGHWyvDlClTjM/QifNwyltZGjpzMo1DXIbPhtB14I3cYostViWuqb6zyBfYkFz958aNG9vVhsoiwVuclObGDFEShC79pC9luMqDQCABQd8IUuwicvbbbz/z7LPPGt9BhLgi2KIk7AoUWrJaNoWugwGSaBBiAS88fujQJhAiv+CdZDWB2rlEdLOxtByy4FVSWtm4MYJJgO/XZtasWeb99983Rx11lPGNIMVuopXB90HZlY8JSdClS2jJarkQuongZ+P3EgXBP+m2ZxUim9C+EKNMVvHoZrMObKiCV0lpZYPVjb7M9x3T4LnnnrP7EfBc+UawYpcSZHi9xowZY3yHGSm+3RAEXaaQqEYn77udIddC14FIIHGNwYESUKrHK7IFwnPOnDm2TnaDBg2s2M1FpC00wcvYoKS0siFQRMAohM01Bg4caHr37l3ow8gJ/t+9MsDfdeihhwaRqIawYcauMmRlJ6uxLOprIl++hK6DJWWWlhEjiBOsDaoIIqoCbXfatGn2/5s0aWInqbkkFMHLpJSJPitcSkorDRZAJuwh+JjHjh1rJk2a5F0VBhO62AVmMIMGDfK2I0v2KTND1dJyanFGZ0+n71tbyLfQdbhEFxKHqE+JUAm18oWoPDyPWGKcICMZMl+ln0IQvFxXzi+E2rGVgZJ2XJsQJgIDBw60QtdXu0bQYrdz5852aWL48OHGd4jsksyh6G5q6NCIFhGF9MXOUCihmwh/k7+N8GXXNQZXRXlFOrDSwiSJ9kI0l2c03wlCPgteZ19QUlpqsP3Rd7JC5Tt///23Fbs+VmFwBC12qUF7zDHHBGFlcNHdxYsXS2xUYGfwoXxWFISug4GUAYMoL1VBFOUV6URzmXgixNgNrZCF/H0UvLIvVAwroeRzECTynXfffdf2zd27dze+ErTYdVaGV155JYhEGiKXDBpkM4vScG3IQiUBJs7JfFESuokoyiviEM0NQfDKvlA+3F9WQUOI6gJRXcqN+TzxCV7stm3b1maPv/baa8Z36LBddNeXpfpsg1+JSUFcqzNEVeiWF+UNYaIp0o/mssJS6Giuz4JX9oWKQehyn6uyUUlc+PXXX82LL77otYUBghe7POxEd5nZhIAzn/uwVJ8rGGzpAOJ2jaIudMuK8lKxgWLm2vgkPFhOp81OnTrVtl8mQZR5iqoIi7vg5XhlXygfVhWwMBAYCoE33njDbgrUsWNH4zPBi13At/v222/b5WvfUXQ3fTsDgwKlZ+JAnIRucpS3adOm1hfHjlhE9+JyzUXVBAV9ECIXnzyl6ojmxkGAxVXw0kdQW55opewL5Ud1aYehbLDxzD/bA0d1gpktJHaNsTaGXXfdNZjoLh0dERWWskRqSEyoWbOmjTpG3VcaR6GbPLkgmo7opcPF2uBjGThR3FbJGeAe8xXRiNCN23JxHAUv0UomkkzkfRc2VZ2EERAK4Rr98MMPNrLru4UBJHb/4dRTTzUPPfRQENFOyq0RUVN0t3zYUYgOjw4hqsRd6CZCNAUBwVI2CYJE/Tg31YaOP7RTvKLsqsf23Cybcp+ZVMZVVMRJ8BI951miTjFViERq6EcZH2mXIfDkk0+aXXbZxTRv3tz4jsTuPxx22GG2M6AERwjgi2OWrxJQ5Q9mDA5EoKLo3/VJ6CaCpYHtYIn4MUgjelUyL77QxyAGST5jtYQIfpR9ub4JXiaL2IOYvMctgp7v/pRNJEKJ6v799982wHfGGWeYEJDY/Qc6qxNPPNEMGDDAhACze5KDeLgV3S0bBCTLfgzUUfKS+ip0E2FgRvAiJtzSN346id7oQ/tkokKJOV5UOEHk0uf4JiSiLHi5D/RdTCBD2PK2KriARih+5hEjRthzPvjgg00ISOwmcNppp5mXX345iEQ1oPNjK1eVfiofOj9eREeiMDEIQegmCgmWFFnyZukb3+GUKVNiXwvZd08uyYZU2KBtInK5dz4vn0dV8DI5ZNIhn275MIF29ppQrtOAAQPMySef7PX4kYjEbgItWrQwu+22m/WxhACDD0s2CKcoiLgoQwKVE5mFJCShmwgDEEvfiF6sJUTZsTeQQMhgrvZbWBB3iAUmIqwWca+aNWtmn5uo1csNRfBSyo9JIc9LKPegKpMCvLqhRHXnzZtnhgwZYgN8oSCxmwT+lYcffjiYpVI8dJwrySOibOgIKY1Ep1go/26oQjdZULAkjqeXHbZIaiOCSOITUV8ls+W3PbIqxIQDkesiiNwXVo18juRGXfDyd7kvBDNCKaFVWegzmKC5hOQQePzxx02XLl3sqksoSOwm0atXLyv83nnnHROKiFN0Nz0QlwxkeODyvQGChG5puAZEDrfaaisrrrg2kydPtnYTkqLUnnMD9hHEAZF1rjUTDgQu/uo4V1fwRfDS7rkv/P1QNkaoCkyS6UuYRIfAn3/+aQN6p59+ugkJid0kaPSE9u+77z4TCi4zmqilqHgHOgYQoib5GsQkdCuesLFCQb1sXkQUSYoioY3rJptDdgQu/QPXFZHLZIJIGBMNJhxqk9ERvNSoJlrJ3w994lER3BcqvYQU1R06dKjtD3v06GFCYo0ijQKlQMgQ3h83blwwYX6i2UQs8dkhHkTFOxEhABCfuewkJXQrB9YcNk1xL1c7k+gNryi1cYTJpEmTzNZbbx2ZpX/aHcmr7vrx/wg3riETPrXDzPoKVoJ4fnPtnSVKiXcab3scdqMrNEwM6MexRYVCt27dzN57720uu+wyExISu2VwxBFH2M7pjjvuMCFAMyACgRAgI1VULKa4XpT0yVWms4Ru9q4jkUgn3Ijm0M4RbrwKnbwTFbFLmyYK7q4Tx+WuE18LfZ3iSr4EL20c/zp2Evl0K4YkV1Z/mBjQj4fA999/bzp06GDbSWjjvMRuGbz33numZ8+eNsobSsdBZ8kyJdFsDWwVQ0SAEkvsRscrm0jo5gauK4OcE3QIECKWTtQx6OV7ObOQYhfhT5IZ14KvLgLOi34vShHwOJNrwUubpi9iOR5Lj6gYfM3ObhIKZ511lp3QPvHEEyY0JHbLgMvSrl07c/bZZ9uthEPB1casW7duoQ8lFtBxEOFlGSxbCQ4SuvkVe07o8eLaI37dC/GbawGcL7HL5Aw7AoLLvTh/Z08olNgPhVwJXiLyCF0mJ+q304N7wDUjsBOK3WPp0qW2otDo0aNtdDc0JHbL4dFHHzX33nuv+eqrr4IZAELsBLLRiVDPkgGsqsthErqFj/omikHEYaIA5v66r9nqE7ItdjleRKw7/kRhS3tKFvNR8QmHQLYFL7+P1UcEL/aFUMapbAR1aPskV4ZC//79zaBBg8yHH35oQkRit4JlfTqQF154wZq6Q1reAYqRi/QgKYRsdaoBVHaSIKEbLwHMYMm9RrAkvxCQvNIRH5mKXYQNwjX5xe8hesvxStj6L3jdVsDu9+jepoerDR2SXe/PP/80LVu2NNddd5055phjTIhI7FbANddcYz744INg6u4CAybGfZY8Qqk9WFV4jMjsZYLkyl9l+vMSuvESwIjeVKKTF4IUoZssgp0Hlu85IczvI9KEFYbvuy6Zry5Km+p308ZSCW0ncuW39VvwJvYXWoVL/7oztuFrznaeRZQZNGiQ6devn51UhyLwk5HYrQCKpyNeRo4caXbccUcTCtQeJFJJsXgtjWVWzB1BwopAumJDQtc/yoq+8n6imAUisggfEmXcJMmJYSeYk4VtulFj4afgpX9mbMqGdSokuGb0s1RgCOX5cflHZ5xxhjnzzDNNqEjspsGFF15otyN9+eWXTSjQLDhnNpwIaQZcVRAzROkQI0TGK+pQJXRFVEqPiXgIXvoK7AtMqNdff/28HKdPK5asoIRSYQlef/1106dPHzues+ITKlrnSlPsvvHGG3aTiVBApJHZixeVTkKkB9FcOlOuGQNSeXNJCV0hwibTndbwmyKOyaeQ0M0MkohdSb2QuPnmm80FF1wQtNAFid00QLz07t3b3HrrrSYk6BToHBBkIn2IztFm8O+Wde0kdIUQmQheyhySWMUmNvTLIn1cacGQqi+4/QK+/fbboO0LDondNLnkkkusyZvOKCQoUu7qkIr0IWGEZUbKkuETS0RCVwiRieAlGZINf9j1CmuZyDx5mGsXWnIWUd2+ffuajTbayISOxG6aNG/e3O6oFsr2wYmijU6CzkL27sxAxCJ4SSbhBRK6QohMBC9Cl3/XqlVL+ROVgL6Xa8v1C4kvv/zSjBo1ypx33nmFPpRIoAS1DBvPbrvttmpbxlAItVxLtiD5hKQ1rh3JSBK6IhElqImyktawLFDhhWhuSGNOtgg1KQ2OPPJIa9tgYyyhyG5GbL/99qZTp07mnnvuMSGhZLWqQaSGzpboDElrErpCiIoivCy5jx071vpzWV0TmRNqUhqT59dee81cfPHFhT6UyCCxmyEUZr7vvvtsdC4k2FxCyWqVj9QsX77cil5sIXighRCiLNymJXgtyZcg+i8yI9SkNLjttttsZJc9AkQxErsZsscee5htttnGDBgwwISGS1ZDuIn0SPToNmvWzBYzJ2EtOWlNCCEAkYvtCdtYixYtbImxdMqSiZL1zllFY8wKLSmNih3//e9/zaWXXlroQ4kUEruVWGIiunvXXXfZUjAhQVQSOwPJaoo0VEyqZDQGLpe0hi1ElnkhhAOfLsIWoYt1gbrdmdThFavtC4xXXMfQQJvst99+pnXr1oU+lEghsVsJDjjgALs08uSTT5rQYFmNjhfBK8qmvKoLXD8EL9sx8xkJXiEEdbkRtCSyInTd7ouZbjwROlgX6HdJ7gtlS2AHK4YPPfSQDciJkkjsVgIeoCuuuMLceOONwUV3XbKa7Axlk055MQYuvsc1JPNagleIcKEfoI4uQZRNN9201PcleNODFUdnXwgxCZiNr6gYtdNOOxX6UCKHxG4lOeyww6zoI1ktNGRnKJtM6ujyPRIISEZhoMNnJoQIC1Z4mPAiZstbdpfgrRj63lDtC4wh6BE2khClUZ3dKvDOO+/YjMepU6cG93DRbDDC4yljn3ZR+Q0jmDBwLRG7lCgLLaEidFRnN9z+gmVn/PuZ1IFNrMNLP6P+YrV9gX6UJOAQo7qnnHKKXXFlp1dRGkV2q8Dee+9t2rdvb5cOQsPZGehgZGeo2s5oCBwGOyISRGxUy1iIMLawJapLf5FJHVhFeEsTun1h3LhxZuDAgeaGG24o9KFEFkV2q8hnn31mOnfubCMzIUY4ly5dakUes+lQIwzZ2gKY30MWMZMHxC+DmfAfRXbDghUcIrOUGCNRlUluZVCEdzUIXexgXM/QktLg0EMPtcGnBx54oNCHElkkdrPA4YcfbjNoyYIMjdDtDNkSuom/j2VNljeJ3tSoUSNrxyqiicRuOBCFpb+E+vXrV1mgSvDKvvDJJ5+Ybt26mcmTJ9sKFCI1sjFkAaoyPPXUU2bChAkmNEK2M2Rb6LrrSTY2nRaDGKJX81Eh4g+CdPr06TaSSwQyG8I0dEtD6PYFxobLLrvMnH/++RK6FSCxmwWaN29uTjjhBHPllVeaEHHVGeh0QvGb5kLoJtcz5ve6TG1VahAivtBPIEZr1aplxSkrYdkiVMHrfM+hVl+At956y3zzzTfmX//6V6EPJfJI7GaJq6++2rz++uvm888/NyGCOKtevXoQNWNzLXQdDF6UJmMCocQ1IeLbVxAIwObFqk0uPKUhCl76X1YUOe8QfboEQIjqXn755WbjjTcu9OFEHondLEFHdu6559rGFypEd+lkWXr3lXwJXQdLnSx5VqtWzcyYMSO4TUyEiCuupCB9BZNWggG5JCTBS3IfUV3G3com+MWd559/3uZ39O3bt9CHEgskdrPIJZdcYsaMGWPr74aIS1LjAWTG7Rv5FrqJ1xU/FkmQDGJUwBBCRBcqA/Cs0meQOMVkNR+EIHiJaM6dO9daQjbccMNCH07B2he7uF577bWq2pMmErtZhIePPamJ7obqseTBY8tL7Aw+dbSFErqJgxhil5JklCeTj1eIaEIfQSIatXN5XvNdYcN3wUv/RwBgs802M6HyyCOP2Pt7/PHHF/pQYoPEbpY555xz7PLKiy++aEIF/xAdvS/+3UIL3USIZBApYmbPgMpynhCi8DD5xJvLC7GJratQXlJfBS99MFV/WEEM0acL7JJ23XXXmZtuukmlCjNAYjfLrL/++nZpgQhvqP5KV44MQYalIc5ESeg68KhxLNTgxcdLxQYfJhVCxBUmnTyLfG3SpEkk6mP7JngZT5hIYOkK1acL7Ni61VZbmZ49exb6UGKFxG4OOPHEE23W7W233WZChRkns+9FixaZFStWmDgSRaGbOJBRW5LC9BwjUXQSYoQQ+QUPPUKXVRf6iSgJMV8Er/PpsmoYhYlEoWDjiDvvvNP0798/2Mh2ZdEOajni008/NV26dDFjx441TZs2NaFCZPenn36yS+9xWnKJstBNhgGMgYDSZIhfJSzEC+2gZmIrwLCssayMoMx1tYWQd1rjOrNSSlWLUEUe9/CAAw6wY6m2Bc4cid0cctppp9lll8GDB5tQcdsJA0IsDh1VnIRu4jFT8o0XEV+SJeNwrYXEbhxBeCEe3QpWlKK5vglePLocd6jbATtee+0106dPHzNx4kSbrCwyQzaGHIKB/IMPPjBDhw41oeKW0fCyxcG/G0eh664z2cnU5CWSzpIlHjchRHajufQPPF9ul8M4CN24WhoYNxC6+HTj0hfnAqyA5513nvXrSuhWDondHIL4QPDSSJlNhwrRD6K6RB2ZpUeVuArdRKiCQYIMAxrVGphgaPFGiOxEc/HmUkOc5XT697itnsRJ8LpNOVilYmIRMrfccosV/CeddFKhDyW2yMaQhwe2Y8eONnPyqquuMiGDiMTWwUCRryLrIQndVNEAoiIsVzLA+XBOPiIbQ7ShbyDRlokjice52vI3n0Td0sDxzZ49217nuNjfcpmUtt1225n33nvPdOjQodCHE1skdvOYrPbtt9/aqFvIMGiQvYzgjUoH66PQTV525ZoTiZKXN3pI7EYXxCCiEFxE1BeiLHjZOILEP8aJkJ8J7tGBBx5o78+DDz5Y6MOJNRK7eeLUU0+1DzAm85ChuVE5gAEef2mhhZfPQresKC/LYVGLrIeMxG40J4nYrnyK5sZF8FI3nD4Zoetrf5wuJLeffPLJSkrLAvLs5ombb77ZLkO8/vrrJmScZ4wBHvFfSEIRuoleXjY9wcvLtVddXiFK9wnkFUybNi3W3ty4enjxRVNmjAoXPvfH6V4L8n3w60roVh2J3Twnq5177rlBJ6sB+5qzZzwik8oBhSAkoZt43evUqWMHcDpSBnTOX4s7QhTv0IVPlLwCIrk8Jz7ZFqIueKkTTkIafRQbdIQOIpdrQWRXVB3ZGPKIktVKL63PmjXL2hmIPOaLEIVuqmvA+XMdOH+2d5a1oTDIxhAdywI7dFGnOsT7UEhLA/cAoY3gpi/yNZKeLlOmTDFt2rQx7777rtlhhx0KfTheILGbZz755BPTtWtXJasl+bMoGJ6PepUSuqWFFgM9EXaS14hohTjQFxKJ3cJAX0ASFJYehB1RNGw+IVMIwev+JpFd/mboQtclpREEGjBgQKEPxxskdgu0sxr1GocNGxb8gw14tIjy0tHlcrCX0C0bBjfuAwMOlhsiXGqb+UFitzDtnb6Ar0Ry1d4LJ3ijWKGnkLzwwgumb9++Zvz48Tb4ILKDPLsF4LbbbjPfffedeeyxxwp9KJGAiAqdHH4tlrNygYRu+bB8yHXhXhDpxc9Loo7mwsI3Xy7VYAg2YNtp2rSpqVmzpoRugTy8rOxhH6GWroRucck1hO79998voZtlFNktEG+++aY56qijzNixY63ICB3n2cLKQCZuNgcfCd3MrxeDEKKX+0HkK5+e6tBQZDf3INhoz7RrduNi9SIu2/z6GuFlMs3vJ1lZ/Uvx9T788MPt2Pfiiy8W+nC8Q2K3gPTp08cmaL311luKLPwzICF4ycQlwpiNayKhW7UJCFEXXngZEb0hZKfnG4nd3F5b2i+edAQVbViJmIUXvNjWqHxBBLlGjRpZ+Z1x5/nnnzdnn322XfVl/BPZRTaGAnLXXXeZcePGmUcffbTQhxIJ6Egx5TPjJwpTVSR0q16qjAgYS70IBJZ+WQJmKViIOEzUpk6daoUV/QoRRAndwlsafvvtN2tZY+IhoVsM+RLYFx544AEJ3RyhyG6BIarL0gXVGWRnKIYoAh0rDz1+usogoZt9SF4jmYRrWr16despU6S36iiym91rSRSXFzYFJmusFGnlLBoRXvoQJs3069wbUXxtDzvsMPvsk5wmcoPEbgQ45ZRTrLiTnSE7y1wSurmFAYuoGf5HloYRvdgc1HYrh8Ru1SHi6NokEzDaJG1TbTI6gtfZ1LgvqqW7mkGDBtnNprAvEO0WuUFiNwJQdmXbbbc1V155pS1LJiqfwCChmz8YvFwUjeVhtrQk4qtBLDMkdisPlhpELn0oEVw38RLRErzYSshP4fPZTkCOu31hm222sfV0ie6K3CGxGzE7A9UZqDcoiiFSQzkWOtaKlswldAsn1rhPiF7EGqKXjHcNaOkhsZs5iC1ELhNiVn5oc7LURFPw8nlW6fhK4IJcAFF8XQ499FA7ThHdFblFYjdCnHrqqWb69Onm7bffllBIAJ8oYopJQFnlgiR0Cw/RGyJsiBDuB4X68eapxFP5SOymB20KccukCqFF+0Lk6lmPruB1nyMpLdebBsWN5557zpx//vnWviD/cu6R2I0QCDXsDP/+97/N6aefXujDiQw0UaK7bO1Jh5ksniR0owX345dffrETFL5ibWArYvl6UyOxW7FHnEkU7Yn2Q1tC6OpaRVvw8n2W6ekDUvXbITN//nxrX3jkkUfMIYccUujDCQKJ3YhBVBfvzjfffGMaN25c6MOJDGV1nBK60fdUIlIQK4gTIr0SKiWR2K14woQfl7ajygrxELwVBShChmuDwMV2Q3RX5AeJ3QhCktqUKVPMO++8I39TAjRVZsQrV660dTPpWCV042NxYAka8cLAiM8SX6/Ei8RuIix38zzzkhUmnoKXNiyhWzYDBw40F154oewLeUZiN4LQ0bdv397usNavX79CH05kBS/L4i7SK6EbL0FDpBfxiwhG9PIi0hGi8A1d7GJToC3Q79E2sL3QHlTZI36Cl36ZyjluIw/1yyXhOd9hhx2s4D3wwAMLfThBIbEbUcaMGWP23HNPa2vYbbfdCn04kQKBNGHCBDs4tmnTRvuqxxS6HgZHJ3wReogconkhDZIhil3OmcgfzzDCiIkr956IfyjXwDfUL5cPE7ldd93VdOrUye6eKvKLxG6E6d+/v7njjjvMl19+aetHitUeXQQStV2p9UoEQUtl8R8oidIzUCKCuLcIH6J7CF+fI3yhiF3Ok3vMxIZ7zH11UX09v/HGeXS5t9xX+uWq7LTmI+edd5758MMPzQcffBDUZD4qSOxGGG7NwQcfbIXAa6+95vWAnw7JyWgMkIkeXg2Y/ogiJ4gQRwyYiF5ePu6K5bPYJUGR+8iL55RBnvvIREZ1cf0gMRnN9cPZ2FrYJ1599VVz4oknmi+++MI0bdq00IcTJBK7EYeapdtvv7254IILbE2+UCmr6oLz8LIUqmQIfyO+Tvjybyd8SW7zQRz6JHZ5HhE5brKCH5cJirtnej7DqZIjwVvMjBkzTLt27czDDz9sN44ShUFiNwZ89NFHZq+99jKjRo0yO+64owmNisqLJXa4SorwFyekXKSQqCHRQfyeCCpecaxeEmexyz3Bi8hkk8gtX4GJiE8TElGaigINErzFyZfk3iB2H3zwwUIfTtBI7MaE2267ze6fjX+XBJ5QSLeObuLn2JJSS6RhDCQMtO6FTzCO4jdOYjeVuOW9xGsealWNkGCFxe2MVp6FLHTBe+mll5phw4aZjz/+2D4jonBI7Maoc9l///2t0GUf7RAGk0w3jODz2D5+/PFHU79+fRtVEuFQlvhNfEUx2S3KYpdriFBxLwSuxG3Y0F5nz55t/59+tiIBG6rgffPNN80RRxxhPvvsM9OyZctCH07wSOzGCJIAWA65+uqrvd9OuCo7o1GpgeW1evXq2UxvEbb4TRRrkCh+qfrAq5BiLSpil+tFpC7xeiF2efbc9ULkStyGC20EoUskd4sttkh75SQ0wTtnzhw7VlNi7Ljjjiv04QiJ3fiBb/eAAw6wPt7tttvO+Eg2tgDG0zl37lxTu3ZtU6tWrZwcp4hfu8LnmyjmEHe8TxtL9cqH+Myn2GWFCMHCdUh88V6ysHWTgahFm0VhoJ3MmjXLRvM333zzjCc8oQhenqNu3bqZJk2amCeffLLQhyP+QWI3hlx77bV2T+3PP//cJoH4RDaEroMlV6IQbDfKtoyKRomyBHBZ4g+h54Qv0Sz+zSCd+Kpqu8qW2OVcELMcd/Ir8bw43lTCHmEbB4+zyD+uL8VGRwChsm0+BMHLyusLL7xg7Qu+jc9xRmI3hjA4Up2BxICnnnrKGxGXTaHrIHJHNIJOp27dut5cK5Gf58wJxEQB7F58HxIFMP/Pi3aGcCzrBa4tIlCnTp1q62+67/EsOPFa0SvxmPgZfoc7FgQ6/89XJ2qzIdBFOLhVMgIGm2yySZV/n8+Cd/jw4aZnz55er7zGFYndmELnwx7bZHuyM0vcyYXQdSBSELz8zkx8ZkJU1GaTI6gI4PKEqROwrtt1onbRokVWTCS2zURx7MRzspBOjjQ7sS1ENshV/oOPgpcJ60477WRuvfVW06dPn0IfjkhCYjfGfPLJJ6Zr167mlVdeMd27dzdxJZdCN1UGMaXJJAhEVIhKgpoQiVDZhklYrirb+CR42URl1113NV26dDH9+/cv9OGIFCjEFWM6duxoC1UfeeSRdrCMI/kQuoCIwPbBV3a0wd4ghBAi9WYRlHCkz8xVCUdWKIgYkwg5c+ZMuzISR1ipoeICNjmqL4hoIrEbc44//nhzyimnWJ8QS05xIl9C18GyL1EK/LsIXrxoQgghikFwIjxJSGvcuHHON0LwQfCSkPbtt9/apLQ4R6d9RzYGT5ZBDzzwQCvmBg8eHIul0HwL3bK8aK40mRJ2RKGQjUFEAewE1IdFeCJA85nbEFdLAwL31FNPtQlprVu3LvThiHJQZNcDGCApRTZlyhRz+eWXm6hTaKELlNDhb+NLQ/SyFCWEECGC55TIKv1iIZJ44xjh/fLLL20i2sCBAyV0Y4DEridQS5ao7sMPP2yeeeYZE1WiIHQdLNE1atRoVXkyqjYIIUQouEogRFURm4WsRx4nwbtgwQJz0EEHmSuuuMKuqoroIxuDZ7z11lvm0EMPNSNGjLBlUKJElIRuIkR1ie6ytSye3lz71IRIRDYGUah+z1kH6PcQmVEg6pYGgiNUQcLTTGBJFrh4oMiuZ+yzzz7m+uuvN7169bK1eKNCVIUusGRHRIGC6UR4OUYhhPAVVrFI0mWixepWVIRu1CO8jGNnnXWW3WTm0UcfldCNERK7HnL++edb0YvgJau20ERZ6DrotBC7+NWI8i5cuHBV4X8hhPAFVrCmT59uV7AoLRa1yGmUBe+9995r3njjDfPqq69qBTBmSOx6CB3FgAEDbCd22mmnFVS0xUHoJkJZMiIdlCWTj1cI4Qv0xdTOpV/Dm7v55ptHOjIZNcH7zjvvmH79+lmhi+1DxAuJXU+pVq2aefnll82oUaPMzTffXJBjiJvQTbx2+LHWWWcdGwFRPV4hRJxBKLKD5JIlS2xfTLnFOBAVwTtu3Di7eRObOLGZk4gfErsew8x96NCh5rbbbjNPPPFEXv92XIVuso+3Tp061vssW4MQIo788ssvdtJO8mM+NorwTfAyScAWePbZZ9tNnEQ8UTWGACC6e8ABB5hBgwaZHj165PzvxV3opsq+RfAigPH0EvEVIluoGoPIZVmxn376yU7aqaEbZdtCFKs0UId9jz32MLvvvru1Bsb5+oWOxG4gvPTSS+aEE04wb7/9ttl1111z9nd8E7qJZXqI7lJ8nYh5jRo1Cn1IwhMkdkW2IdeACTptiwl6lKotxEXwksjXvXt3u8vmiy++GMlEPpE+unuBQO1dRCgFsN977z2zzTbbZP1v+Cp0gaguIneDDTawnS0dIZ1gvncaEkKI8iDHgD6KZNu6det61Uc5SwPnh6UhV4IXqwQeXa7ds88+K6HrAf48BaJCzjjjDHPuueeafffd12bkZhOfhW4iG220kfW9UdKNzpZ6i0IIUWjog1l9IqKLbQFR6JPQzZeHl+tIFSPqELMradw8ziI1/j0Jolyuvvpq69/FcE8ZmmwQitB1cH6UJyPKS+IHGc5yAwkhCplXgDgjGY2+CX+uz+RS8P773/+2O5AOGzbM1KxZM2u/VxQWid3AoJO4//77TatWraylgc6xKoQmdBOvI9ET6i0yaSBjVzV5hRCFqJ3LpJvJN0KX0okhkAvBe88995iHH37YvPXWW9brLPxBCWqBgsGf6C6JVq+88kqlKgyEKnSTIQnEJa/5kPUs8osS1ERlo7l4V0meRfSFutyeraQ1qhWdeuqpZvjw4WannXbK+nGKwqLIbqAwG37ttdesd5cHPNM5j4TuahAoDDZEAij1oyivECJf0dw41s6NWoSX3dH69Oljqy5I6PqJxG7A4Ed68803zejRo+02iOkioZsasp+bNGliIwvTpk2Tl1cIkRNv7tKlS23fy0qSj0lo+RS8n3/+ua1W9NBDD9nkbeEnekoCh2gk/qTHHnvM3HnnnRV+XkK3fBTlFUJkG0VzcyN4J0yYYPbff39zzTXXmN69e+flOEVhkNgVpnnz5jbz9Prrrzf33XdfmZ+T0E0fRXmFENlA0dzcCN7Jkyebrl27mlNOOcVceOGFeT1OkX9UKVlYOnToYCO87BiDQKMmbyISupWP8pIEOH/+fHvtKPIeSra0EKLykHhGNJcta2vVqmU222wzidwsbTwxdepU06VLF3PMMceYG2+8sWDHKvKHxK5YRceOHa2HF98SnQMzXpDQzU6U1y1DMnBtuummyrwXQpSC/pZd0KjwQj9MOTFftvuNguClD0boHnbYYea2225T5ZxAkNgVJdh1113N66+/bn1MiLETTzxRQjcLcC1dWbIFCxZYawP/JuqrzlYIAezISP9AGS22I1cZw+wKXnaXQ+j27NnT3HXXXbq2ASGxK0qxxx57mCFDhpgePXqYFStW2Hq8ErrZAQtDw4YNbU1eIjd4eWVtECJsEi0LVMkhwVUrP9kVvJ988ok5/vjjzX777Wf69+8voRsYErsiJZ07dzavvvqqOeigg2zW78knn1zoQ/IGOtmNNtrIbLjhhrI2CBG4ZYGJL6tnsizkrr8lUY1qC3vttZdNwpbQDQ+JXVEm3bp1M4MHD7aCl87hpJNOKvQheW9tYOkSIazOWIhwLAv0A3rucwOVLLAukHz94IMPKskvUCR2RblQmmXo0KHmwAMPtLNjdlsTubc2MPipjqYQfm4PzYrOTz/9JMtCjiGAgNBl/Lr33ns1mQgYiV1RIZ06dbJVGkhaQ/CeeeaZhT4kr60N+PbYxpn/p9yQ/LxC+OHLReAidJnIyrKQW6ZMmWKF7iGHHGL+85//SOgGjsSuSIvdd9/d1uGlLBmC95xzzin0IXkJER6sDER8nJ8XEYzoXWeddQp9eEKISvhyWa3hecaXW79+fTuRFblj0qRJVugeeeSR5o477pDQFRK7In122WUX8/bbb1vBS5WGSy65RJ1IjkDYbr755maTTTax2w5TBF1JbELEL/mM5xdUajA/jB071lYQOu6448wtt9yi6y0sErsi440nRo4caQUvu4LdeeedMvznEMq94elbuXKlHTRZmkPwInx13YWIJr/88outsMAqGKsyqpebH959912bUH3RRReZf//737rmYhVrFDH9FCJDiDSS3Yr4feKJJ1SDN09oEPUzYYll16233lpR+5jDpJTnkwoLmpTmF0plUl7s7rvvXrX7pxAOPYUx4uabbzY77rijXQpjSaxXr15mwoQJq75PYhNe2hYtWtgECDaCOPfcc83SpUtL/B7EUfJr0KBBJT5z7bXXmgYNGliv7sSJE0sdS9OmTc0HH3xgxo8fbzefYLlO5B68fiS2cP+530w68ANqzipEYUXunDlz7E5dJJ01a9bMil0J3fzw8MMPW6E7cODAlEKXkmPbbbedzX/ghSWPpOvEn6e2vCv/Rp+aTOPGjUuNm9gkEnnkkUds/7z99tvbTSxEdNCTGCNGjx5t+vbtaz7++GPzzjvvmD/++MNGV4n2AVsh8sKQ/+2335onn3zSDBs2zPTp06fU7yIay64y7oVwdiBi2TL4tddeM8ccc4w5++yzUx4PO3+NGjXKRqYoUUZEQ+SvckOTJk1sdBfRi72Br2R8CyFyDxNM+l4ELtVT8NkTBGAiqgh9/u7BddddZy699FIrXrEwpILADcJ0zJgx5vPPP7fjFZ/97rvv7PfJQcGad/nll5f79/hbieNmYqI27eC2226zgSMsFKpLHy3k2Y0RCNdEELN0rDzAe+65p9l2223NSy+9tOr7RBduvPFGO+Nl2ZtMYAfZ/iRApYLyOPhEmQnzc/ydsiDKjDA+4YQTzG677WYrNiDCRH5ELzYGhO/PP/9ss715sXTKSwOuELkRWO55I+DAs0Z/mdi/itxDkIWVS+wLeHXbtGlT5mdZfUyEcZFoL4GjbbbZxpx//vn2fYI35cF4V9a4uWzZMjuuMm7yGaL9IjooshtjnD2BjP3yPoMYSu6IiRATFdxpp53M448/XmIZnExWPGcbbLCBne1inygP6sA+++yz9rO77rqr+frrr6t8biIz0UsnzPIZgy5RCiK9bFDBYCyEqDr0kfSnbFTAzmf0qwQU6EcldPML49NRRx1lhg8fbj788MNyhW4qkUz0lag8doZMIDqMPQWbwu23326DQQ6CTQhdAhAI6BtuuCGj3y1yi57QmMJyNbNRoqk8ZKkge//66683p512WqmlGJZxELOUEjvrrLNspIJZMrAcRxQZscRMNZ3kM7xp99xzj6lXr57dhAILBF9FfkUvnl5eRBWIPOHppfNlQqQkQiEq19cicrEJAWIHoSs/bmHgXmC7Y1L//vvv28lGuiXJELcI5erVq5tXXnnFtG7dOu2/y/jYvn1725cisPv162etDHfdddeqzzz22GPWysDYqh0wo4WqMcQUdjHDo8TDjh8p1ZLK3nvvbR/MwYMHl7shwVVXXWU9vPjOsgEP/HnnnWeefvppu3uNKBy//fabFb0kEBL9ZcmVBBpVcIgOqsYQTYjakaiErYvILSJXdXILC+Jyv/32s0GV//u//8toc47ff//d+moRy/zso48+avNgEgUvNgY2o3BbOZcHK6Knn366DRRpl8voo6lpDCFhbOjQobbebSqhi7DBUkDHzOy1op23KB82e/ZsK4yyAQlx2BqOP/54M2DAgKz8TlE56ISxNpA4g5BiQjNjxgzb4SuZTYjSsCpCoi9WIKKHCCsy8V2mvigMTAhZycSyQAAn013oWNnaaqutTIcOHaw1r23btnY1srIwbjIhYpdLEX1kY4gRBOHJ/kTAMgNNlQhGRBfPLSKHDiGdvde/+uorG/HL5uy0Z8+eNlmNxABK8lDKTMt+hYMJD9UzWPKjjRDtdTYVXtqKWIQMEz+CBERymfQjbBG4ithFAxLJGFNIhL711luzMpZwz6sS4GHc5DhIEhfRR2I3RpBURsQUPyxRW3YwAzyZ+IMQMZQiIxrxzDPP2H/zgtq1a9vI3pAhQ2xyxc4772yFMCXMbrrpJnPxxRdn/XiZhWOzQPBS4gVbA14pUThoA0xsELi0E5br8PUSJeE9vip6JUKBpW0ELisdPBs8A6yWyU4SHZ566imbV0I01uWVZAr+WuwP1J5nUsM4SsCIgAwwlvKaPHnyKn8vYyyfxwr40Ucf2bq5WBx4n39fcMEFttIR/amIAXh2RTzgdqV6PfHEE/b7I0eOLPMz06ZNs5958803i9q1a1dUvXr1og033LCobdu2RQMGDCj666+/cnbcixYtKuratWtRmzZtVh2HiA6///570cKFC4smTZpUNHnyZHu//vjjj0IfVjD8+eefRePGjbNfRe75+++/i5YtW1Y0c+bMovHjxxfNnj276Oeff7bvi+hAH3ThhRcW1apVq+idd96p0u86+eSTixo1alS07rrrFtWuXbuoW7duRW+//faq71999dXljq1jxowp6tixY9HGG29ctN566xW1atWq6Kabbir69ddfq3yeIj8oQU3kBUpgsV/5c889Z5MDVKkhuvVDiXQR9SUKz3Iu0V5ZUHKHEtTy07ZZsnarXaxeEMVlVUxlw6IHfRClxUgoYyWTZ0OIqqCnXOQFPKH9+/e3yQX777+/LddCJquIXr1eXizvsrSLrxcxxnvOLiObg4jTJNsJXNq02xRAdp3oMmHCBOvPReBiF6DfEaKqKLIr8s57771nS5IdccQR5u6771ZyVIShe6AupRMMRHgRDER800l+FBWjyG72rye+TCZrbnMc2ivtVisU0QYP7ZFHHmnOOOMMu8uZngeRLSR2RUGg/BWzd8z/L774YtqFwUX+IWdjxAhjfv65yGy88S+mXbtlpnr15baUDyKClyYslUdi12Qlsx4LDiLX1T11bVM2heiDDPn/9u48yub6j+P4O1kyxk5k+WUoW3QkshVysi/ti62UEtF60qL4pRTHSf6gjjWURCpkPVSMtWJkLWSnsSvKrvqd18fvO+fOmMFoZr73fu/zcc7nzNyZOXxn5s69r/v+vD+fz+DBg92e78OHD7f27dv7fUkIGMIufKMnpU6dOtnKlSvdNmlpnQQHf+iMkT59zBYuNDt+XKfkKVSYxcSYNWz4l7300p8WE3PU9feqvUGVM/X5EnzTh7B7+QFX9z0FXA397BRuNe3NaYGRQ9V3VXK1M9DUqVOtZs2afl8SAoiwC9+fsHSk8aBBg+zjjz+2O++80+9Lwv+Dbtu256q6+fKZ5c2rnl5VYHRoifZzNrvuOrNPPzUrXvxMUkVNG/IraCj0anBa28URdi+dNvHX/Uzj2LFjrmrrLaTkvhaZJ6KppU3PA9o/XgfgAJmBsIuw8MUXX7gq7yuvvGK9evXiSctnjz5qNnu2gqxZarPAZ89qb0qzFi10bGby4BYaRtQj6QVf9U7SM3k+wu7Fd1Hw7k+qAirUevcpvbDisSIyJSQkuOJGo0aNbMSIEawBQKYi7CJsrF692j346RjHMWPGuH5eZD1Vc5s21QEU56q6aVF196+/tKjkXJU3JT20aJrZC7+qymkVvBdU6KU8h7CbHPeb4P9+1ZerrSjfeOMNd6ARL1iQ2XjUQNhQyFX/7mOPPWbVqlVze/LqFDZkLS1GU4/uxWYU1dqQmGg2f37qYVdPYAopGjpSUxU6Vee0Sl6n+Kkqp2qvNwh60b3jhwKuhlphvBkBHXHNjECw9s994oknbMmSJTZz5kxr2LCh35eEKEHYRVhRNVe9W0OGDHFHH7/++uv28ssv82SXhf7889xitIsVW/R5fZ16eC9GwVfTlBqFCxd21Tov3Bw4cMDtgaoV9ITf6Ay3un9okaNeGOloc90XqPYFy/Lly922YhUrVnSzePo9A1mFsIuwoyc5nYGuqq4eHHWG+UcffeSqPMh8sbHndl1Qg9OF8oY+r69ThTe9NBXtbQ0lqYVfBWOFXoUgwm/kItxGN/3+tZ+6ChdqW1D7AsULZDV6dhHWdJBBly5dLD4+3j755BO3mAHh1bM7d65ZuXIZew2h4VdD4VdtD151WEMBKQgBOEg9u3o60e9K4dYbal+R0Ko94TY6HDp0yC08XrNmjU2cONHq1Knj9yUhSlHZRVhT5U+9u6NGjXKHUKgqoI3HIz0UhDP139avf243Bu2pm9ZuDAq72o0ho4NuWpVfLzwp/B4+fNh9LKgBOFKDrYZ4v48CBQq43wnhNvosXrzY2rZtazVq1LBVq1ZZwYIF/b4kRDEqu4gYa9eudUcMq51BVd6SJUv6fUmBlZ59dkuX9ucaQwOwN0IDsAKWDrjQbY1wnToN98quniL0c1Ww1VClViNlsPUG24FFN+2ZO2DAAHfcr9726NGD+wN8R9hFRNFqfj14zpgxw8aNG2ctVFpEpgXe//7XLD7+/BPUGjQw69vXv6B7KQHYC2caegJW8A0Nv97Qx/x8Mg6HsKunAV1H6M/szJkzSe971Xb9vLxKLcEWKe3du9c6duxo27dvt0mTJln16tX9viTAIewiIum0taeeesq6devmKggcUZt5VN3V9mKq6KrCq7bpzGhdyMogFxroxAvCCnRpjcwKdZkddr3vXy8ENELf1/BCrV4QeIE23F4QIPx9/fXX1qFDB7v99tvdPrpeCxIQDgi7iFgbN250uzVoenrs2LF24403+n1JiDB6+PPCnt6GhsDQUCgKoqHhV7c1FAK9t7ovhr7vDd1OKyxeStjVdSqMXmh4oTa1YKvP6TrSCvLh3uqB8J5t06mXo0ePdrsudO7cmRdGCDuEXUQ09Q6+9dZb9t5779mrr77qjhumyovM6FlNrSp6sQDq8cJuaJj0AoH+fW23VqRIkaTPew/LXsgNfZhOGa5TjpSh3BsEWWS0RYsW2aOPPmrFixd3p17qBRsQjgi7CIQVK1a4LW7US6gqb9WqVf2+JEQ5PbSmrMiGPtx67ytAb9u2zeLi4pIqu6GVsZRhlqoZ/KYdUVTNHTlypPXr18/tix6OiysBD1uPIRC0vU1CQoK9+eabVqtWLfdArJPXqPLCL6lVc1OjsOsdnUxgQCRsKaZqro4A//HHH618+fJ+XxJwUcxrITBU1dVitYULF7q9eWvXrm3r1q3z+7IAIBDV3Oeff96aNm3qFgbrcZagi0hB2EUgq7wrV650D8q33HKLC8DeIiMAQPosWbLEqlWrZt9//717bH3hhReYhUBEIewisFXed955xxYsWOAOoKDKCwDpr+Yq2DZp0sSefPJJtyCtQoUKfl8WkG6EXQSaKruqRDRu3Ni9rwBMlRcALmzp0qWumrts2TL3GKqj2qnmIlIRdhF4Oumpf//+rso7fvx4V+XV7g0AgOSOHDlizz77rCsQdOnSxS1Io5qLSEfYRdRVeVu2bGn169e3rl272qFDh/y+LADwnbbC08mUCrbr1693j5Uvvvgi1VwEAmEXUVfl7du3r61du9Z27drlVhNrr8jQAwAAIJqsWbPGFQB0MM+QIUNs3rx5VHMRKIRdRKVy5crZjBkz3Kk/6uNVa8Py5cv9viwAyPKWBe1NXq9ePduwYYPdf//9HFyCwCHsImrpAb1Nmzb2008/WfPmza1BgwZuxTGtDQCC3rLw0UcfueqtHv90OMSAAQMsNjbW70sDMgVhF1Evd+7cSa0Nv/76q2ttGDFihDvZCgCCZPXq1a5lQadMqmVh7ty5VrFiRb8vC8hUhF0gRWvD2LFj3e4NtDYACIrff//dtSzocY2WBUQbwi6QQuvWrd3UnnZtoLUBQCSjZQEg7AJptja88cYbrrUhMTHRrr/+ehs4cKCdOHHC70sDgEuivcXr1Kljr732mg0dOpSWBUQtwi5wkdaG6dOn26RJk9xQ6B09ejSnsAEIW6tWrbJmzZrZnXfe6Rbh0rKAaEfYBS6BThNS/+6gQYPcFGDVqlXtyy+/dFOEABAOtmzZYu3atbO6detalSpVbOvWrW4hWp48efy+NMBXhF3gEmXLls0efPBB1/f2zDPPWPfu3d0UoaYKAcAv+/btsx49eriAq4NzVMl99913rXDhwn5fGhAWCLtAOuXIkcO6detmmzdvdlOEmirUPr2aOgSArHL06FHr06ePa7fStokJCQn24Ycf2n/+8x+/Lw0IK4Rd4DJpalBThJoqvOGGG9zUoaYQNZUIAJnl1KlTNnjwYCtbtqzFx8e7432nTJlilStX9vvSgLBE2AX+JU0VaspQU4eaQtRUoqYUNbUIABlFB92MGzfOHXyj/cC1pZi34wKAtBF2gQyiqUNNIa5YscJ2797tphZ79uxpe/bs8fvSAEQw7f4yfvx4u/HGG92WiG+//bbbL7dFixbssABcAsIukMHU0jB16lT75ptv7JdffnFTjTqYgvYGAOmhfb0/+OADt+WhQq5OQNMMUocOHdyCWQCXhr8WIJPUqlXLhV5tWXb8+HEXgtu2bWtr1qzx+9IAhLEjR464LQ7LlCljw4cPd8eXK+R26dLFcuXK5fflARGHsAtkMvXwfvzxx/bzzz9boUKF3Nn0rVq1ssWLF/t9aQDCyP79+92iV7VEzZgxw7VFaZeXhx56yLJnz+735QERi7ALZJG4uDh7//33bdu2be5QipYtW1r9+vVt9uzZHE4BRLEdO3a4Ra2q5CrcKujqxbAeI+jJBf49wi6QxYoVK+amJfUEpyM9H3nkEatevbo7jlirrQFEBx1Q8/DDD7vdFQ4ePGhLly61WbNm2W233eb3pQGBQtgFfFKgQAE3Zbl9+3br3LmzvfTSS1axYkUbMWKE6/EFEDyaxVGovfvuu92LXPXgrlu3ziZOnGjVqlXz+/KAQCLsAj6LiYlxU5g6ka137942dOhQK1WqlAu/ankAEIydFcaMGWM1atRwJy5qlxbt0DJy5Ei32wKAzEPYBcLoGGJNaa5evdrt4qCgq0qvjiPWCUn09QKRR+1Kr7zyipUuXdodPvPEE0+4o30HDRpkJUuW9PvygKhA2AXCjBakaOHa5MmTXeVHi9nat29vlSpVsiFDhrhtiQCEr7///tu+/vpr16qgqu2mTZvc37PaFbp27WqxsbF+XyIQVa74h3IREPZOnTpln332mdvNYe3atW4rIj1pakqU1dqRTYsSdfiIQtGVV17p9+XgXzhw4IA7xld993pR+thjj1m3bt3s2muv9fvSgKhGZReIAFrE0rFjR/vuu+9syZIlljNnTmvUqJHdfPPN7on1jz/+8PsSgaiketHChQutXbt2rlVBuyn069fPdu3a5Q6GIOgC/qOyC0QoBdxPP/3Uhg0b5iqDerJVz2/dunWp9kYQKruRKTEx0f39jR492vbu3WudOnVyJ5ypzx5AeCHsAhFOf8IrVqywUaNGub5AbWmm4NuhQweeeCMAYTdyHD161L788ksbP368xcfHW4MGDdw+2ffdd5/lzp3b78sDkAbCLhCw3t45c+a4J+Pp06fbDTfc4EKvenyvueYavy8PqSDshrfTp0+7v6lPPvnEvvrqK7dQVAtG9TfFbgpAZCDsAgGlBTJffPGFC76LFi2y22+/3QVfrRDPmzev35eH/yPshu/BDwq4OtlQfy8KuBqVK1f2+/IApBNhF4gCu3fvdv2FevLWNkjau1fBt0mTJm5/X/iHsBs+NmzY4F4cTpgwwX7//Xd74IEHXMCtV6+eZcvGem4gUhF2gSijvT4VejV0qpOe0O+55x63ty/BN+sRdv2ln73aE/RiUH8brVu3di8EmzVr5nZBARD5CLtAFG98v3jxYlfF0pP98ePH3TGmerLX24IFC/p9iVGBsJv1P+9ly5a5nnbd77du3epafPSi795777X8+fP7fYkAMhhhF4ALvitXrnRP/goBqnDdeuut1qZNGzfKlSvn9yUGFmE3a7bpmzt3rrt/ax9cadmypbtvN27cmB52IOAIuwDOs3PnThd6NebPn+/Crhd8a9WqRSjLQITdzKFDHbzqrXcf1qyF7sO1a9fmZw1EEcIugIvuLaqqmILDzJkz3YEVrVq1cqHhjjvuoCr2LxF2M2524scff3ThVsObnVDA1dDPF0B0IuwCuGRnz55N6necNm2abdmyxWrWrGkNGzZ0Q6vWY2Nj/b7MiELYvfxwq0C7YMECN3TIg+6foX3nhQoV8vsyAYQBwi6Ay7Zjxw4XMrzAoanjGjVqEH7TgbB7+eFWBz6oeuvd36pXr86OIgDOQ9gFkOHhVz2SCiTa39cLv1rxXrduXcJvCoTdSw+3OiHwtttuI9wCSBfCLoBMs3379mSVX4VftT00aNDALRK6+eab3ZGr6gOOVoTdc/78809bvXq1rVixwhYuXOjuNydPnkyq3OrFEuEWwOUg7ALwJfwuX77cfv75ZytSpIgLMQq+3ihdunTUBOBoDLsKtlpMlpCQkDR0etnVV1/tfv9e9VbvE24B/FuEXQC+OXbsmKvmhYaen376yS0sCg2/CsPXXnttIANw0MOudvMIDbbaz3njxo1WvHjx837HJUqUCOTvGIC/CLsAwopOcluzZk2yALx+/XorUKCAC0QalSpVsvLly7tRuHBhi2RBCbvqp9XuHJs2bXJh1nsRo+/tmmuuSRZsNfQxAMgKhF0AYe/EiRNJAVhVQgUqjb1797oqsBd8Q4fCY0xMjIW7SAq7ulbtuOH9/EOHFifmypUr6WdftWrVpGCrKi4A+IWwCyCip8gVFFMLX/pcqVKlrEKFCkkB+LrrrnML4lRVLFq0aFiEy3AKu3o60NG6iYmJtmfPHtu2bVuyn+nmzZvdXrZly5ZN9QWG2hCyZcvm6/cAACkRdgEEjh7W9u/ff14AVlhTkDt8+LALlsWKFXPB1xsKa6G3NfQ1mblIKivCrn4ev/32mwuwGl6YTe222kiuuuoq972XKVPmvEAbFxfHojEAEYWwCyDqaEsrtUCkFfi89w8cOOAWTKkKrKn4fPnyueORtVew3oa+f6GP6W327Nld1VOBVm+9oYdghfBy5cq5/0vhV3vMekO31cahiqt2MQh9e7GPaRw8eNB9L+qpzZMnT7JAnzLce7fz58/PQjEAgUHYBYA0nDlzxvbt2+fCr96qNeJCQTOttxnxMJs7d+5UQ/SFAraGtnbzQqw+DgDRhrALAJlID7GqzKpCm7JqGzpCK76h76vCqqCryjAAIP0IuwAAAAgsls0CAAAgsAi7AAAACCzCLgAAAAKLsAsAAIDAIuwCAAAgsAi7AAAACCzCLgAAAAKLsAsAAIDAIuwCAAAgsAi7AAAACCzCLgAAAAKLsAsAGaB///5Ws2ZNy5s3r1199dV211132caNG5M+v337drviiitSHZMnT076up07d1rLli0tJibG/Ts9e/a0s2fPJvu/+vbta6VKlbJbb73VNm3alKXfJwBEGsIuAGSA+Ph46969u3333Xc2b948O3PmjDVp0sSOHTvmPl+6dGnbs2dPsqHQGhsba82bN3df89dff7mge/r0aVu6dKmNGzfOxo4da3369En6f5YsWWIzZ860adOmWbt27axHjx6+fc8AEAmu+Oeff/7x+yIAIGgOHDjgKrMKwfXr10/1a2666SarXr26jR492t2ePXu2tWrVyhITE61YsWLuY8OGDbOXX37Z/Xs5c+a0GTNm2KhRo1w1eOXKlfb000/bDz/8kKXfGwBEEiq7AJAJjhw54t4WKlQo1c8nJCTYqlWrrHPnzkkfW7ZsmVWtWjUp6ErTpk3t6NGjtn79+qTbJ0+edG0OzZo1c+0TAIC0Zb/A5wAAl+Hvv/+25557zurVq2dVqlRJ9WtUza1UqZLVrVs36WN79+5NFnTFu63PSY4cOWzOnDm2f/9+K1CggKv2AgDSRtgFgAym3t1169bZ4sWLU/38iRMnbMKECda7d+/L/j/UIgEAuDjaGAAgA2nBmPpq58+f73ZMSM3nn39ux48ft4cffjjZx4sXL2779u1L9jHvtj4HAEg/wi4AZACt9VXQnTJlin377bcWFxeX5teqhaFNmzZWtGjRZB+vU6eOrV271rUoeLSzQ758+axy5cqZev0AEFTsxgAAGeCpp55yrQnaEqxChQpJH8+fP7/lzp076fbmzZutfPnyNmvWLLfALJS2HqtWrZqVKFHCBg4c6Pp0O3bsaI8//ri98847Wfr9AEBQEHYBIAPocIjUjBkzxjp16pR0u1evXjZ+/Hh3yES2bOdPru3YscO6detmCxYssDx58tgjjzxiAwYMsOzZWWIBAJeDsAsAAIDAomcXAAAAgUXYBQAAQGARdgEAABBYhF0AAAAEFmEXAAAAgUXYBQAAQGARdgEAABBYhF0AAAAEFmEXAAAAgUXYBQAAQGARdgEAABBYhF0AAABYUP0Pxb9Fch1an+YAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Weight Distribution Analysis ===\n",
      "Mean norm: 1.2583\n",
      "Std norm: 2.2512\n",
      "Weight range: [-8.0090, 8.3249]\n",
      "Number of neurons: 33\n",
      "\n",
      "=== Weight Evolution ===\n",
      "Neuron counts across iterations:\n",
      "Iteration 0: 20 neurons\n",
      "Iteration 1: 30 neurons\n",
      "Iteration 2: 33 neurons\n",
      "Iteration 3: 30 neurons\n",
      "Iteration 4: 31 neurons\n",
      "Iteration 5: 30 neurons\n",
      "Iteration 6: 29 neurons\n",
      "Iteration 7: 30 neurons\n",
      "Iteration 8: 31 neurons\n",
      "Iteration 9: 30 neurons\n",
      "Iteration 10: 30 neurons\n",
      "Iteration 11: 31 neurons\n",
      "Iteration 12: 30 neurons\n",
      "Iteration 13: 30 neurons\n",
      "Iteration 14: 31 neurons\n",
      "Iteration 15: 31 neurons\n",
      "Iteration 16: 30 neurons\n",
      "Iteration 17: 30 neurons\n",
      "Iteration 18: 31 neurons\n",
      "Iteration 19: 31 neurons\n",
      "Iteration 20: 31 neurons\n",
      "Iteration 21: 31 neurons\n",
      "Iteration 22: 31 neurons\n",
      "Iteration 23: 30 neurons\n",
      "Iteration 24: 30 neurons\n",
      "Iteration 25: 31 neurons\n",
      "Iteration 26: 31 neurons\n",
      "Iteration 27: 31 neurons\n",
      "Iteration 28: 31 neurons\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PLOT: Weight space visualization in polar coordinates\n",
    "# Shows the distribution of weights in 2D space for the current training run\n",
    "# =============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Extract weights from the current training run\n",
    "weights_run = training_logger.history['weights']\n",
    "biases_run = training_logger.history['biases']\n",
    "neurons_run = training_logger.history['neuron_count']\n",
    "\n",
    "print(f\"Training run: {len(weights_run)} iterations, max neurons: {max(neurons_run)}\")\n",
    "\n",
    "# Find optimal iteration (iteration with the most neurons)\n",
    "optimal_iter = neurons_run.index(max(neurons_run))\n",
    "print(f\"Optimal iteration: {optimal_iter} with {neurons_run[optimal_iter]} neurons\")\n",
    "\n",
    "# Extract weights at optimal iteration\n",
    "weights_optimal = weights_run[optimal_iter]\n",
    "b_optimal = biases_run[optimal_iter].reshape(1, -1)   # (1, n)\n",
    "a_optimal = weights_optimal.T                         # (2, n)\n",
    "Z = a_optimal / (1 + b_optimal) \n",
    "\n",
    "# Create polar coordinate visualization\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "# Compute angles and radii in weight space (2D)\n",
    "angles = np.arctan2(Z[1], Z[0])\n",
    "xy_norms = np.linalg.norm(Z, axis=0)\n",
    "\n",
    "# Plot in polar coordinates\n",
    "ax.scatter(angles, xy_norms, color='blue', alpha=0.8, s=60)\n",
    "ax.set_title(f'Weight Space at Optimal Iteration\\nNeurons: {neurons_run[optimal_iter]}', fontsize=14)\n",
    "ax.grid(True, alpha=0.5)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('../data_result/plot/weights_polar_analysis_single.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"Polar coordinate analysis saved to ../data_result/plot/weights_polar_analysis_single.png\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Additional analysis: Weight distribution statistics\n",
    "print(\"\\n=== Weight Distribution Analysis ===\")\n",
    "print(f\"Mean norm: {np.mean(xy_norms):.4f}\")\n",
    "print(f\"Std norm: {np.std(xy_norms):.4f}\")\n",
    "print(f\"Weight range: [{weights_optimal.min():.4f}, {weights_optimal.max():.4f}]\")\n",
    "print(f\"Number of neurons: {weights_optimal.shape[0]}\")\n",
    "\n",
    "# Optional: Show weight evolution across iterations\n",
    "if len(weights_run) > 1:\n",
    "    print(f\"\\n=== Weight Evolution ===\")\n",
    "    print(\"Neuron counts across iterations:\")\n",
    "    for i, count in enumerate(neurons_run):\n",
    "        print(f\"Iteration {i}: {count} neurons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b0f71",
   "metadata": {},
   "source": [
    "## Test with the L1 Penalty ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82bceb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameter\n",
    "power = 2.1\n",
    "M = 10 # number greedy insertion selected\n",
    "num_iterations = 30\n",
    "loss_weights = (1.0, 1.0)\n",
    "pruning_threshold = 1e-13\n",
    "\n",
    "gamma = 1e-5\n",
    "alpha = 1e-1\n",
    "regularization = (gamma, alpha) \n",
    "th = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ac139d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-27 06:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_configure_logger\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mVDPModel initialized\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_configure_logger\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mVDPModel (outer weights) initialized\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 10 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=1000, batch_size=1620, display_every=200\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 32.881128\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 200: Train Loss = 3.312362, Val Loss = 4.078511\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 400: Train Loss = 2.206047, Val Loss = 2.440477\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 600: Train Loss = 2.054642, Val Loss = 2.265622\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 800: Train Loss = 1.994972, Val Loss = 2.176929\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mInitialization done\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mInitial weights shape: (10, 2), bias shape: (10,)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 0 - weights shape: (10, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.955640, Val Loss = 2.135877\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.955640, Val Loss = 2.135877\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.955640, Val Loss = 2.135877\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.955640, Val Loss = 2.135877\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.955640, Val Loss = 2.135877\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 5\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (10, 2), biases: (10,), outer_weights: (1, 10)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 5 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (5, 2), biases: (5,), outer_weights: (1, 5)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 15 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 27.652419\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.675799, Val Loss = 1.834644\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.615437, Val Loss = 1.777959\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.618790, Val Loss = 1.935294\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.555743, Val Loss = 1.729018\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.540901, Val Loss = 1.748493\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.533445, Val Loss = 1.740426\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.518187, Val Loss = 1.758393\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.515960, Val Loss = 1.774473\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.467797, Val Loss = 1.611284\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.462597, Val Loss = 1.608560\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.459088, Val Loss = 1.594310\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.460689, Val Loss = 1.574122\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.431383, Val Loss = 1.499600\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.395557, Val Loss = 1.330139\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.392281, Val Loss = 1.310039\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.362516, Val Loss = 1.249152\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.346126, Val Loss = 1.244116\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.341319, Val Loss = 1.233889\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.338648, Val Loss = 1.231108\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 0 with validation loss: 1.231108\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 0: 15 neurons, test_loss=1.231108\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 1 - weights shape: (15, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.331426, Val Loss = 1.230642\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.331426, Val Loss = 1.230642\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.331426, Val Loss = 1.230642\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.331426, Val Loss = 1.230642\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.331426, Val Loss = 1.230642\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (15, 2), biases: (15,), outer_weights: (1, 15)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (15, 2), biases: (15,), outer_weights: (1, 15)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 25 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 6.497543\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.330776, Val Loss = 1.232184\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.329066, Val Loss = 1.232440\u001b[0m\n",
      "\u001b[32m2025-08-27 06:17:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.327519, Val Loss = 1.230163\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.326750, Val Loss = 1.227950\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.325957, Val Loss = 1.227350\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.325465, Val Loss = 1.225896\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.330528, Val Loss = 1.254198\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.324788, Val Loss = 1.224610\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.324810, Val Loss = 1.224723\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.324567, Val Loss = 1.224115\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.368107, Val Loss = 1.322332\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.323045, Val Loss = 1.217764\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.321006, Val Loss = 1.209438\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.319355, Val Loss = 1.207393\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.317674, Val Loss = 1.205547\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.317387, Val Loss = 1.204720\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.434562, Val Loss = 1.231833\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.315970, Val Loss = 1.203777\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.318065, Val Loss = 1.202088\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 1 with validation loss: 1.202088\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 1: 25 neurons, test_loss=1.202088\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 2 - weights shape: (25, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.315938, Val Loss = 1.203348\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.315938, Val Loss = 1.203348\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.315938, Val Loss = 1.203348\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.315938, Val Loss = 1.203348\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.315938, Val Loss = 1.203348\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 4\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (25, 2), biases: (25,), outer_weights: (1, 25)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 4 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 30 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 9.375617\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.315385, Val Loss = 1.202524\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.316438, Val Loss = 1.209229\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.348576, Val Loss = 1.328257\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.313141, Val Loss = 1.199889\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.312860, Val Loss = 1.200118\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.317637, Val Loss = 1.270422\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.328498, Val Loss = 1.389753\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.405206, Val Loss = 1.631735\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.312666, Val Loss = 1.199584\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.313065, Val Loss = 1.199196\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.306826, Val Loss = 1.199997\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.297163, Val Loss = 1.199945\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.295019, Val Loss = 1.199417\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.294090, Val Loss = 1.198753\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.293876, Val Loss = 1.198522\u001b[0m\n",
      "\u001b[32m2025-08-27 06:18:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.293591, Val Loss = 1.198706\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.293263, Val Loss = 1.199083\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.292621, Val Loss = 1.199624\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.292402, Val Loss = 1.200794\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 2 with validation loss: 1.200794\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 2: 30 neurons, test_loss=1.200794\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 3 - weights shape: (30, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.292004, Val Loss = 1.200703\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.292004, Val Loss = 1.200703\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.292004, Val Loss = 1.200703\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.292004, Val Loss = 1.200703\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.292004, Val Loss = 1.200703\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (30, 2), biases: (30,), outer_weights: (1, 30)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (20, 2), biases: (20,), outer_weights: (1, 20)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 30 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 7.673372\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.292252, Val Loss = 1.201629\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.290928, Val Loss = 1.200074\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.292250, Val Loss = 1.205795\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.304326, Val Loss = 1.220411\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.290942, Val Loss = 1.201611\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.291057, Val Loss = 1.201976\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.290844, Val Loss = 1.202082\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.316563, Val Loss = 1.234489\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.290926, Val Loss = 1.202235\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.291151, Val Loss = 1.202615\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.290885, Val Loss = 1.202014\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.290415, Val Loss = 1.201861\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.290731, Val Loss = 1.202478\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.290753, Val Loss = 1.202677\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.290420, Val Loss = 1.202036\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.290301, Val Loss = 1.201829\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.289696, Val Loss = 1.201654\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.290295, Val Loss = 1.201958\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.290967, Val Loss = 1.202929\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 3: 30 neurons, test_loss=1.202929\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 4 - weights shape: (30, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.290144, Val Loss = 1.204879\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.290144, Val Loss = 1.204879\u001b[0m\n",
      "\u001b[32m2025-08-27 06:19:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.290144, Val Loss = 1.204879\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.290144, Val Loss = 1.204879\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.290144, Val Loss = 1.204879\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 8\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (30, 2), biases: (30,), outer_weights: (1, 30)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 8 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 32 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 7.086970\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.289711, Val Loss = 1.201759\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.288563, Val Loss = 1.199505\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.288716, Val Loss = 1.201482\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.288953, Val Loss = 1.200940\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.289862, Val Loss = 1.200248\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.289111, Val Loss = 1.201732\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.289694, Val Loss = 1.201999\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.290069, Val Loss = 1.201392\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.289115, Val Loss = 1.200975\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.340875, Val Loss = 1.224798\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.293124, Val Loss = 1.226137\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.289370, Val Loss = 1.201629\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.289519, Val Loss = 1.201566\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.288901, Val Loss = 1.201355\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.291970, Val Loss = 1.200467\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.289360, Val Loss = 1.201689\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.289452, Val Loss = 1.201777\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.292059, Val Loss = 1.205380\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.289751, Val Loss = 1.202119\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 4: 32 neurons, test_loss=1.202119\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 5 - weights shape: (32, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.331907, Val Loss = 1.334801\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.331907, Val Loss = 1.334801\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.331907, Val Loss = 1.334801\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.331907, Val Loss = 1.334801\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.331907, Val Loss = 1.334801\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (32, 2), biases: (32,), outer_weights: (1, 32)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 32 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 7.326946\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.288907, Val Loss = 1.201403\u001b[0m\n",
      "\u001b[32m2025-08-27 06:20:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.287913, Val Loss = 1.200059\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.288278, Val Loss = 1.199523\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.288081, Val Loss = 1.200329\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.288046, Val Loss = 1.198968\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.332916, Val Loss = 1.320078\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.288804, Val Loss = 1.200299\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.526014, Val Loss = 1.732099\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.289158, Val Loss = 1.200814\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.289183, Val Loss = 1.201005\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.289072, Val Loss = 1.201362\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.288791, Val Loss = 1.201099\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.289913, Val Loss = 1.201044\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.288892, Val Loss = 1.201168\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.289778, Val Loss = 1.201252\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.288855, Val Loss = 1.201371\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.289351, Val Loss = 1.201329\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.289048, Val Loss = 1.201859\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.290224, Val Loss = 1.201572\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 5: 32 neurons, test_loss=1.201572\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 6 - weights shape: (32, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.288973, Val Loss = 1.201439\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.288973, Val Loss = 1.201439\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.288973, Val Loss = 1.201439\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.288973, Val Loss = 1.201439\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.288973, Val Loss = 1.201439\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (32, 2), biases: (32,), outer_weights: (1, 32)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 32 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 6.978685\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.288819, Val Loss = 1.202773\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.287670, Val Loss = 1.200131\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.288099, Val Loss = 1.201130\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.289378, Val Loss = 1.199062\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.310684, Val Loss = 1.242843\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.491223, Val Loss = 1.900828\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.288587, Val Loss = 1.200690\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.288959, Val Loss = 1.199407\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.288700, Val Loss = 1.199951\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.288285, Val Loss = 1.201138\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.288768, Val Loss = 1.200494\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.301423, Val Loss = 1.240113\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.288531, Val Loss = 1.200754\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.694345, Val Loss = 2.285377\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.289373, Val Loss = 1.200500\u001b[0m\n",
      "\u001b[32m2025-08-27 06:21:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.290112, Val Loss = 1.203685\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.288606, Val Loss = 1.201510\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.289156, Val Loss = 1.202617\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.288504, Val Loss = 1.201421\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 6: 32 neurons, test_loss=1.201421\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 7 - weights shape: (32, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.289198, Val Loss = 1.201786\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.289198, Val Loss = 1.201786\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.289198, Val Loss = 1.201786\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.289198, Val Loss = 1.201786\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.289198, Val Loss = 1.201786\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (32, 2), biases: (32,), outer_weights: (1, 32)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 32 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 6.028716\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.288634, Val Loss = 1.201654\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.287691, Val Loss = 1.199374\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.293091, Val Loss = 1.207188\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.289279, Val Loss = 1.205101\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.353631, Val Loss = 1.225786\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.288354, Val Loss = 1.203973\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.333165, Val Loss = 1.230605\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.544502, Val Loss = 1.886792\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.288661, Val Loss = 1.200061\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.288713, Val Loss = 1.210436\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.288991, Val Loss = 1.199415\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.289762, Val Loss = 1.199862\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.288338, Val Loss = 1.200847\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.288418, Val Loss = 1.200862\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.288180, Val Loss = 1.200389\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.288425, Val Loss = 1.201115\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.288097, Val Loss = 1.200567\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.288606, Val Loss = 1.200969\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.289641, Val Loss = 1.214527\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 7: 32 neurons, test_loss=1.214527\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 8 - weights shape: (32, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.288462, Val Loss = 1.200993\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.288462, Val Loss = 1.200993\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.288462, Val Loss = 1.200993\u001b[0m\n",
      "\u001b[32m2025-08-27 06:22:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.288462, Val Loss = 1.200993\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.288462, Val Loss = 1.200993\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (32, 2), biases: (32,), outer_weights: (1, 32)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 32 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 6.558134\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.288201, Val Loss = 1.200876\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.287139, Val Loss = 1.198883\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.287133, Val Loss = 1.200702\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.287535, Val Loss = 1.200243\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.287618, Val Loss = 1.199770\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.288122, Val Loss = 1.198733\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.289437, Val Loss = 1.200306\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.574482, Val Loss = 1.606143\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.288050, Val Loss = 1.200482\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.288163, Val Loss = 1.200143\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.288888, Val Loss = 1.200417\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.343801, Val Loss = 1.392837\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.287915, Val Loss = 1.200336\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.288205, Val Loss = 1.200340\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.288438, Val Loss = 1.200755\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.288923, Val Loss = 1.202077\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.288321, Val Loss = 1.200661\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.288371, Val Loss = 1.200967\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.289812, Val Loss = 1.217047\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 8: 32 neurons, test_loss=1.217047\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 9 - weights shape: (32, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.288585, Val Loss = 1.201090\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.288585, Val Loss = 1.201090\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.288585, Val Loss = 1.201090\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.288585, Val Loss = 1.201090\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.288585, Val Loss = 1.201090\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (32, 2), biases: (32,), outer_weights: (1, 32)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 31 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 6.499435\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.287973, Val Loss = 1.200994\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.286848, Val Loss = 1.199377\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.287057, Val Loss = 1.199328\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.287068, Val Loss = 1.199047\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.287430, Val Loss = 1.199749\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.287622, Val Loss = 1.199809\u001b[0m\n",
      "\u001b[32m2025-08-27 06:23:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.287614, Val Loss = 1.200048\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.287441, Val Loss = 1.199439\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.287454, Val Loss = 1.199907\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.322160, Val Loss = 1.203877\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.313508, Val Loss = 1.200853\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.287645, Val Loss = 1.198821\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.287831, Val Loss = 1.200286\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.287949, Val Loss = 1.200187\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.287767, Val Loss = 1.200115\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.288624, Val Loss = 1.200803\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.287932, Val Loss = 1.200424\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.294309, Val Loss = 1.212815\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.288287, Val Loss = 1.200333\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 9 with validation loss: 1.200333\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 9: 31 neurons, test_loss=1.200333\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 10 - weights shape: (31, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.288934, Val Loss = 1.201832\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.288934, Val Loss = 1.201832\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.288934, Val Loss = 1.201832\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.288934, Val Loss = 1.201832\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.288934, Val Loss = 1.201832\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (31, 2), biases: (31,), outer_weights: (1, 31)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 30 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 5.957717\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.288082, Val Loss = 1.201708\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.286911, Val Loss = 1.199703\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.287111, Val Loss = 1.201081\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.287121, Val Loss = 1.198796\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.287433, Val Loss = 1.199714\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.287605, Val Loss = 1.200370\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.471918, Val Loss = 1.683254\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.288800, Val Loss = 1.199117\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.287864, Val Loss = 1.200926\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.287609, Val Loss = 1.200805\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.287768, Val Loss = 1.200832\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.288326, Val Loss = 1.201222\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.288615, Val Loss = 1.211926\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.294952, Val Loss = 1.255472\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.305159, Val Loss = 1.215453\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.287522, Val Loss = 1.201096\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.287868, Val Loss = 1.200854\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.288091, Val Loss = 1.201878\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.287699, Val Loss = 1.200961\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 10: 30 neurons, test_loss=1.200961\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 11 - weights shape: (30, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:24:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.287921, Val Loss = 1.200673\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.287921, Val Loss = 1.200673\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.287921, Val Loss = 1.200673\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.287921, Val Loss = 1.200673\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.287921, Val Loss = 1.200673\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 9\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (30, 2), biases: (30,), outer_weights: (1, 30)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 9 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 31 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 5.234469\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.287677, Val Loss = 1.200788\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.286800, Val Loss = 1.198536\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.287807, Val Loss = 1.200377\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.286958, Val Loss = 1.199639\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.287195, Val Loss = 1.200778\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.287267, Val Loss = 1.199919\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.287191, Val Loss = 1.200260\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.300071, Val Loss = 1.267309\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.444869, Val Loss = 1.351497\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.411551, Val Loss = 1.499372\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.287767, Val Loss = 1.200374\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.288105, Val Loss = 1.200730\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.287155, Val Loss = 1.200304\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.288302, Val Loss = 1.350831\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.287621, Val Loss = 1.200300\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.287593, Val Loss = 1.200121\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.287721, Val Loss = 1.200031\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.287872, Val Loss = 1.200115\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.349642, Val Loss = 1.384919\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 11: 31 neurons, test_loss=1.384919\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 12 - weights shape: (31, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.287768, Val Loss = 1.200372\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.287768, Val Loss = 1.200372\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.287768, Val Loss = 1.200372\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.287768, Val Loss = 1.200372\u001b[0m\n",
      "\u001b[32m2025-08-27 06:25:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.287768, Val Loss = 1.200372\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 9\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (31, 2), biases: (31,), outer_weights: (1, 31)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 9 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 32 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 5.736575\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.287223, Val Loss = 1.200489\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.286365, Val Loss = 1.198742\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.286937, Val Loss = 1.198093\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.286688, Val Loss = 1.198435\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.286749, Val Loss = 1.198776\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.287017, Val Loss = 1.199473\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.286735, Val Loss = 1.199046\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.291262, Val Loss = 1.201794\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.288133, Val Loss = 1.199087\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.287748, Val Loss = 1.208678\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.287698, Val Loss = 1.316023\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.287359, Val Loss = 1.200122\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.287745, Val Loss = 1.200231\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.288417, Val Loss = 1.200019\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.287371, Val Loss = 1.200016\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.288087, Val Loss = 1.200491\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.288049, Val Loss = 1.200191\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.295246, Val Loss = 1.220359\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.287781, Val Loss = 1.200388\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 12: 32 neurons, test_loss=1.200388\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 13 - weights shape: (32, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.288130, Val Loss = 1.200327\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.288130, Val Loss = 1.200327\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.288130, Val Loss = 1.200327\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.288130, Val Loss = 1.200327\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.288130, Val Loss = 1.200327\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (32, 2), biases: (32,), outer_weights: (1, 32)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 32 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 5.273983\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.287288, Val Loss = 1.200747\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.286389, Val Loss = 1.199162\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.287048, Val Loss = 1.199504\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.308806, Val Loss = 1.250272\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.286916, Val Loss = 1.198596\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.287422, Val Loss = 1.216909\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.287214, Val Loss = 1.198661\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.286971, Val Loss = 1.199566\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.288129, Val Loss = 1.199425\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.291373, Val Loss = 1.199799\u001b[0m\n",
      "\u001b[32m2025-08-27 06:26:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.287219, Val Loss = 1.199365\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.287729, Val Loss = 1.199784\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.669559, Val Loss = 2.053401\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.287695, Val Loss = 1.200054\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.287168, Val Loss = 1.199410\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.287060, Val Loss = 1.199594\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.287362, Val Loss = 1.199786\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.287077, Val Loss = 1.199707\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.287688, Val Loss = 1.200235\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 13 with validation loss: 1.200235\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 13: 32 neurons, test_loss=1.200235\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 14 - weights shape: (32, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.286912, Val Loss = 1.199442\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286912, Val Loss = 1.199442\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.286912, Val Loss = 1.199442\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.286912, Val Loss = 1.199442\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.286912, Val Loss = 1.199442\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (32, 2), biases: (32,), outer_weights: (1, 32)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 32 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 5.579536\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286860, Val Loss = 1.200415\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.286422, Val Loss = 1.197637\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.289564, Val Loss = 1.204131\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.286077, Val Loss = 1.196482\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.287040, Val Loss = 1.197872\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.286872, Val Loss = 1.198689\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.287099, Val Loss = 1.199890\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.292266, Val Loss = 1.199563\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.286770, Val Loss = 1.198344\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.286886, Val Loss = 1.198795\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.287581, Val Loss = 1.199035\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.288713, Val Loss = 1.217002\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.287117, Val Loss = 1.198403\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.286851, Val Loss = 1.198870\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.286803, Val Loss = 1.198633\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.286778, Val Loss = 1.198663\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.287511, Val Loss = 1.198982\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.286806, Val Loss = 1.198687\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.287334, Val Loss = 1.198986\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 14 with validation loss: 1.198986\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 14: 32 neurons, test_loss=1.198986\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 15 - weights shape: (32, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.496799, Val Loss = 1.636057\u001b[0m\n",
      "\u001b[32m2025-08-27 06:27:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.496799, Val Loss = 1.636057\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.496799, Val Loss = 1.636057\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.496799, Val Loss = 1.636057\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.496799, Val Loss = 1.636057\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (32, 2), biases: (32,), outer_weights: (1, 32)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 32 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 7.906127\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286716, Val Loss = 1.198910\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.285819, Val Loss = 1.197337\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.286406, Val Loss = 1.199833\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.286169, Val Loss = 1.197434\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.328468, Val Loss = 1.217919\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.286617, Val Loss = 1.197447\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.287169, Val Loss = 1.197735\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.287282, Val Loss = 1.197425\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.287750, Val Loss = 1.198397\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.287641, Val Loss = 1.198076\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.287198, Val Loss = 1.197190\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.287488, Val Loss = 1.197654\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.286866, Val Loss = 1.197823\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.289800, Val Loss = 1.209119\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.287719, Val Loss = 1.197904\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.429507, Val Loss = 1.820296\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.287397, Val Loss = 1.198022\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.288316, Val Loss = 1.197637\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.287366, Val Loss = 1.197821\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 15 with validation loss: 1.197821\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 15: 32 neurons, test_loss=1.197821\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 16 - weights shape: (32, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.287513, Val Loss = 1.198061\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.287513, Val Loss = 1.198061\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.287513, Val Loss = 1.198061\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.287513, Val Loss = 1.198061\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.287513, Val Loss = 1.198061\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (32, 2), biases: (32,), outer_weights: (1, 32)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 32 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:28:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 5.313809\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286826, Val Loss = 1.198216\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.285887, Val Loss = 1.197358\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.337156, Val Loss = 1.383570\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.288739, Val Loss = 1.206084\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.286466, Val Loss = 1.196967\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.286718, Val Loss = 1.197261\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.286536, Val Loss = 1.197018\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.286530, Val Loss = 1.197188\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.286849, Val Loss = 1.197285\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.286903, Val Loss = 1.197382\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.287601, Val Loss = 1.197665\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.287194, Val Loss = 1.197474\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.287192, Val Loss = 1.196530\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.286695, Val Loss = 1.197319\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.286837, Val Loss = 1.197389\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.287004, Val Loss = 1.197228\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.287024, Val Loss = 1.197353\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.293036, Val Loss = 1.197674\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.286679, Val Loss = 1.197125\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 16 with validation loss: 1.197125\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 16: 32 neurons, test_loss=1.197125\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 17 - weights shape: (32, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.286757, Val Loss = 1.197212\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286757, Val Loss = 1.197212\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.286757, Val Loss = 1.197212\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.286757, Val Loss = 1.197212\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.286757, Val Loss = 1.197212\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (32, 2), biases: (32,), outer_weights: (1, 32)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 32 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 5.389151\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286504, Val Loss = 1.197012\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.285844, Val Loss = 1.197570\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.288639, Val Loss = 1.209904\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.286412, Val Loss = 1.195573\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.293682, Val Loss = 1.211671\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.286892, Val Loss = 1.197756\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.286991, Val Loss = 1.260287\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.287232, Val Loss = 1.199629\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.288328, Val Loss = 1.196805\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.287086, Val Loss = 1.197207\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.287191, Val Loss = 1.196562\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.293818, Val Loss = 1.197905\u001b[0m\n",
      "\u001b[32m2025-08-27 06:29:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.286915, Val Loss = 1.196814\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.287133, Val Loss = 1.197022\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.286835, Val Loss = 1.197157\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.287729, Val Loss = 1.197396\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.287152, Val Loss = 1.196953\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.287355, Val Loss = 1.197452\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.287495, Val Loss = 1.197588\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 17: 32 neurons, test_loss=1.197588\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 18 - weights shape: (32, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.287970, Val Loss = 1.197988\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.287970, Val Loss = 1.197988\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.287970, Val Loss = 1.197988\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.287970, Val Loss = 1.197988\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.287970, Val Loss = 1.197988\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (32, 2), biases: (32,), outer_weights: (1, 32)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 32 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 5.042541\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286924, Val Loss = 1.198304\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.286423, Val Loss = 1.196505\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.286126, Val Loss = 1.195939\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.286604, Val Loss = 1.195247\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.286713, Val Loss = 1.195540\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.287516, Val Loss = 1.196027\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.286622, Val Loss = 1.196687\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.286928, Val Loss = 1.196828\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.286833, Val Loss = 1.197167\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.287415, Val Loss = 1.197637\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.287152, Val Loss = 1.196960\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.288090, Val Loss = 1.196299\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.288179, Val Loss = 1.199712\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.286504, Val Loss = 1.197010\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.286491, Val Loss = 1.196936\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.286996, Val Loss = 1.196961\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.288076, Val Loss = 1.197775\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.286634, Val Loss = 1.197386\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.287113, Val Loss = 1.197040\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 18 with validation loss: 1.197040\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 18: 32 neurons, test_loss=1.197040\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 19 - weights shape: (32, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.286948, Val Loss = 1.197125\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286948, Val Loss = 1.197125\u001b[0m\n",
      "\u001b[32m2025-08-27 06:30:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.286948, Val Loss = 1.197125\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.286948, Val Loss = 1.197125\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.286948, Val Loss = 1.197125\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (32, 2), biases: (32,), outer_weights: (1, 32)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 32 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 5.397697\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286521, Val Loss = 1.197337\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.285635, Val Loss = 1.195993\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.288888, Val Loss = 1.203105\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.286148, Val Loss = 1.195380\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.290485, Val Loss = 1.203650\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.286353, Val Loss = 1.195777\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.286668, Val Loss = 1.196495\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.286647, Val Loss = 1.196915\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.287635, Val Loss = 1.201776\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.286928, Val Loss = 1.197235\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.286914, Val Loss = 1.197010\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.287487, Val Loss = 1.196658\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.381433, Val Loss = 1.251993\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.287131, Val Loss = 1.197116\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.288212, Val Loss = 1.197036\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.287264, Val Loss = 1.196681\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.286469, Val Loss = 1.196626\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.286902, Val Loss = 1.197117\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.286846, Val Loss = 1.196717\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 19 with validation loss: 1.196717\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 19: 32 neurons, test_loss=1.196717\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 20 - weights shape: (32, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.287046, Val Loss = 1.196749\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.287046, Val Loss = 1.196749\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.287046, Val Loss = 1.196749\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.287046, Val Loss = 1.196749\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.287046, Val Loss = 1.196749\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (32, 2), biases: (32,), outer_weights: (1, 32)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 32 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 5.103714\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286773, Val Loss = 1.197925\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.285697, Val Loss = 1.197697\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.288419, Val Loss = 1.208481\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.286059, Val Loss = 1.195796\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.313798, Val Loss = 1.220261\u001b[0m\n",
      "\u001b[32m2025-08-27 06:31:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.286996, Val Loss = 1.196047\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.286883, Val Loss = 1.196096\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.286543, Val Loss = 1.196532\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.287047, Val Loss = 1.198602\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.286779, Val Loss = 1.196761\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.287559, Val Loss = 1.197039\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.288174, Val Loss = 1.198898\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.288312, Val Loss = 1.199866\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.287531, Val Loss = 1.197173\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.286866, Val Loss = 1.197433\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.288088, Val Loss = 1.198054\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.286984, Val Loss = 1.197030\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.286856, Val Loss = 1.197132\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.288228, Val Loss = 1.201911\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 20: 32 neurons, test_loss=1.201911\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 21 - weights shape: (32, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.302709, Val Loss = 1.219830\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.302709, Val Loss = 1.219830\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.302709, Val Loss = 1.219830\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.302709, Val Loss = 1.219830\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.302709, Val Loss = 1.219830\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (32, 2), biases: (32,), outer_weights: (1, 32)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 32 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 4.923956\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286990, Val Loss = 1.198201\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.286061, Val Loss = 1.197868\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.286344, Val Loss = 1.194848\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.286092, Val Loss = 1.196632\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.286164, Val Loss = 1.196206\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.286359, Val Loss = 1.195841\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.286731, Val Loss = 1.197043\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.286899, Val Loss = 1.196182\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.286680, Val Loss = 1.196962\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.287161, Val Loss = 1.197235\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.286644, Val Loss = 1.197088\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.286782, Val Loss = 1.196813\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.287603, Val Loss = 1.197633\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.286915, Val Loss = 1.196758\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.286825, Val Loss = 1.196778\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.287011, Val Loss = 1.197335\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.287021, Val Loss = 1.197006\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.287384, Val Loss = 1.196833\u001b[0m\n",
      "\u001b[32m2025-08-27 06:32:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.286587, Val Loss = 1.197020\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 21: 32 neurons, test_loss=1.197020\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 22 - weights shape: (32, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.286451, Val Loss = 1.196676\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286451, Val Loss = 1.196676\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.286451, Val Loss = 1.196676\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.286451, Val Loss = 1.196676\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.286451, Val Loss = 1.196676\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (32, 2), biases: (32,), outer_weights: (1, 32)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 31 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 5.498578\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286347, Val Loss = 1.196283\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.285611, Val Loss = 1.196936\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.303803, Val Loss = 1.201279\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.286270, Val Loss = 1.195652\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.385297, Val Loss = 1.292718\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.328609, Val Loss = 1.382477\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.287834, Val Loss = 1.198771\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.287184, Val Loss = 1.198137\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.286511, Val Loss = 1.196904\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.287417, Val Loss = 1.196118\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.287218, Val Loss = 1.197815\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.286641, Val Loss = 1.196003\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.286550, Val Loss = 1.196661\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.288084, Val Loss = 1.196752\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.286661, Val Loss = 1.196725\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.287260, Val Loss = 1.197411\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.286598, Val Loss = 1.196815\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.286719, Val Loss = 1.196823\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.286563, Val Loss = 1.196789\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 22: 31 neurons, test_loss=1.196789\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 23 - weights shape: (31, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.286779, Val Loss = 1.196988\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286779, Val Loss = 1.196988\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.286779, Val Loss = 1.196988\u001b[0m\n",
      "\u001b[32m2025-08-27 06:33:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.286779, Val Loss = 1.196988\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.286779, Val Loss = 1.196988\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (31, 2), biases: (31,), outer_weights: (1, 31)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (21, 2), biases: (21,), outer_weights: (1, 21)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 31 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 5.373238\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286320, Val Loss = 1.196875\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.285520, Val Loss = 1.195694\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.298188, Val Loss = 1.235318\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.285755, Val Loss = 1.194630\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.287001, Val Loss = 1.194972\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.286104, Val Loss = 1.195730\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.286464, Val Loss = 1.196194\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.316826, Val Loss = 1.330114\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.289735, Val Loss = 1.200020\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.286483, Val Loss = 1.196638\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.286760, Val Loss = 1.196639\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.287386, Val Loss = 1.196060\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.286814, Val Loss = 1.196678\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.287137, Val Loss = 1.197338\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.286679, Val Loss = 1.196922\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.287004, Val Loss = 1.196751\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.286836, Val Loss = 1.196933\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.286488, Val Loss = 1.196776\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.286643, Val Loss = 1.196948\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 23: 31 neurons, test_loss=1.196948\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 24 - weights shape: (31, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.286834, Val Loss = 1.197041\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286834, Val Loss = 1.197041\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.286834, Val Loss = 1.197041\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.286834, Val Loss = 1.197041\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.286834, Val Loss = 1.197041\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 9\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (31, 2), biases: (31,), outer_weights: (1, 31)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 9 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 32 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 5.538673\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286381, Val Loss = 1.197834\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.285447, Val Loss = 1.195565\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.285980, Val Loss = 1.195194\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.286072, Val Loss = 1.195812\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.286394, Val Loss = 1.195534\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.329112, Val Loss = 1.264583\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.286211, Val Loss = 1.196615\u001b[0m\n",
      "\u001b[32m2025-08-27 06:34:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.286426, Val Loss = 1.196589\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.286638, Val Loss = 1.196967\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.531498, Val Loss = 1.532059\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.287742, Val Loss = 1.197648\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.286304, Val Loss = 1.196657\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.286582, Val Loss = 1.196968\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.286756, Val Loss = 1.196699\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.286767, Val Loss = 1.196656\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.286839, Val Loss = 1.196786\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.286911, Val Loss = 1.197198\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.287150, Val Loss = 1.196963\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.287239, Val Loss = 1.197217\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 24: 32 neurons, test_loss=1.197217\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 25 - weights shape: (32, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.287229, Val Loss = 1.196947\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.287229, Val Loss = 1.196947\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.287229, Val Loss = 1.196947\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.287229, Val Loss = 1.196947\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.287229, Val Loss = 1.196947\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (32, 2), biases: (32,), outer_weights: (1, 32)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 32 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 5.298360\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286641, Val Loss = 1.198201\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.285815, Val Loss = 1.196225\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.286125, Val Loss = 1.197772\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.286038, Val Loss = 1.196205\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.287867, Val Loss = 1.198605\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.286577, Val Loss = 1.199501\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.286537, Val Loss = 1.195773\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.286466, Val Loss = 1.196215\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.286773, Val Loss = 1.196352\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.334151, Val Loss = 1.478205\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.296423, Val Loss = 1.208008\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.287135, Val Loss = 1.196150\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.286694, Val Loss = 1.196909\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.287181, Val Loss = 1.197144\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.286509, Val Loss = 1.196911\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.286589, Val Loss = 1.196527\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.287297, Val Loss = 1.197129\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.287102, Val Loss = 1.197216\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.287986, Val Loss = 1.196972\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 25: 32 neurons, test_loss=1.196972\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 26 - weights shape: (32, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.286809, Val Loss = 1.197077\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286809, Val Loss = 1.197077\u001b[0m\n",
      "\u001b[32m2025-08-27 06:35:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.286809, Val Loss = 1.197077\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.286809, Val Loss = 1.197077\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.286809, Val Loss = 1.197077\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (32, 2), biases: (32,), outer_weights: (1, 32)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 32 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 5.650063\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286187, Val Loss = 1.196566\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.285690, Val Loss = 1.197995\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.362518, Val Loss = 1.423448\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.286094, Val Loss = 1.196331\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.285895, Val Loss = 1.195251\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.286345, Val Loss = 1.195587\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.286098, Val Loss = 1.195865\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.286243, Val Loss = 1.195796\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.286980, Val Loss = 1.196777\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.286530, Val Loss = 1.196464\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.286759, Val Loss = 1.196105\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.474728, Val Loss = 1.799517\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.286284, Val Loss = 1.196996\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.291532, Val Loss = 1.197972\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.290353, Val Loss = 1.202189\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.286440, Val Loss = 1.196779\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.286874, Val Loss = 1.197232\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.286751, Val Loss = 1.197066\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.286737, Val Loss = 1.196791\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 26: 32 neurons, test_loss=1.196791\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 27 - weights shape: (32, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.287336, Val Loss = 1.197471\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.287336, Val Loss = 1.197471\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.287336, Val Loss = 1.197471\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.287336, Val Loss = 1.197471\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.287336, Val Loss = 1.197471\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (32, 2), biases: (32,), outer_weights: (1, 32)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 32 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 5.082415\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286567, Val Loss = 1.197545\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.285948, Val Loss = 1.197654\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.286639, Val Loss = 1.200928\u001b[0m\n",
      "\u001b[32m2025-08-27 06:36:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.285795, Val Loss = 1.196743\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.286141, Val Loss = 1.195938\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.286386, Val Loss = 1.196290\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.286054, Val Loss = 1.196766\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.286871, Val Loss = 1.196669\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.292617, Val Loss = 1.197087\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.286736, Val Loss = 1.196605\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.286260, Val Loss = 1.196634\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.286807, Val Loss = 1.197059\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.331314, Val Loss = 1.521934\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.286878, Val Loss = 1.196521\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.287073, Val Loss = 1.197230\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.294710, Val Loss = 1.218926\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.298731, Val Loss = 1.255250\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.287174, Val Loss = 1.197202\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.286838, Val Loss = 1.197399\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 27: 32 neurons, test_loss=1.197399\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 28 - weights shape: (32, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=1e-05, th=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 1.287497, Val Loss = 1.197472\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.287497, Val Loss = 1.197472\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.287497, Val Loss = 1.197472\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.287497, Val Loss = 1.197472\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.287497, Val Loss = 1.197472\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_outerweights_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m377\u001b[0m - \u001b[1mTraining completed successfully (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mSmall weights count: 10\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mprune_small_weights - weights: (32, 2), biases: (32,), outer_weights: (1, 32)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mPruning 10 neurons with small weights\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mprune_small_weights\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mAfter pruning - weights: (22, 2), biases: (22,), outer_weights: (1, 22)\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 32 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=20000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 5.329475\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 1.286607, Val Loss = 1.198011\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 1.286103, Val Loss = 1.198789\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 1.332049, Val Loss = 1.323912\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 4000: Train Loss = 1.285757, Val Loss = 1.196136\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 5000: Train Loss = 1.286034, Val Loss = 1.196735\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 6000: Train Loss = 1.287644, Val Loss = 1.195299\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 7000: Train Loss = 1.286602, Val Loss = 1.195788\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 8000: Train Loss = 1.286268, Val Loss = 1.196255\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 9000: Train Loss = 1.286382, Val Loss = 1.196482\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 10000: Train Loss = 1.286613, Val Loss = 1.196414\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 11000: Train Loss = 1.286569, Val Loss = 1.197159\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 12000: Train Loss = 1.287006, Val Loss = 1.196834\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 13000: Train Loss = 1.287363, Val Loss = 1.197584\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 14000: Train Loss = 1.286972, Val Loss = 1.196752\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 15000: Train Loss = 1.286642, Val Loss = 1.196495\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 16000: Train Loss = 1.286776, Val Loss = 1.196884\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 17000: Train Loss = 1.294900, Val Loss = 1.196987\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 18000: Train Loss = 1.286615, Val Loss = 1.196520\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 19000: Train Loss = 1.286446, Val Loss = 1.196669\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mNew best model found at iteration 28 with validation loss: 1.196669\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mlog_iteration\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mIteration 28: 32 neurons, test_loss=1.196669\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36msave\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mSaved training history to /Users/ruizhechao/Documents/NNforHJB/data_result/weights/training_history_20250827_063757.pkl\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1mTraining completed. History saved to /Users/ruizhechao/Documents/NNforHJB/data_result/weights/training_history_20250827_063757.pkl\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mBest validation loss: 1.196669\u001b[0m\n",
      "\u001b[32m2025-08-27 06:37:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mTraining completed with improved logging\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to Python path so model.py can find ssn and net modules\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from src.model import model\n",
    "from src.model_outerweights import model_outerweights\n",
    "from src.greedy_insertion import insertion\n",
    "from src.training_logger import run_training_with_logging\n",
    "\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "import torch\n",
    "# Initialize the model \n",
    "model_1 = model(data, torch.relu, power, regularization, optimizer='Adam', loss_weights = loss_weights)\n",
    "model_2 = model_outerweights(data, torch.relu, power, regularization, optimizer='SSN_TR', loss_weights = loss_weights, th = th)\n",
    "# Set up the initializing weights and bias\n",
    "init_weights = np.random.randn(M, 2) * 0.1\n",
    "init_bias = np.random.randn(M)\n",
    "\n",
    "model_result, weight_raw, bias_raw, outerweight_raw = model_1.train(\n",
    "    iterations=1000,\n",
    "    display_every=200,\n",
    "    inner_weights=init_weights, inner_bias=init_bias,\n",
    ")\n",
    "logger.info(\"Initialization done\"); logger.info(f\"Initial weights shape: {weight_raw.shape}, bias shape: {bias_raw.shape}\")\n",
    "\n",
    "# Training with improved logging\n",
    "training_logger_1, weight_raw_1, bias_raw_1, outerweight_raw_1 = run_training_with_logging(\n",
    "    data, model_1, model_2, model_result, weight_raw, bias_raw, outerweight_raw,\n",
    "    num_iterations, M, alpha, pruning_threshold, power, gamma\n",
    ")\n",
    "\n",
    "logger.info(\"Training completed with improved logging\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4b6c4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training run: 29 iterations, max neurons: 32\n",
      "Optimal iteration: 4 with 32 neurons\n",
      "Polar coordinate analysis saved to ../data_result/plot/weights_polar_analysis_single.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Weight Distribution Analysis ===\n",
      "Mean norm: 1.7915\n",
      "Std norm: 4.7037\n",
      "Weight range: [-9.3928, 9.9717]\n",
      "Number of neurons: 32\n",
      "\n",
      "=== Weight Evolution ===\n",
      "Neuron counts across iterations:\n",
      "Iteration 0: 15 neurons\n",
      "Iteration 1: 25 neurons\n",
      "Iteration 2: 30 neurons\n",
      "Iteration 3: 30 neurons\n",
      "Iteration 4: 32 neurons\n",
      "Iteration 5: 32 neurons\n",
      "Iteration 6: 32 neurons\n",
      "Iteration 7: 32 neurons\n",
      "Iteration 8: 32 neurons\n",
      "Iteration 9: 31 neurons\n",
      "Iteration 10: 30 neurons\n",
      "Iteration 11: 31 neurons\n",
      "Iteration 12: 32 neurons\n",
      "Iteration 13: 32 neurons\n",
      "Iteration 14: 32 neurons\n",
      "Iteration 15: 32 neurons\n",
      "Iteration 16: 32 neurons\n",
      "Iteration 17: 32 neurons\n",
      "Iteration 18: 32 neurons\n",
      "Iteration 19: 32 neurons\n",
      "Iteration 20: 32 neurons\n",
      "Iteration 21: 32 neurons\n",
      "Iteration 22: 31 neurons\n",
      "Iteration 23: 31 neurons\n",
      "Iteration 24: 32 neurons\n",
      "Iteration 25: 32 neurons\n",
      "Iteration 26: 32 neurons\n",
      "Iteration 27: 32 neurons\n",
      "Iteration 28: 32 neurons\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PLOT: Weight space visualization in polar coordinates\n",
    "# Shows the distribution of weights in 2D space for the current training run\n",
    "# =============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Extract weights from the current training run\n",
    "weights_run = training_logger_1.history['weights']\n",
    "biases_run = training_logger_1.history['biases']\n",
    "neurons_run = training_logger_1.history['neuron_count']\n",
    "\n",
    "print(f\"Training run: {len(weights_run)} iterations, max neurons: {max(neurons_run)}\")\n",
    "\n",
    "# Find optimal iteration (iteration with the most neurons)\n",
    "optimal_iter = neurons_run.index(max(neurons_run))\n",
    "print(f\"Optimal iteration: {optimal_iter} with {neurons_run[optimal_iter]} neurons\")\n",
    "\n",
    "# Extract weights at optimal iteration\n",
    "weights_optimal = weights_run[optimal_iter]\n",
    "b_optimal = biases_run[optimal_iter].reshape(1, -1)   # (1, n)\n",
    "a_optimal = weights_optimal.T                          # (2, n)\n",
    "Z = a_optimal / (1 + b_optimal) \n",
    "\n",
    "# Create polar coordinate visualization\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "# Compute angles and radii in weight space (2D)\n",
    "angles = np.arctan2(Z[1], Z[0])\n",
    "xy_norms = np.linalg.norm(Z, axis=0)\n",
    "\n",
    "# Plot in polar coordinates\n",
    "ax.scatter(angles, xy_norms, color='blue', alpha=0.8, s=60)\n",
    "ax.set_title(f'Weight Space at Optimal Iteration\\nNeurons: {neurons_run[optimal_iter]}', fontsize=14)\n",
    "ax.grid(True, alpha=0.5)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('../data_result/plot/weights_polar_analysis_single.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"Polar coordinate analysis saved to ../data_result/plot/weights_polar_analysis_single.png\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Additional analysis: Weight distribution statistics\n",
    "print(\"\\n=== Weight Distribution Analysis ===\")\n",
    "print(f\"Mean norm: {np.mean(xy_norms):.4f}\")\n",
    "print(f\"Std norm: {np.std(xy_norms):.4f}\")\n",
    "print(f\"Weight range: [{weights_optimal.min():.4f}, {weights_optimal.max():.4f}]\")\n",
    "print(f\"Number of neurons: {weights_optimal.shape[0]}\")\n",
    "\n",
    "# Optional: Show weight evolution across iterations\n",
    "if len(weights_run) > 1:\n",
    "    print(f\"\\n=== Weight Evolution ===\")\n",
    "    print(\"Neuron counts across iterations:\")\n",
    "    for i, count in enumerate(neurons_run):\n",
    "        print(f\"Iteration {i}: {count} neurons\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
