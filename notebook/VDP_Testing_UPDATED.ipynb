{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeebd44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to Python path so model.py can find ssn and net modules\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from src.model import model\n",
    "from src.model_outerweights import model_outerweights\n",
    "from src.greedy_insertion import _sample_uniform_sphere_points\n",
    "from src.training_logger import run_training_with_logging\n",
    "\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dfa9fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-27 05:43:21.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mLoaded data with shape: (1800,), dtype: [('x', '<f8', (2,)), ('dv', '<f8', (2,)), ('v', '<f8')]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "path = '../data_result/raw_data/VDP_beta_0.1_grid_combined.npy'# Initialize the weights\n",
    "data = np.load(path)\n",
    "logger.info(f\"Loaded data with shape: {data.shape}, dtype: {data.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4099fadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameter\n",
    "power = 1.0\n",
    "M = 10 # number greedy insertion selected\n",
    "num_iterations = 30\n",
    "loss_weights = (1.0, 1.0)\n",
    "pruning_threshold = 1e-15\n",
    "\n",
    "gamma = 5.0\n",
    "alpha = 1e-1\n",
    "regularization = (gamma, alpha) \n",
    "th = 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4273cea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-27 05:43:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_configure_logger\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mVDPModel initialized\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_configure_logger\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mVDPModel (outer weights) initialized\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model \n",
    "model_1 = model(data, torch.relu, power, regularization, optimizer='Adam', loss_weights = loss_weights)\n",
    "model_2 = model_outerweights(data, torch.relu, power, regularization, optimizer='SSN_TR', loss_weights = loss_weights, th = th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9e2c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the initializing weights and bias\n",
    "init_weights, init_bias = _sample_uniform_sphere_points(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "256a18d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-27 05:43:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1mStarting network training session\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_create_network\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mCreating network with 10 neurons\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mUsing Adam optimizer with lr=0.01\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m288\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mTraining hyperparameters: iterations=1000, batch_size=1620, display_every=200\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 0: Train Loss = 31.794406, Val Loss = 32.526917\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 200: Train Loss = 4.983107, Val Loss = 4.843150\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 400: Train Loss = 3.801428, Val Loss = 4.323381\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 600: Train Loss = 5.023797, Val Loss = 6.439427\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mEpoch 800: Train Loss = 5.712785, Val Loss = 7.423927\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mFinal model saved to /Users/ruizhechao/Documents/NNforHJB/train_history/model_final.pt\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m382\u001b[0m - \u001b[1mTraining completed successfully\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mInitialization done\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mInitial weights shape: (10, 2), bias shape: (10,)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_result, weight_raw, bias_raw, outerweight_raw = model_1.train(\n",
    "    iterations=1000,\n",
    "    display_every=200,\n",
    "    inner_weights=init_weights, inner_bias=init_bias,\n",
    ")\n",
    "logger.info(\"Initialization done\"); logger.info(f\"Initial weights shape: {weight_raw.shape}, bias shape: {bias_raw.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b80147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-27 05:43:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.training_logger\u001b[0m:\u001b[36mrun_training_with_logging\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mIteration 0 - weights shape: (10, 2)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m266\u001b[0m - \u001b[1mStarting network training session (outer weights only)\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mTraining set: 1620 samples, Validation set: 180 samples\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1mData ranges - x: [-3.00, 3.00], v: [0.00, 10.96], dv: [-13.19, 13.19]\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36m_setup_optimizer\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1mUsing SSN_TR optimizer with alpha=0.1, gamma=5.0, th=0.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m283\u001b[0m - \u001b[1mTraining model, saving to /Users/ruizhechao/Documents/NNforHJB/train_history\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m284\u001b[0m - \u001b[1mTraining hyperparameters: iterations=5000, batch_size=1620, display_every=1000\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m285\u001b[0m - \u001b[1mLoss weights: value=1.0, gradient=1.0\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 0: Train Loss = 5.594079, Val Loss = 8.008012\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 1000: Train Loss = 5.594079, Val Loss = 8.008012\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 2000: Train Loss = 5.594079, Val Loss = 8.008012\u001b[0m\n",
      "\u001b[32m2025-08-27 05:43:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_outerweights\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m330\u001b[0m - \u001b[1mEpoch 3000: Train Loss = 5.594079, Val Loss = 8.008012\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Training with improved logging\n",
    "training_logger, weight_raw, bias_raw, outerweight_raw = run_training_with_logging(\n",
    "    data, model_1, model_2, model_result, weight_raw, bias_raw, outerweight_raw,\n",
    "    num_iterations, M, alpha, pruning_threshold, power, gamma\n",
    ")\n",
    "\n",
    "logger.info(\"Training completed with improved logging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794aec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_logger.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adb6393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PLOT: Weight space visualization in polar coordinates\n",
    "# Shows the distribution of weights in 2D space for the current training run\n",
    "# =============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Extract weights from the current training run\n",
    "weights_run = training_logger.history['weights']\n",
    "biases_run = training_logger.history['biases']\n",
    "neurons_run = training_logger.history['neuron_count']\n",
    "\n",
    "print(f\"Training run: {len(weights_run)} iterations, max neurons: {max(neurons_run)}\")\n",
    "\n",
    "# Find optimal iteration (iteration with the most neurons)\n",
    "optimal_iter = neurons_run.index(max(neurons_run))\n",
    "print(f\"Optimal iteration: {optimal_iter} with {neurons_run[optimal_iter]} neurons\")\n",
    "\n",
    "# Extract weights at optimal iteration\n",
    "weights_optimal = weights_run[optimal_iter]\n",
    "b_optimal = biases_run[optimal_iter].reshape(1, -1)   # (1, n)\n",
    "a_optimal = weights_optimal.T                          # (2, n)\n",
    "Z = a_optimal / (1 + b_optimal) \n",
    "\n",
    "# Create polar coordinate visualization\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "# Compute angles and radii in weight space (2D)\n",
    "angles = np.arctan2(Z[1], Z[0])\n",
    "xy_norms = np.linalg.norm(Z, axis=0)\n",
    "\n",
    "# Plot in polar coordinates\n",
    "ax.scatter(angles, xy_norms, color='blue', alpha=0.8, s=60)\n",
    "ax.set_title(f'Weight Space at Optimal Iteration\\nNeurons: {neurons_run[optimal_iter]}', fontsize=14)\n",
    "ax.grid(True, alpha=0.5)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('../data_result/plot/weights_polar_analysis_single.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"Polar coordinate analysis saved to ../data_result/plot/weights_polar_analysis_single.png\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Additional analysis: Weight distribution statistics\n",
    "print(\"\\n=== Weight Distribution Analysis ===\")\n",
    "print(f\"Mean norm: {np.mean(xy_norms):.4f}\")\n",
    "print(f\"Std norm: {np.std(xy_norms):.4f}\")\n",
    "print(f\"Weight range: [{weights_optimal.min():.4f}, {weights_optimal.max():.4f}]\")\n",
    "print(f\"Number of neurons: {weights_optimal.shape[0]}\")\n",
    "\n",
    "# Optional: Show weight evolution across iterations\n",
    "if len(weights_run) > 1:\n",
    "    print(f\"\\n=== Weight Evolution ===\")\n",
    "    print(\"Neuron counts across iterations:\")\n",
    "    for i, count in enumerate(neurons_run):\n",
    "        print(f\"Iteration {i}: {count} neurons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b0f71",
   "metadata": {},
   "source": [
    "## Test with the L1 Penalty ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bceb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the parameter\n",
    "power = 1.0\n",
    "M = 10 # number greedy insertion selected\n",
    "num_iterations = 30\n",
    "loss_weights = (1.0, 1.0)\n",
    "pruning_threshold = 1e-13\n",
    "\n",
    "gamma = 1e-5\n",
    "alpha = 1e-1\n",
    "regularization = (gamma, alpha) \n",
    "th = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac139d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to Python path so model.py can find ssn and net modules\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from src.model import model\n",
    "from src.model_outerweights import model_outerweights\n",
    "from src.greedy_insertion import insertion\n",
    "from src.training_logger import run_training_with_logging\n",
    "\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "import torch\n",
    "# Initialize the model \n",
    "model_1 = model(data, torch.relu, power, regularization, optimizer='Adam', loss_weights = loss_weights)\n",
    "model_2 = model_outerweights(data, torch.relu, power, regularization, optimizer='SSN_TR', loss_weights = loss_weights, th = th)\n",
    "# Set up the initializing weights and bias\n",
    "init_weights = np.random.randn(M, 2) * 0.1\n",
    "init_bias = np.random.randn(M)\n",
    "\n",
    "model_result, weight_raw, bias_raw, outerweight_raw = model_1.train(\n",
    "    iterations=1000,\n",
    "    display_every=200,\n",
    "    inner_weights=init_weights, inner_bias=init_bias,\n",
    ")\n",
    "logger.info(\"Initialization done\"); logger.info(f\"Initial weights shape: {weight_raw.shape}, bias shape: {bias_raw.shape}\")\n",
    "\n",
    "# Training with improved logging\n",
    "training_logger_1, weight_raw_1, bias_raw_1, outerweight_raw_1 = run_training_with_logging(\n",
    "    data, model_1, model_2, model_result, weight_raw, bias_raw, outerweight_raw,\n",
    "    num_iterations, M, alpha, pruning_threshold, power, gamma\n",
    ")\n",
    "\n",
    "logger.info(\"Training completed with improved logging\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b6c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PLOT: Weight space visualization in polar coordinates\n",
    "# Shows the distribution of weights in 2D space for the current training run\n",
    "# =============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Extract weights from the current training run\n",
    "weights_run = training_logger_1.history['weights']\n",
    "biases_run = training_logger_1.history['biases']\n",
    "neurons_run = training_logger_1.history['neuron_count']\n",
    "\n",
    "print(f\"Training run: {len(weights_run)} iterations, max neurons: {max(neurons_run)}\")\n",
    "\n",
    "# Find optimal iteration (iteration with the most neurons)\n",
    "optimal_iter = neurons_run.index(max(neurons_run))\n",
    "print(f\"Optimal iteration: {optimal_iter} with {neurons_run[optimal_iter]} neurons\")\n",
    "\n",
    "# Extract weights at optimal iteration\n",
    "weights_optimal = weights_run[optimal_iter]\n",
    "b_optimal = biases_run[optimal_iter].reshape(1, -1)   # (1, n)\n",
    "a_optimal = weights_optimal.T                          # (2, n)\n",
    "Z = a_optimal / (1 + b_optimal) \n",
    "\n",
    "# Create polar coordinate visualization\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "# Compute angles and radii in weight space (2D)\n",
    "angles = np.arctan2(Z[1], Z[0])\n",
    "xy_norms = np.linalg.norm(Z, axis=0)\n",
    "\n",
    "# Plot in polar coordinates\n",
    "ax.scatter(angles, xy_norms, color='blue', alpha=0.8, s=60)\n",
    "ax.set_title(f'Weight Space at Optimal Iteration\\nNeurons: {neurons_run[optimal_iter]}', fontsize=14)\n",
    "ax.grid(True, alpha=0.5)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('../data_result/plot/weights_polar_analysis_single.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"Polar coordinate analysis saved to ../data_result/plot/weights_polar_analysis_single.png\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Additional analysis: Weight distribution statistics\n",
    "print(\"\\n=== Weight Distribution Analysis ===\")\n",
    "print(f\"Mean norm: {np.mean(xy_norms):.4f}\")\n",
    "print(f\"Std norm: {np.std(xy_norms):.4f}\")\n",
    "print(f\"Weight range: [{weights_optimal.min():.4f}, {weights_optimal.max():.4f}]\")\n",
    "print(f\"Number of neurons: {weights_optimal.shape[0]}\")\n",
    "\n",
    "# Optional: Show weight evolution across iterations\n",
    "if len(weights_run) > 1:\n",
    "    print(f\"\\n=== Weight Evolution ===\")\n",
    "    print(\"Neuron counts across iterations:\")\n",
    "    for i, count in enumerate(neurons_run):\n",
    "        print(f\"Iteration {i}: {count} neurons\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
